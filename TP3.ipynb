{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d1485",
   "metadata": {},
   "source": [
    "# TP3 - Find the soda logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaf884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467ba69",
   "metadata": {},
   "source": [
    "## Find the soda logo within the provided images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20eb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ff4b",
   "metadata": {},
   "source": [
    "1. Obtain a logo detection in each image without false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(path, max_size=1200):\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    \n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path, max_size=400):\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "# Note: The create_template_variants function is defined in Cell 5 (DETECTION FUNCTIONS)\n",
    "# This cell only contains utility functions for loading and visualization\n",
    "\n",
    "\n",
    "def draw_detections(img_rgb, detections):\n",
    "    \"\"\"Draw detection rectangles on image with confidence scores.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for det in detections:\n",
    "        x, y, w, h = det[:4]\n",
    "        score = det[4] if len(det) > 4 else 1.0\n",
    "        \n",
    "        # Color according to confidence level (green high, yellow medium, red low)\n",
    "        if score >= 0.7:\n",
    "            color = (0, 255, 0)  # Green\n",
    "        elif score >= 0.5:\n",
    "            color = (255, 255, 0)  # Yellow\n",
    "        else:\n",
    "            color = (255, 0, 0)  # Red\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, 2)\n",
    "        \n",
    "        # Display confidence level\n",
    "        label = f'{score:.2f}'\n",
    "        label_size, _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        label_y = max(y - 5, label_size[1])\n",
    "        cv.rectangle(img_out, (x, label_y - label_size[1] - 5), \n",
    "                    (x + label_size[0], label_y + 5), color, -1)\n",
    "        cv.putText(img_out, label, (x, label_y), \n",
    "                  cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_results_grid(results, title, save_path=None):\n",
    "    \"\"\"Plot results in a grid layout with confidence information.\"\"\"\n",
    "    n = len(results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img_rgb, detections, img_name) in enumerate(results):\n",
    "        img_result = draw_detections(img_rgb, detections)\n",
    "        axes[idx].imshow(img_result)\n",
    "        \n",
    "        # Display confidence information in the title\n",
    "        if detections:\n",
    "            scores = [d[4] for d in detections if len(d) > 4]\n",
    "            avg_conf = np.mean(scores) if scores else 0.0\n",
    "            conf_str = f\"avg confidence: {avg_conf:.2f}\" if len(detections) > 1 else f\"confidence: {scores[0]:.2f}\"\n",
    "            axes[idx].set_title(f\"{img_name}\\n{len(detections)} detection(s), {conf_str}\")\n",
    "        else:\n",
    "            axes[idx].set_title(f\"{img_name}\\n0 detections\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for idx in range(n, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single_result(img_rgb, detections, title, save_path=None):\n",
    "    \"\"\"Plot single image result with confidence information.\"\"\"\n",
    "    img_result = draw_detections(img_rgb, detections)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_result)\n",
    "    \n",
    "    # Display confidence information in the title\n",
    "    if detections:\n",
    "        scores = [d[4] for d in detections if len(d) > 4]\n",
    "        avg_conf = np.mean(scores) if scores else 0.0\n",
    "        min_conf = np.min(scores) if scores else 0.0\n",
    "        max_conf = np.max(scores) if scores else 0.0\n",
    "        title_with_conf = f\"{title} | {len(detections)} detections\\nConfidence: min={min_conf:.2f}, avg={avg_conf:.2f}, max={max_conf:.2f}\"\n",
    "    else:\n",
    "        title_with_conf = f\"{title} | 0 detections\"\n",
    "    \n",
    "    plt.title(title_with_conf, fontsize=12)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_template_variants(template):\n",
    "    \"\"\"\n",
    "    Create useful template variants for template matching.\n",
    "    Preprocessing matches image preprocessing for better alignment.\n",
    "    \"\"\"\n",
    "    # Apply CLAHE first (matching image preprocessing)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_template = clahe.apply(template)\n",
    "    \n",
    "    # Smooth variant (with CLAHE applied)\n",
    "    smooth = cv.GaussianBlur(clahe_template, (3, 3), 0)\n",
    "    \n",
    "    # Inverted variant (with CLAHE applied)\n",
    "    inverted = 255 - clahe_template\n",
    "    \n",
    "    # Equalized histogram variant (alternative preprocessing)\n",
    "    equalized = cv.equalizeHist(template)\n",
    "    \n",
    "    return {\n",
    "        'original': clahe_template,  # Use CLAHE as base to match image preprocessing\n",
    "        'clahe': clahe_template,\n",
    "        'smooth': smooth,\n",
    "        'inverted': inverted,\n",
    "        'equalized': equalized,\n",
    "    }\n",
    "\n",
    "\n",
    "def preprocess_image(img_gray):\n",
    "    \"\"\"\n",
    "    Preprocess image before template matching.\n",
    "    Uses CLAHE to match template preprocessing for better alignment.\n",
    "    \"\"\"\n",
    "    # Apply CLAHE for contrast normalization (matching template preprocessing)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img_gray)\n",
    "    # Light Gaussian blur to reduce noise while preserving edges\n",
    "    img = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    inter_w = max(0, xi2 - xi1)\n",
    "    inter_h = max(0, yi2 - yi1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def nms_global(detections, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression globally across all detections.\n",
    "    detections: list of (x, y, w, h, score)\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n",
    "    \n",
    "    keep = []\n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "\n",
    "def find_by_template(img_gray, template_variants, single_detection=True, min_threshold=0.30):\n",
    "    \"\"\"\n",
    "    Multi-scale template matching following the class code pattern.\n",
    "    - 30 scales between 0.2 and 1.6\n",
    "    - Adaptive threshold: mean + multiplier*std, min threshold according to mode\n",
    "    - Global NMS to filter overlaps\n",
    "    - Aspect ratio filtering: 0.5 < w/h < 3.0\n",
    "    \n",
    "    For multiple detections, uses lower threshold (following 01.Templates.ipynb Cell 6).\n",
    "    Improved thresholds based on actual detection confidence levels observed.\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    img_processed = preprocess_image(img_gray)\n",
    "    \n",
    "    # Adjust threshold according to detection mode\n",
    "    # Based on observed confidence levels (0.35-0.70 range), thresholds adjusted\n",
    "    if single_detection:\n",
    "        base_threshold = 0.25  # Lowered from 0.30 to catch detections with confidence ~0.35-0.45\n",
    "        adaptive_multiplier = 1.5  # Reduced from 2.5 to be less strict (allows more detections)\n",
    "    else:\n",
    "        base_threshold = 0.35  # Lowered from 0.60 for multiple detections (matches observed confidence range)\n",
    "        adaptive_multiplier = 1.2  # More permissive for multiple detections\n",
    "    \n",
    "    scales = np.linspace(0.2, 1.6, 30)\n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        for name, tmpl in template_variants.items():\n",
    "            th, tw = tmpl.shape\n",
    "            new_w = int(tw * scale)\n",
    "            new_h = int(th * scale)\n",
    "            \n",
    "            if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "                continue\n",
    "            \n",
    "            scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n",
    "            # Use TM_CCOEFF_NORMED as in 01.Templates.ipynb Cell 6\n",
    "            res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # Adaptive threshold with reduced multiplier for better sensitivity\n",
    "            mean_val = np.mean(res)\n",
    "            std_val = np.std(res)\n",
    "            threshold = max(mean_val + adaptive_multiplier * std_val, base_threshold)\n",
    "            \n",
    "            # np.where() as in 01.Templates.ipynb Cell 6\n",
    "            locations = np.where(res >= threshold)\n",
    "            \n",
    "            for pt in zip(*locations[::-1]):\n",
    "                x, y = pt\n",
    "                score = res[y, x]\n",
    "                \n",
    "                aspect = new_w / new_h if new_h > 0 else 0\n",
    "                if not (0.5 < aspect < 3.0):\n",
    "                    continue\n",
    "                \n",
    "                all_detections.append((x, y, new_w, new_h, score))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return (None, None, 0) if single_detection else []\n",
    "    \n",
    "    # Apply NMS to filter overlaps (improvement over basic 01.Templates.ipynb)\n",
    "    final_detections = nms_global(all_detections, iou_threshold=0.3)\n",
    "    \n",
    "    if single_detection:\n",
    "        best = final_detections[0]\n",
    "        return (best[0], best[1], best[2], best[3]), 'template', best[4]\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "\n",
    "def detect_logo(img_bgr, img_gray, template_variants, single_detection=True):\n",
    "    \"\"\"\n",
    "    Detection pipeline using only template matching (aligned with 01.Templates.ipynb).\n",
    "    - Single detection: Template matching with strict threshold\n",
    "    - Multi detection: Template matching with more permissive threshold (like 01.Templates.ipynb Cell 6)\n",
    "    \"\"\"\n",
    "    if single_detection:\n",
    "        bbox, method, score = find_by_template(img_gray, template_variants, single_detection=True)\n",
    "        if bbox:\n",
    "            return bbox, method, score\n",
    "        return None, None, 0\n",
    "    else:\n",
    "        # Multiple detections using template matching (like 01.Templates.ipynb Cell 6)\n",
    "        # Lower threshold for multiple detections to catch all instances\n",
    "        detections = find_by_template(img_gray, template_variants, single_detection=False, min_threshold=0.35)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "up51dq952i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEMPLATE VARIANTS VISUALIZATION (4 useful transformations)\n",
    "# =============================================================================\n",
    "\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "variants = create_template_variants(template)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
    "\n",
    "for ax, (name, img) in zip(axes, variants.items()):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(f'Template Variants ({len(variants)} transformations)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/template_variants.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af173e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCA-COLA-LOGO.jpg: template (confidence=0.415)\n",
      "coca_logo_1.png: template (confidence=0.358)\n",
      "coca_logo_2.png: template (confidence=0.395)\n",
      "coca_multi.png: template (confidence=0.457)\n",
      "coca_retro_1.png: template (confidence=0.631)\n",
      "coca_retro_2.png: template (confidence=0.699)\n",
      "logo_1.png: template (confidence=0.435)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 1: Single Detection per Image\n",
    "# =============================================================================\n",
    "\n",
    "IMAGES_DIR = 'images/'\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "results = []\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "    img_rgb, img_gray, img_bgr = load_image(img_path)\n",
    "    \n",
    "    bbox, method, match_val = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        # Save with real confidence score\n",
    "        detections = [(x, y, w, h, match_val)]\n",
    "        print(f\"{img_name}: {method} (confidence={match_val:.3f})\")\n",
    "    else:\n",
    "        detections = []\n",
    "        print(f\"{img_name}: NOT DETECTED\")\n",
    "    \n",
    "    results.append((img_rgb, detections, img_name))\n",
    "\n",
    "plot_results_grid(results, \"ASSIGNMENT 1: Single Detection per Image\", 'results/Figure_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891386f8",
   "metadata": {},
   "source": [
    "2. Propose and validate an algorithm for multiple detections in the image coca_multi.png using the same template from item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gktc1c4y0n7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 0 logo instances in coca_multi.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 2: Multiple Detections on coca_multi.png\n",
    "# Using template matching with the same template from Item 1 (like 01.Templates.ipynb Cell 6)\n",
    "# =============================================================================\n",
    "\n",
    "img_rgb, img_gray, img_bgr = load_image('images/coca_multi.png')\n",
    "detections = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "\n",
    "print(f\"Detected {len(detections)} logo instances in coca_multi.png\")\n",
    "for i, det in enumerate(detections):\n",
    "    x, y, w, h, score = det\n",
    "    print(f\"  Detection {i+1}: position=({x},{y}), size=({w}x{h}), confidence={score:.3f}\")\n",
    "\n",
    "plot_single_result(img_rgb, detections, \"ASSIGNMENT 2: coca_multi.png (Template Matching)\", 'results/Figure_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf815d5",
   "metadata": {},
   "source": [
    "3. Generalize the algorithm from item 2 for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1b10e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCA-COLA-LOGO.jpg: 1 single detection, 0 multiple detections\n",
      "coca_logo_1.png: 1 single detection, 0 multiple detections\n",
      "coca_logo_2.png: 1 single detection, 0 multiple detections\n",
      "coca_multi.png: 1 single detection, 0 multiple detections\n",
      "coca_retro_1.png: 1 single detection, 1 multiple detections\n",
      "coca_retro_2.png: 1 single detection, 1 multiple detections\n",
      "logo_1.png: 1 single detection, 0 multiple detections\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 3: Generalized Algorithm for All Images\n",
    "# Generalizes the template matching algorithm from Item 2 for all images\n",
    "# =============================================================================\n",
    "\n",
    "results_single = []\n",
    "results_multi = []\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray, img_bgr = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    \n",
    "    # Single detection: template matching with strict threshold\n",
    "    bbox, method, score = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    det_single = [(bbox[0], bbox[1], bbox[2], bbox[3], score)] if bbox else []\n",
    "    results_single.append((img_rgb, det_single, img_name))\n",
    "    \n",
    "    # Multiple detection: template matching with more permissive threshold (Item 2 algorithm)\n",
    "    det_multi = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "    results_multi.append((img_rgb, det_multi, img_name))\n",
    "    \n",
    "    print(f\"{img_name}: {len(det_single)} single detection, {len(det_multi)} multiple detections\")\n",
    "\n",
    "plot_results_grid(results_single, \"ASSIGNMENT 3: Single Detection (Template Matching)\", 'results/Figure_3a_single.png')\n",
    "plot_results_grid(results_multi, \"ASSIGNMENT 3: Multiple Detection (Template Matching)\", 'results/Figure_3b_multi.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
