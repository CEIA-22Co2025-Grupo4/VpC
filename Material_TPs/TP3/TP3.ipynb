{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TP3: Detección del logo de Coca-Cola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea463079",
   "metadata": {},
   "source": [
    "## 1: Detección única por imagen\n",
    "\n",
    "Encontrar el logotipo de la gaseosa dentro de las imágenes provistas.\n",
    "\n",
    "### Estrategia\n",
    "\n",
    "Para cada imagen se selecciona el método más adecuado según sus características:\n",
    "\n",
    "| Imagen | Método | Justificación |\n",
    "|--------|--------|---------------|\n",
    "| coca_logo_1.png | Edge TM | Fondo limpio, bordes preservados tras Canny |\n",
    "| coca_logo_2.png | SIFT | Superficie curva, distorsión de perspectiva |\n",
    "| coca_multi.png | TM invertido | Múltiples logos, contraste invertido |\n",
    "| coca_retro_1.png | SIFT | Logo retro estructuralmente diferente |\n",
    "| coca_retro_2.png | SIFT | Logo curvado en emblema circular |\n",
    "| COCA-COLA-LOGO.jpg | SIFT | Logo grande, fondo complejo |\n",
    "| logo_1.png | TM invertido | Reflejos en vidrio, variaciones de iluminación |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utilities-header",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str, max_size: int = 1200) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path: str, max_size: int = 400) -> np.ndarray:\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    if template is None:\n",
    "        raise FileNotFoundError(f\"Template not found: {path}\")\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "def preprocess_image(img_gray: np.ndarray, method: str = 'clahe') -> np.ndarray:\n",
    "    \"\"\"Apply preprocessing to grayscale image.\n",
    "    \n",
    "    Methods:\n",
    "        - 'clahe': Contrast Limited Adaptive Histogram Equalization\n",
    "        - 'smooth': Gaussian blur\n",
    "        - 'equalize': Histogram equalization\n",
    "        - 'clahe_smooth': CLAHE + Gaussian blur\n",
    "    \"\"\"\n",
    "    if method == 'clahe':\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(img_gray)\n",
    "    elif method == 'smooth':\n",
    "        return cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    elif method == 'equalize':\n",
    "        return cv.equalizeHist(img_gray)\n",
    "    elif method == 'clahe_smooth':\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img = clahe.apply(img_gray)\n",
    "        return cv.GaussianBlur(img, (3, 3), 0)\n",
    "    else:\n",
    "        return img_gray\n",
    "\n",
    "\n",
    "def create_template_variants(template: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Create template variants: original, clahe, smooth.\"\"\"\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return {\n",
    "        'original': template,\n",
    "        'clahe': clahe.apply(template),\n",
    "        'smooth': cv.GaussianBlur(template, (3, 3), 0),\n",
    "    }\n",
    "\n",
    "\n",
    "def rotate_template(template: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"Rotate template by given angle (degrees).\"\"\"\n",
    "    h, w = template.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate new bounding box size\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    new_w = int(h * sin + w * cos)\n",
    "    new_h = int(h * cos + w * sin)\n",
    "    \n",
    "    # Adjust rotation matrix\n",
    "    M[0, 2] += (new_w - w) / 2\n",
    "    M[1, 2] += (new_h - h) / 2\n",
    "    \n",
    "    return cv.warpAffine(template, M, (new_w, new_h), borderValue=255)\n",
    "\n",
    "\n",
    "def compute_iou(box1: Tuple, box2: Tuple) -> float:\n",
    "    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n",
    "    x1, y1, w1, h1 = box1[:4]\n",
    "    x2, y2, w2, h2 = box2[:4]\n",
    "    \n",
    "    xi1, yi1 = max(x1, x2), max(y1, y2)\n",
    "    xi2, yi2 = min(x1 + w1, x2 + w2), min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    union_area = w1 * h1 + w2 * h2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def nms_global(detections: List[Tuple], iou_threshold: float = 0.3) -> List[Tuple]:\n",
    "    \"\"\"Apply Non-Maximum Suppression globally.\"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n",
    "    keep = []\n",
    "    \n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "\n",
    "def draw_detection(img_rgb: np.ndarray, bbox: Tuple, color=(0, 255, 0), thickness=3) -> np.ndarray:\n",
    "    \"\"\"Draw bounding box on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    if bbox:\n",
    "        x, y, w, h = bbox[:4]\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, thickness)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_result(img_rgb: np.ndarray, bbox: Tuple, title: str, score: float = None):\n",
    "    \"\"\"Plot single detection result.\"\"\"\n",
    "    img_out = draw_detection(img_rgb, bbox)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_out)\n",
    "    title_str = title\n",
    "    if score is not None:\n",
    "        title_str += f\" | Score: {score:.3f}\"\n",
    "    if bbox:\n",
    "        title_str += f\" | Size: {bbox[2]}x{bbox[3]}\"\n",
    "    plt.title(title_str)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detection-header",
   "metadata": {},
   "source": [
    "### Core Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "detection-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_match_multiscale(\n",
    "    img_gray: np.ndarray,\n",
    "    template_variants: Dict[str, np.ndarray],\n",
    "    scales: np.ndarray,\n",
    "    threshold: float = 0.30,\n",
    "    preprocess: str = None,\n",
    "    aspect_filter: Tuple[float, float] = None,\n",
    "    min_width_ratio: float = 0.05\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"\n",
    "    Multi-scale template matching.\n",
    "    \n",
    "    Returns: (bbox, score, method_info)\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    \n",
    "    # Preprocess image\n",
    "    if preprocess:\n",
    "        img_processed = preprocess_image(img_gray, preprocess)\n",
    "    else:\n",
    "        img_processed = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "        img_processed = cv.equalizeHist(img_processed)\n",
    "    \n",
    "    min_det_width = w * min_width_ratio\n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        for name, tmpl in template_variants.items():\n",
    "            th, tw = tmpl.shape\n",
    "            new_w, new_h = int(tw * scale), int(th * scale)\n",
    "            \n",
    "            # Skip invalid sizes\n",
    "            if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "                continue\n",
    "            if new_w < min_det_width:\n",
    "                continue\n",
    "            \n",
    "            scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n",
    "            res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # Adaptive threshold\n",
    "            mean_val, std_val = np.mean(res), np.std(res)\n",
    "            adaptive_thresh = max(mean_val + 2.5 * std_val, threshold)\n",
    "            \n",
    "            locations = np.where(res >= adaptive_thresh)\n",
    "            \n",
    "            for pt in zip(*locations[::-1]):\n",
    "                x, y = pt\n",
    "                score = res[y, x]\n",
    "                \n",
    "                # Aspect ratio filter\n",
    "                aspect = new_w / new_h if new_h > 0 else 0\n",
    "                if aspect_filter:\n",
    "                    if not (aspect_filter[0] < aspect < aspect_filter[1]):\n",
    "                        continue\n",
    "                elif not (0.5 < aspect < 4.0):\n",
    "                    continue\n",
    "                \n",
    "                all_detections.append((x, y, new_w, new_h, score, name, scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return None, 0, \"No detection\"\n",
    "    \n",
    "    # Apply NMS and get best\n",
    "    final = nms_global(all_detections, iou_threshold=0.3)\n",
    "    best = final[0]\n",
    "    \n",
    "    bbox = (best[0], best[1], best[2], best[3])\n",
    "    method_info = f\"TM-{best[5]}@{best[6]:.2f}\"\n",
    "    \n",
    "    return bbox, best[4], method_info\n",
    "\n",
    "\n",
    "def template_match_edges(\n",
    "    img_gray: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    scales: np.ndarray,\n",
    "    threshold: float = 0.25,\n",
    "    canny_low: int = 50,\n",
    "    canny_high: int = 150,\n",
    "    y_range: Tuple[int, int] = None\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"\n",
    "    Edge-based template matching - robust to contrast inversion.\n",
    "    \n",
    "    Args:\n",
    "        img_gray: Grayscale image\n",
    "        template: Grayscale template\n",
    "        scales: Array of scales to test\n",
    "        threshold: Minimum score threshold\n",
    "        canny_low/high: Canny edge detection thresholds\n",
    "        y_range: Optional (y_min, y_max) to restrict detection area\n",
    "    \n",
    "    Returns: (bbox, score, method_info)\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    \n",
    "    # Create edge versions\n",
    "    template_edges = cv.Canny(template, canny_low, canny_high)\n",
    "    img_edges = cv.Canny(img_gray, canny_low, canny_high)\n",
    "    \n",
    "    # Dilate edges for better matching\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    template_edges = cv.dilate(template_edges, kernel, iterations=1)\n",
    "    img_edges = cv.dilate(img_edges, kernel, iterations=1)\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        th, tw = template.shape\n",
    "        new_w, new_h = int(tw * scale), int(th * scale)\n",
    "        \n",
    "        if new_w >= w or new_h >= h or new_w < 40:\n",
    "            continue\n",
    "        \n",
    "        scaled_edges = cv.resize(template_edges, (new_w, new_h))\n",
    "        res = cv.matchTemplate(img_edges, scaled_edges, cv.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Adaptive threshold\n",
    "        mean_val, std_val = np.mean(res), np.std(res)\n",
    "        adaptive_thresh = max(mean_val + 2.5 * std_val, threshold)\n",
    "        \n",
    "        locations = np.where(res >= adaptive_thresh)\n",
    "        \n",
    "        for pt in zip(*locations[::-1]):\n",
    "            x, y = pt\n",
    "            score = res[y, x]\n",
    "            \n",
    "            # Y-range filter (if specified)\n",
    "            if y_range:\n",
    "                if not (y_range[0] <= y <= y_range[1]):\n",
    "                    continue\n",
    "            \n",
    "            all_detections.append((x, y, new_w, new_h, score, 'edges', scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return None, 0, \"No detection (edges)\"\n",
    "    \n",
    "    # Apply NMS and get best\n",
    "    final = nms_global(all_detections, iou_threshold=0.3)\n",
    "    best = final[0]\n",
    "    \n",
    "    bbox = (best[0], best[1], best[2], best[3])\n",
    "    method_info = f\"TM-edges@{best[6]:.2f}\"\n",
    "    \n",
    "    return bbox, best[4], method_info\n",
    "\n",
    "\n",
    "def template_match_with_rotation(\n",
    "    img_gray: np.ndarray,\n",
    "    template_variants: Dict[str, np.ndarray],\n",
    "    scales: np.ndarray,\n",
    "    rotations: List[float],\n",
    "    threshold: float = 0.30,\n",
    "    preprocess: str = None\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"\n",
    "    Multi-scale + multi-rotation template matching.\n",
    "    \n",
    "    Returns: (bbox, score, method_info)\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    \n",
    "    # Preprocess image\n",
    "    if preprocess:\n",
    "        img_processed = preprocess_image(img_gray, preprocess)\n",
    "    else:\n",
    "        img_processed = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "        img_processed = cv.equalizeHist(img_processed)\n",
    "    \n",
    "    min_det_width = w * 0.10\n",
    "    all_detections = []\n",
    "    \n",
    "    for rotation in rotations:\n",
    "        for scale in scales:\n",
    "            for name, tmpl in template_variants.items():\n",
    "                # Rotate template\n",
    "                if rotation != 0:\n",
    "                    tmpl_rot = rotate_template(tmpl, rotation)\n",
    "                else:\n",
    "                    tmpl_rot = tmpl\n",
    "                \n",
    "                th, tw = tmpl_rot.shape\n",
    "                new_w, new_h = int(tw * scale), int(th * scale)\n",
    "                \n",
    "                if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "                    continue\n",
    "                if new_w < min_det_width:\n",
    "                    continue\n",
    "                \n",
    "                scaled_tmpl = cv.resize(tmpl_rot, (new_w, new_h))\n",
    "                res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "                \n",
    "                mean_val, std_val = np.mean(res), np.std(res)\n",
    "                adaptive_thresh = max(mean_val + 2.5 * std_val, threshold)\n",
    "                \n",
    "                locations = np.where(res >= adaptive_thresh)\n",
    "                \n",
    "                for pt in zip(*locations[::-1]):\n",
    "                    x, y = pt\n",
    "                    score = res[y, x]\n",
    "                    all_detections.append((x, y, new_w, new_h, score, name, scale, rotation))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return None, 0, \"No detection\"\n",
    "    \n",
    "    final = nms_global(all_detections, iou_threshold=0.3)\n",
    "    best = final[0]\n",
    "    \n",
    "    bbox = (best[0], best[1], best[2], best[3])\n",
    "    method_info = f\"TM-{best[5]}@{best[6]:.2f},rot={best[7]}\"\n",
    "    \n",
    "    return bbox, best[4], method_info\n",
    "\n",
    "\n",
    "def detect_by_sift(\n",
    "    img_gray: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    min_matches: int = 8,\n",
    "    ratio: float = 0.75,\n",
    "    min_bbox_ratio: float = 0.02,\n",
    "    max_bbox_ratio: float = 0.95\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"\n",
    "    SIFT-based detection with homography.\n",
    "    \n",
    "    Args:\n",
    "        img_gray: Grayscale image\n",
    "        template: Grayscale template\n",
    "        min_matches: Minimum number of good matches required\n",
    "        ratio: Lowe's ratio test threshold (0.7 stricter, 0.75-0.8 more relaxed)\n",
    "        min_bbox_ratio: Minimum bbox area as ratio of image area\n",
    "        max_bbox_ratio: Maximum bbox area as ratio of image area\n",
    "    \n",
    "    Returns: (bbox, score, method_info)\n",
    "    \"\"\"\n",
    "    img_h, img_w = img_gray.shape\n",
    "    img_area = img_h * img_w\n",
    "    \n",
    "    sift = cv.SIFT_create(nfeatures=2000)\n",
    "    kp2, des2 = sift.detectAndCompute(img_gray, None)\n",
    "    \n",
    "    if des2 is None or len(des2) < min_matches:\n",
    "        return None, 0, \"SIFT: insufficient features in image\"\n",
    "    \n",
    "    # Try both normal and inverted template\n",
    "    for tmpl_name, tmpl in [('normal', template), ('inverted', 255 - template)]:\n",
    "        kp1, des1 = sift.detectAndCompute(tmpl, None)\n",
    "        \n",
    "        if des1 is None or len(des1) < 4:\n",
    "            continue\n",
    "        \n",
    "        # FLANN matcher\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "        \n",
    "        # Lowe's ratio test with configurable ratio\n",
    "        good = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                m, n = match\n",
    "                if m.distance < ratio * n.distance:\n",
    "                    good.append(m)\n",
    "        \n",
    "        if len(good) < min_matches:\n",
    "            continue\n",
    "        \n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        \n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
    "        \n",
    "        if M is None:\n",
    "            continue\n",
    "        \n",
    "        # Count inliers from RANSAC\n",
    "        inliers = mask.ravel().sum() if mask is not None else 0\n",
    "        \n",
    "        th, tw = tmpl.shape\n",
    "        pts = np.float32([[0,0], [0,th-1], [tw-1,th-1], [tw-1,0]]).reshape(-1,1,2)\n",
    "        dst = cv.perspectiveTransform(pts, M)\n",
    "        x, y, bw, bh = cv.boundingRect(dst)\n",
    "        \n",
    "        # Clamp to image bounds\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        bw = min(bw, img_w - x)\n",
    "        bh = min(bh, img_h - y)\n",
    "        \n",
    "        # Validate bounding box size relative to image\n",
    "        bbox_area = bw * bh\n",
    "        if bbox_area < img_area * min_bbox_ratio:\n",
    "            continue  # Too small\n",
    "        if bbox_area > img_area * max_bbox_ratio:\n",
    "            continue  # Too large (likely bad homography)\n",
    "        \n",
    "        # Additional sanity checks\n",
    "        if bw < 20 or bh < 10:\n",
    "            continue  # Absolute minimum size\n",
    "        if bw / bh > 10 or bh / bw > 5:\n",
    "            continue  # Unreasonable aspect ratio\n",
    "        \n",
    "        score = len(good) / 100.0  # Normalize score\n",
    "        return (x, y, bw, bh), score, f\"SIFT-{tmpl_name}({len(good)} matches)\"\n",
    "    \n",
    "    return None, 0, \"SIFT: no valid homography found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-template-header",
   "metadata": {},
   "source": [
    "### Load Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "load-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template shape: (175, 400)\n",
      "Variants: ['original', 'clahe', 'smooth']\n"
     ]
    }
   ],
   "source": [
    "# Load template and create variants\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "template_variants = create_template_variants(template)\n",
    "\n",
    "print(f\"Template shape: {template.shape}\")\n",
    "print(f\"Variants: {list(template_variants.keys())}\")\n",
    "\n",
    "# Display template variants\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, (name, img) in zip(axes, template_variants.items()):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Template Variants')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results storage\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image1-header",
   "metadata": {},
   "source": [
    "---\n",
    "### Image Detection\n",
    "\n",
    "#### 1 coca_logo_1.png\n",
    "\n",
    "Se utilizó template matching basado en bordes porque el fondo es limpio y el contorno del logotipo se preserva bien tras Canny, logrando una coincidencia muy estable. Además, el uso de un rango de escalas reducido y un filtro por posición vertical permite evitar falsas detecciones en áreas sin contenido relevante.\n",
    "\n",
    "**Características:** Botella con etiqueta frontal, texto BLANCO sobre fondo ROJO.  \n",
    "**Problema:** En escala de grises, el contraste está invertido respecto al template.  \n",
    "**Estrategia:** Template matching basado en bordes (Canny es invariante a la inversión de contraste).  \n",
    "**Escalas:** 0.30 - 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "detect-coca-logo-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (500, 207)\n",
      "Image: coca_logo_1.png\n",
      "Method: TM-edges@0.42\n",
      "Score: 0.411\n",
      "BBox: (np.int64(31), np.int64(198), 167, 73)\n"
     ]
    }
   ],
   "source": [
    "# coca_logo_1.png - Bottle with white text on red background\n",
    "# Problem: Inverted contrast in grayscale\n",
    "# Solution: Edge-based matching (edges are invariant to contrast inversion)\n",
    "img_name = \"coca_logo_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Edge-based matching with scales optimized for this image\n",
    "scales = np.linspace(0.30, 0.55, 20)\n",
    "\n",
    "# Use relative y_range based on image height (robust to resizing)\n",
    "h, w = img_gray.shape\n",
    "y_min, y_max = int(0.3 * h), int(0.7 * h)\n",
    "\n",
    "bbox, score, method = template_match_edges(\n",
    "    img_gray, \n",
    "    template,\n",
    "    scales=scales,\n",
    "    threshold=0.25,\n",
    "    y_range=(y_min, y_max)  # Restrict to label area (avoid false positives)\n",
    ")\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image2-header",
   "metadata": {},
   "source": [
    "#### 2 coca_logo_2.png\n",
    "\n",
    "Para esta imagen se aplicó SIFT debido a la curvatura del envase y las variaciones de iluminación, que afectan la correlación directa de plantillas pero no la coincidencia de puntos clave. La homografía obtenida a partir de los matches permite recuperar con precisión la región del logotipo pese a la deformación de perspectiva.\n",
    "\n",
    "**Características:** Lata con texto BLANCO sobre fondo ROJO, superficie curva, gotas de agua.  \n",
    "**Problema:** Template matching falla debido a la distorsión por curvatura e inversión de contraste.  \n",
    "**Estrategia:** SIFT con template invertido (el texto blanco genera features que coinciden con el template invertido).  \n",
    "**Nota:** SIFT maneja la distorsión de perspectiva de la superficie curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detect-coca-logo-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (363, 233)\n",
      "Image: coca_logo_2.png\n",
      "Method: SIFT-inverted(48 matches)\n",
      "Score: 0.480\n",
      "BBox: (0, 95, 233, 133)\n"
     ]
    }
   ],
   "source": [
    "# coca_logo_2.png - Can with curved surface\n",
    "# Problem: Template matching fails due to curved surface and contrast inversion\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"coca_logo_2.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT works well for curved surfaces (handles perspective distortion)\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image3-header",
   "metadata": {},
   "source": [
    "#### 3 coca_multi.png\n",
    "\n",
    "Se utilizó template matching invertido y un rango de escalas estrecho porque todos los logos aparecen a tamaño similar y contrastan de manera consistente con el fondo. La supresión global de no-máximos permite conservar solo la mejor detección individual, cumpliendo con la restricción de una única coincidencia por imagen.\n",
    "\n",
    "**Características:** Estante con múltiples botellas, texto BLANCO sobre etiquetas ROJAS.  \n",
    "**Problema:** Múltiples logos similares, inversión de contraste en escala de grises.  \n",
    "**Estrategia:** Template matching invertido con CLAHE (corrige la inversión de contraste).  \n",
    "**Escalas:** Derivadas del tamaño esperado del logo (~10% del ancho de imagen).  \n",
    "**Nota:** Para Assignment 1, se detecta solo UN logo (mejor coincidencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "detect-coca-multi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (598, 799)\n",
      "Expected logo width: ~80px\n",
      "Scale range: 0.12 - 0.30\n",
      "Image: coca_multi.png\n",
      "Method: TM-inverted_clahe@0.23\n",
      "Score: 0.501\n",
      "BBox: (np.int64(274), np.int64(146), 93, 40)\n"
     ]
    }
   ],
   "source": [
    "# coca_multi.png - Shelf with many bottles\n",
    "# Problem: White text on red background = contrast inversion\n",
    "# Solution: Use inverted template with CLAHE\n",
    "img_name = \"coca_multi.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Create inverted template variants (for white-on-red labels)\n",
    "template_inv = 255 - template\n",
    "inverted_variants = {\n",
    "    'inverted': template_inv,\n",
    "    'inverted_clahe': preprocess_image(template_inv, 'clahe'),\n",
    "}\n",
    "\n",
    "# Derive scale range from template and expected logo size\n",
    "# Reference: typical bottle label logo is ~80px wide in a 800px wide shelf image\n",
    "# This gives us a reference ratio that scales with any image size\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape  # template: 175x400\n",
    "\n",
    "reference_logo_width = 80  # expected logo width in pixels (for ~800px wide image)\n",
    "reference_image_width = 800\n",
    "expected_logo_ratio = reference_logo_width / reference_image_width  # ~0.10\n",
    "\n",
    "# Scale to actual image width\n",
    "expected_logo_width = w * expected_logo_ratio\n",
    "center_scale = expected_logo_width / tw  # scale where template matches expected logo\n",
    "\n",
    "# Scale range: ±50% around center scale\n",
    "scale_min = center_scale * 0.6\n",
    "scale_max = center_scale * 1.5\n",
    "scales = np.linspace(scale_min, scale_max, 20)\n",
    "\n",
    "print(f\"Expected logo width: ~{expected_logo_width:.0f}px\")\n",
    "print(f\"Scale range: {scale_min:.2f} - {scale_max:.2f}\")\n",
    "\n",
    "# Min width as ratio of image (derived from expected size)\n",
    "min_width_ratio = expected_logo_ratio * 0.5  # allow logos down to 50% of expected\n",
    "\n",
    "bbox, score, method = template_match_multiscale(\n",
    "    img_gray, \n",
    "    inverted_variants,\n",
    "    scales=scales,\n",
    "    threshold=0.35,\n",
    "    preprocess='clahe',\n",
    "    aspect_filter=(1.8, 3.5),  # Coca-Cola logo aspect ratio\n",
    "    min_width_ratio=min_width_ratio\n",
    ")\n",
    "\n",
    "# NOTE: For Assignment 2 (multiple detections), modify template_match_multiscale\n",
    "# to return `final` (all NMS results) instead of just `final[0]`\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image4-header",
   "metadata": {},
   "source": [
    "#### 4 coca_retro_1.png\n",
    "\n",
    "Se aplicó SIFT porque el logotipo retro difiere estructuralmente del template moderno, lo que hace que la correlación clásica falle al no haber similitud pixel-a-pixel. Los puntos clave permiten encontrar correspondencias parciales y estimar una homografía incluso cuando la forma global del logotipo no coincide con la plantilla.\n",
    "\n",
    "**Características:** Etiqueta vintage B/N, logotipo estilizado diferente al template.  \n",
    "**Problema:** Diferencias estructurales entre el logo retro y el template moderno.  \n",
    "**Estrategia:** SIFT con `min_matches=6` (menor umbral por diferencias estructurales).  \n",
    "**Fallback:** Template matching con aspect ratio amplio (1.2, 4.0) para formas retro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "detect-coca-retro-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (493, 715)\n",
      "Image: coca_retro_1.png\n",
      "Method: SIFT-normal(45 matches)\n",
      "Score: 0.450\n",
      "BBox: (62, 84, 579, 206)\n"
     ]
    }
   ],
   "source": [
    "# coca_retro_1.png - Vintage label (structurally different)\n",
    "img_name = \"coca_retro_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Try SIFT first (best for this case)\n",
    "# Lower min_matches=6 because vintage logo has different shape, fewer strong correspondences\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=6)\n",
    "\n",
    "# Fallback to template matching if SIFT fails\n",
    "if bbox is None:\n",
    "    print(\"SIFT failed, trying template matching...\")\n",
    "    scales = np.linspace(0.5, 2.0, 25)\n",
    "    bbox, score, method = template_match_multiscale(\n",
    "        img_gray, \n",
    "        template_variants,\n",
    "        scales=scales,\n",
    "        threshold=0.25,  # Lower threshold for difficult case\n",
    "        preprocess='clahe',\n",
    "        aspect_filter=(1.2, 4.0)  # Wider range for retro logo shape\n",
    "    )\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image5-header",
   "metadata": {},
   "source": [
    "#### 5 coca_retro_2.png\n",
    "\n",
    "La detección se resolvió con SIFT ya que el logotipo aparece rotado, curvado y dentro de un disco circular, condiciones que degradan el desempeño del template matching. SIFT permite identificar características locales invariantes y recuperar la transformación geométrica del emblema con alta estabilidad.\n",
    "\n",
    "**Características:** Póster vintage con emblema circular rojo, texto BLANCO sobre fondo ROJO.  \n",
    "**Problema:** Texto curvado en emblema circular, inversión de contraste.  \n",
    "**Estrategia:** SIFT con template invertido (maneja curvatura y contraste).  \n",
    "**Nota:** SIFT funciona mejor que template matching para logos curvados/distorsionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "detect-coca-retro-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (429, 715)\n",
      "Image: coca_retro_2.png\n",
      "Method: SIFT-inverted(33 matches)\n",
      "Score: 0.330\n",
      "BBox: (61, 187, 162, 63)\n"
     ]
    }
   ],
   "source": [
    "# coca_retro_2.png - Vintage poster with circular badge\n",
    "# Problem: White text on red, curved logo on circular badge\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"coca_retro_2.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT handles curved/distorted logos well\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image6-header",
   "metadata": {},
   "source": [
    "#### 6 COCA-COLA-LOGO.jpg\n",
    "\n",
    "Se empleó SIFT porque el logotipo ocupa una región grande, con gradientes complejos, sombras y un fondo texturizado que altera fuertemente la correlación normalizada. Los descriptores locales permiten detectar el texto independientemente del color y la iluminación, obteniendo una caja bien ajustada mediante homografía.\n",
    "\n",
    "**Características:** Imagen grande (1389x1389), texto BLANCO sobre emblema circular ROJO.  \n",
    "**Problema:** Logo grande, inversión de contraste, fondo complejo (botella, hielo, burbujas).  \n",
    "**Estrategia:** SIFT con template invertido (maneja escala y contraste).  \n",
    "**Nota:** SIFT encuentra ~47 matches, proporcionando detección robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "detect-coca-cola-logo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (1200, 1200)\n",
      "Image: COCA-COLA-LOGO.jpg\n",
      "Method: SIFT-inverted(61 matches)\n",
      "Score: 0.610\n",
      "BBox: (16, 339, 1144, 478)\n"
     ]
    }
   ],
   "source": [
    "# COCA-COLA-LOGO.jpg - Large image with complex background\n",
    "# Problem: White text on red, very large logo\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"COCA-COLA-LOGO.jpg\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT handles large scale differences well\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image7-header",
   "metadata": {},
   "source": [
    "#### 7 logo_1.png\n",
    "\n",
    "Se aplicó template matching con preprocesamiento CLAHE porque la imagen presenta reflejos, variaciones de iluminación y textura sobre el vidrio que dificultan la correlación directa. La ecualización adaptativa y el suavizado previo permiten estabilizar el contraste del logotipo y mejorar la respuesta del método en un entorno visual ruidoso.\n",
    "\n",
    "**Características:** Botellas de vidrio con texto BLANCO sobre etiquetas ROJAS, reflejos, sombras.  \n",
    "**Problema:** Inversión de contraste, variaciones de iluminación, reflejos en el vidrio.  \n",
    "**Estrategia:** Template matching con preprocesamiento (Gaussian blur + CLAHE), fallback a SIFT.  \n",
    "**Escalas:** Derivadas del ratio esperado del logo (~35% del ancho de imagen para tomas cercanas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "detect-logo-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (450, 687)\n",
      "Scale range: 0.42 - 0.84\n",
      "Image: logo_1.png\n",
      "Method: TM-inverted_clahe@0.73\n",
      "Score: 0.426\n",
      "BBox: (np.int64(198), np.int64(191), 292, 127)\n"
     ]
    }
   ],
   "source": [
    "# logo_1.png - Glass bottles with glare and shadows\n",
    "# Problem: White text on red, lighting variations, reflections\n",
    "# Strategy: Try template matching first (with preprocessing), fall back to SIFT\n",
    "img_name = \"logo_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Preprocess: light Gaussian blur + CLAHE to handle reflections\n",
    "img_blur = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img_preprocessed = clahe.apply(img_blur)\n",
    "\n",
    "# Create inverted template variants (white text on red = inverted contrast)\n",
    "template_inv = 255 - template\n",
    "inverted_variants = {\n",
    "    'inverted': template_inv,\n",
    "    'inverted_clahe': preprocess_image(template_inv, 'clahe'),\n",
    "}\n",
    "\n",
    "# First try: Template matching with moderate scale band\n",
    "# Logo is roughly 200-300px wide in 687px image, template is 400px\n",
    "# Scale ~0.5-0.75 expected\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape\n",
    "\n",
    "# Derive scale from expected logo ratio\n",
    "expected_logo_ratio = 0.35  # logo ~35% of image width for close-up bottle shots\n",
    "expected_logo_width = w * expected_logo_ratio\n",
    "center_scale = expected_logo_width / tw\n",
    "scale_min = center_scale * 0.7\n",
    "scale_max = center_scale * 1.4\n",
    "scales = np.linspace(scale_min, scale_max, 20)\n",
    "\n",
    "print(f\"Scale range: {scale_min:.2f} - {scale_max:.2f}\")\n",
    "\n",
    "bbox, score, method = template_match_multiscale(\n",
    "    img_preprocessed, \n",
    "    inverted_variants,\n",
    "    scales=scales,\n",
    "    threshold=0.35,\n",
    "    preprocess=None,  # Already preprocessed\n",
    "    aspect_filter=(1.5, 4.0),\n",
    "    min_width_ratio=0.10\n",
    ")\n",
    "\n",
    "# Fall back to SIFT if template matching fails or score is low\n",
    "if bbox is None or score < 0.40:\n",
    "    print(f\"Template matching {'failed' if bbox is None else f'score too low ({score:.3f})'}, trying SIFT...\")\n",
    "    bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de detecciones:\n",
      "Image                     Method                                 Score         Size\n",
      "--------------------------------------------------------------------------------\n",
      "coca_logo_1.png           TM-edges@0.42                          0.411       167x73\n",
      "coca_logo_2.png           SIFT-inverted(48 matches)              0.480      233x133\n",
      "coca_multi.png            TM-inverted_clahe@0.23                 0.501        93x40\n",
      "coca_retro_1.png          SIFT-normal(45 matches)                0.450      579x206\n",
      "coca_retro_2.png          SIFT-inverted(33 matches)              0.330       162x63\n",
      "COCA-COLA-LOGO.jpg        SIFT-inverted(61 matches)              0.610     1144x478\n",
      "logo_1.png                TM-inverted_clahe@0.73                 0.426      292x127\n",
      "--------------------------------------------------------------------------------\n",
      "Total detected: 7/7\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Resumen de detecciones:\")\n",
    "print(f\"{'Image':<25} {'Method':<35} {'Score':>8} {'Size':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "detected_count = 0\n",
    "for r in results_summary:\n",
    "    img = r['image']\n",
    "    method = r['method'][:33] if len(r['method']) > 33 else r['method']\n",
    "    score = r['score']\n",
    "    bbox = r['bbox']\n",
    "    \n",
    "    if bbox:\n",
    "        size = f\"{bbox[2]}x{bbox[3]}\"\n",
    "        detected_count += 1\n",
    "    else:\n",
    "        size = \"N/A\"\n",
    "    \n",
    "    print(f\"{img:<25} {method:<35} {score:>8.3f} {size:>12}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total detected: {detected_count}/{len(results_summary)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "grid-visualization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/TP3-v2_results.png\n"
     ]
    }
   ],
   "source": [
    "# Final grid visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(results_summary):\n",
    "    img_rgb, _, _ = load_image(f\"images/{r['image']}\")\n",
    "    img_out = draw_detection(img_rgb, r['bbox'])\n",
    "    \n",
    "    axes[idx].imshow(img_out)\n",
    "    axes[idx].set_title(f\"{r['image']}\\nScore: {r['score']:.3f}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(len(results_summary), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Assignment 1: Single Detection per Image', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-v2_results.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: results/TP3-v2_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67498d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2: Detección múltiple por imagen\n",
    "\n",
    "Plantear y validar un algoritmo para múltiples detecciones en la imagen `coca_multi.png` con el mismo template del ítem 1.\n",
    "\n",
    "### Enfoque\n",
    "\n",
    "En `coca_multi` hay muchas botellas alineadas con logos a diferentes escalas según el estante.\n",
    "\n",
    "**Mejoras implementadas para reducir falsos positivos:**\n",
    "\n",
    "1. **Filtro por banda horizontal (y_ranges):** Los logos aparecen solo en franjas específicas de la imagen. Restricción a zonas donde realmente hay etiquetas.\n",
    "\n",
    "2. **Validación de consistencia de color:** Después de cada detección, se verifica que la región sea predominantemente roja (R > 110, R > G+25, R > B+25).\n",
    "\n",
    "3. **Filtros de forma (aspect ratio + height):** Filtro estricto de aspect ratio (2.0–3.8) y altura (28–75px) para rechazar detecciones con proporciones incorrectas.\n",
    "\n",
    "4. **Test de aislamiento de picos:** Rechaza picos de correlación aislados (ruido) verificando que el vecindario local también tenga respuesta alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cf93631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multiple_logos(\n",
    "    img_gray: np.ndarray,\n",
    "    img_rgb: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    scales: np.ndarray,\n",
    "    threshold_sigma: float = 2.5,\n",
    "    min_threshold: float = 0.35,\n",
    "    iou_threshold: float = 0.3,\n",
    "    size_filter: Tuple[int, int] = None,\n",
    "    height_filter: Tuple[int, int] = None,\n",
    "    aspect_filter: Tuple[float, float] = (2.6, 3.8),\n",
    "    y_ranges: List[Tuple[float, float]] = None,\n",
    "    local_max_kernel: int = 7,\n",
    "    peak_isolation_ratio: float = 0.5,\n",
    "    color_check: bool = True,\n",
    "    min_red_dominance: int = 30,\n",
    "    min_red_value: int = 120\n",
    ") -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Multi-detection using template matching with local maxima and validation filters.\n",
    "    \n",
    "    Args:\n",
    "        img_gray: Grayscale image\n",
    "        img_rgb: RGB image (for color validation)\n",
    "        template: Single template (use best variant, e.g., inverted + CLAHE)\n",
    "        scales: Array of scales to test\n",
    "        threshold_sigma: Number of std devs above mean for adaptive threshold\n",
    "        min_threshold: Minimum absolute threshold\n",
    "        iou_threshold: IoU threshold for NMS\n",
    "        size_filter: Optional (min_width, max_width) to filter detections\n",
    "        height_filter: Optional (min_height, max_height) to filter detections\n",
    "        aspect_filter: (min_aspect, max_aspect) for logo shape validation\n",
    "        y_ranges: List of (y_min_ratio, y_max_ratio) for valid detection zones\n",
    "        local_max_kernel: Kernel size for local maxima detection\n",
    "        peak_isolation_ratio: Minimum ratio of neighborhood mean to peak score\n",
    "        color_check: Whether to validate red color dominance\n",
    "        min_red_dominance: Minimum R - max(G, B) for color check\n",
    "        min_red_value: Minimum R channel value for color check\n",
    "    \n",
    "    Returns: List of detections [(x, y, w, h, score), ...]\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    th, tw = template.shape\n",
    "    template_aspect = tw / th\n",
    "    \n",
    "    # Preprocess image\n",
    "    img_processed = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    img_processed = cv.equalizeHist(img_processed)\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        new_w, new_h = int(tw * scale), int(th * scale)\n",
    "        \n",
    "        # Skip invalid sizes\n",
    "        if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "            continue\n",
    "        \n",
    "        # Width filter\n",
    "        if size_filter:\n",
    "            if new_w < size_filter[0] or new_w > size_filter[1]:\n",
    "                continue\n",
    "        \n",
    "        # Height filter\n",
    "        if height_filter:\n",
    "            if new_h < height_filter[0] or new_h > height_filter[1]:\n",
    "                continue\n",
    "        \n",
    "        # Resize template\n",
    "        scaled_tmpl = cv.resize(template, (new_w, new_h))\n",
    "        \n",
    "        # Template matching\n",
    "        res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Adaptive threshold\n",
    "        mean_val, std_val = np.mean(res), np.std(res)\n",
    "        adaptive_thresh = max(mean_val + threshold_sigma * std_val, min_threshold)\n",
    "        \n",
    "        # Find local maxima instead of simple thresholding\n",
    "        kernel = np.ones((local_max_kernel, local_max_kernel), np.uint8)\n",
    "        local_max = cv.dilate(res, kernel)\n",
    "        mask = (res == local_max) & (res >= adaptive_thresh)\n",
    "        \n",
    "        ys, xs = np.where(mask)\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            score = res[y, x]\n",
    "            \n",
    "            # Strict aspect ratio filter\n",
    "            det_aspect = new_w / new_h\n",
    "            if aspect_filter:\n",
    "                if not (aspect_filter[0] <= det_aspect <= aspect_filter[1]):\n",
    "                    continue\n",
    "            elif abs(det_aspect - template_aspect) > 0.5:\n",
    "                continue\n",
    "            \n",
    "            # Y-range filter (horizontal band where labels appear)\n",
    "            if y_ranges:\n",
    "                in_valid_zone = False\n",
    "                for y_min_ratio, y_max_ratio in y_ranges:\n",
    "                    y_min = int(h * y_min_ratio)\n",
    "                    y_max = int(h * y_max_ratio)\n",
    "                    if y_min <= y <= y_max:\n",
    "                        in_valid_zone = True\n",
    "                        break\n",
    "                if not in_valid_zone:\n",
    "                    continue\n",
    "            \n",
    "            # Peak isolation test\n",
    "            # Reject sparse bright noise - keep peaks supported by local neighborhood\n",
    "            y1 = max(0, y - 2)\n",
    "            y2 = min(res.shape[0], y + 3)\n",
    "            x1 = max(0, x - 2)\n",
    "            x2 = min(res.shape[1], x + 3)\n",
    "            window = res[y1:y2, x1:x2]\n",
    "            if window.size > 0 and window.mean() < score * peak_isolation_ratio:\n",
    "                continue\n",
    "            \n",
    "            # Color consistency check (red dominance)\n",
    "            if color_check and img_rgb is not None:\n",
    "                # Sample the bounding box region in RGB\n",
    "                box_y1 = max(0, y)\n",
    "                box_y2 = min(img_rgb.shape[0], y + new_h)\n",
    "                box_x1 = max(0, x)\n",
    "                box_x2 = min(img_rgb.shape[1], x + new_w)\n",
    "                \n",
    "                if box_y2 > box_y1 and box_x2 > box_x1:\n",
    "                    patch = img_rgb[box_y1:box_y2, box_x1:box_x2]\n",
    "                    mean_color = patch.mean(axis=(0, 1))  # R, G, B average\n",
    "                    \n",
    "                    # True Coca-Cola labels: R > 120, R > G + 30, R > B + 30\n",
    "                    r, g, b = mean_color[0], mean_color[1], mean_color[2]\n",
    "                    if not (r > min_red_value and \n",
    "                            r > g + min_red_dominance and \n",
    "                            r > b + min_red_dominance):\n",
    "                        continue\n",
    "            \n",
    "            all_detections.append((x, y, new_w, new_h, score, scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return []\n",
    "    \n",
    "    # Apply NMS\n",
    "    final_detections = nms_global(all_detections, iou_threshold=iou_threshold)\n",
    "    \n",
    "    # Return as (x, y, w, h, score)\n",
    "    return [(d[0], d[1], d[2], d[3], d[4]) for d in final_detections]\n",
    "\n",
    "\n",
    "def draw_multiple_detections(img_rgb: np.ndarray, detections: List[Tuple], \n",
    "                              color=(0, 255, 0), thickness=2, \n",
    "                              show_numbers: bool = True) -> np.ndarray:\n",
    "    \"\"\"Draw multiple bounding boxes on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for i, det in enumerate(detections):\n",
    "        x, y, w, h = int(det[0]), int(det[1]), int(det[2]), int(det[3])\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, thickness)\n",
    "        if show_numbers:\n",
    "            cv.putText(img_out, str(i+1), (x+2, y+h-5), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "t3kx005a3u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 799x598\n",
      "Template size: 400x175\n",
      "Scale range: 0.19 - 0.42\n",
      "Width filter: 72px - 170px\n",
      "Height filter: 28px - 75px\n",
      "Y-ranges (relative): [(0.08, 0.35), (0.68, 0.95)]\n",
      "Aspect ratio filter: (2.0, 3.8)\n",
      "\n",
      "============================================================\n",
      "Detected: 18 logos\n",
      "============================================================\n",
      "Top shelf: 9, Bottom shelf: 9\n",
      "\n",
      "   1. [Bottom] pos=( 72, 422), size=89x39, score=0.437\n",
      "   2. [Bottom] pos=(564, 428), size=89x39, score=0.436\n",
      "   3. [Bottom] pos=(487, 424), size=89x39, score=0.432\n",
      "   4. [Bottom] pos=(405, 430), size=89x39, score=0.432\n",
      "   5. [Bottom] pos=(303, 429), size=95x41, score=0.426\n",
      "   6. [Top   ] pos=( 29, 147), size=89x39, score=0.425\n",
      "   7. [Top   ] pos=(276, 147), size=89x39, score=0.425\n",
      "   8. [Bottom] pos=(148, 428), size=89x39, score=0.419\n",
      "   9. [Bottom] pos=(234, 429), size=89x39, score=0.416\n",
      "  10. [Top   ] pos=(109, 151), size=89x39, score=0.409\n",
      "  11. [Bottom] pos=(  0, 419), size=82x36, score=0.402\n",
      "  12. [Bottom] pos=(655, 429), size=76x33, score=0.400\n",
      "  13. [Top   ] pos=(707, 155), size=76x33, score=0.397\n",
      "  14. [Top   ] pos=(201, 153), size=82x36, score=0.396\n",
      "  15. [Top   ] pos=(444, 150), size=89x39, score=0.383\n",
      "  16. [Top   ] pos=(543, 157), size=76x33, score=0.383\n",
      "  17. [Top   ] pos=(368, 149), size=82x36, score=0.376\n",
      "  18. [Top   ] pos=(625, 154), size=76x33, score=0.373\n",
      "\n",
      "Saved: results/TP3-v2_assignment2.png\n"
     ]
    }
   ],
   "source": [
    "# Assignment 2: Multi-detection en coca_multi.png\n",
    "\n",
    "img_name = \"coca_multi.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape\n",
    "\n",
    "print(f\"Image size: {w}x{h}\")\n",
    "print(f\"Template size: {tw}x{th}\")\n",
    "\n",
    "# Create single best template: inverted + CLAHE\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "template_inv_clahe = clahe.apply(255 - template)\n",
    "\n",
    "# Scale range for expected logo sizes\n",
    "scale_min = 0.19  # ~76px\n",
    "scale_max = 0.42  # ~168px\n",
    "scales = np.linspace(scale_min, scale_max, 15)\n",
    "print(f\"Scale range: {scale_min:.2f} - {scale_max:.2f}\")\n",
    "\n",
    "# Strict size filters (width and height)\n",
    "w_min, w_max = 72, 170\n",
    "h_min, h_max = 28, 75\n",
    "print(f\"Width filter: {w_min}px - {w_max}px\")\n",
    "print(f\"Height filter: {h_min}px - {h_max}px\")\n",
    "\n",
    "# Precise y_ranges for label horizontal bands\n",
    "y_ranges = [\n",
    "    (0.08, 0.35),  # Top shelf\n",
    "    (0.68, 0.95),  # Bottom shelf\n",
    "]\n",
    "print(f\"Y-ranges (relative): {y_ranges}\")\n",
    "\n",
    "# Strict aspect ratio filter\n",
    "aspect_filter = (2.0, 3.8)\n",
    "print(f\"Aspect ratio filter: {aspect_filter}\")\n",
    "\n",
    "# Detect multiple logos\n",
    "detections = detect_multiple_logos(\n",
    "    img_gray,\n",
    "    img_rgb,                      # Pass RGB for color check\n",
    "    template_inv_clahe,\n",
    "    scales=scales,\n",
    "    threshold_sigma=2.5,\n",
    "    min_threshold=0.34,\n",
    "    iou_threshold=0.20,\n",
    "    size_filter=(w_min, w_max),\n",
    "    height_filter=(h_min, h_max), # Height filter\n",
    "    aspect_filter=aspect_filter,  # Strict aspect ratio filter\n",
    "    y_ranges=y_ranges,            # Horizontal band filter\n",
    "    local_max_kernel=11,\n",
    "    peak_isolation_ratio=0.5,     # Peak isolation test\n",
    "    color_check=True,             # Red color validation\n",
    "    min_red_dominance=25,         # R must be > G+25 and > B+25\n",
    "    min_red_value=110             # R must be > 110\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Detected: {len(detections)} logos\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Count by shelf\n",
    "top_count = sum(1 for d in detections if d[1] < h * 0.5)\n",
    "bottom_count = len(detections) - top_count\n",
    "print(f\"Top shelf: {top_count}, Bottom shelf: {bottom_count}\\n\")\n",
    "\n",
    "for i, det in enumerate(detections):\n",
    "    x, y, bw, bh, score = det\n",
    "    shelf = \"Top\" if y < h * 0.5 else \"Bottom\"\n",
    "    print(f\"  {i+1:2d}. [{shelf:6s}] pos=({x:3d}, {y:3d}), size={bw}x{bh}, score={score:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "img_out = draw_multiple_detections(img_rgb, detections, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(img_out)\n",
    "plt.title(f\"Assignment 2: {len(detections)} logos detected\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-v2_assignment2.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: results/TP3-v2_assignment2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c8138",
   "metadata": {},
   "source": [
    "---\n",
    "## 3: Generalización del algoritmo\n",
    "\n",
    "Generalizar el algoritmo del ítem 2 para todas las imágenes.\n",
    "\n",
    "### Enfoque: Meta-Detector con Fusión de Detectores\n",
    "\n",
    "En lugar de un único detector, implementamos un **meta-detector** que:\n",
    "\n",
    "1. **Ejecuta múltiples detectores especializados:**\n",
    "   - Template Matching (single) - bueno para fondos limpios\n",
    "   - Template Matching con bordes - robusto a inversión de contraste\n",
    "   - SIFT (single) - bueno para logos curvados/rotados/retro\n",
    "   - Multi-detection - para imágenes con múltiples logos\n",
    "\n",
    "2. **Normaliza las puntuaciones** a rango [0, 1] para comparación justa:\n",
    "   - TM: `norm = clip((max_val - 0.2) / 0.5, 0, 1)`\n",
    "   - SIFT: `norm = min(1.0, num_inliers / 25)`\n",
    "   - Multi: `norm = 0.6 * norm_TM + 0.4 * min(1.0, num / 10)`\n",
    "\n",
    "3. **Selecciona el mejor resultado** con lógica de meta-decisión:\n",
    "   - Single mode: Si SIFT_norm > TM_norm + 0.15 → elegir SIFT\n",
    "   - Auto mode: Si multi_tm ≥ 5 detecciones AND norm > 0.5 → elegir multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52e648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-Detector: Unified Logo Detection Framework\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "@dataclass\n",
    "class DetectionResult:\n",
    "    \"\"\"Standardized detection result from any detector.\"\"\"\n",
    "    method: str           # \"single_tm\", \"edge_tm\", \"sift_single\", \"multi_tm\"\n",
    "    bboxes: List[Tuple]   # [(x, y, w, h), ...]\n",
    "    raw_score: float      # Native score from detector\n",
    "    norm_score: float     # Normalized score [0, 1] for comparison\n",
    "    num: int              # Number of detections\n",
    "    details: str = \"\"     # Additional info\n",
    "\n",
    "\n",
    "class UnifiedLogoDetector:\n",
    "    \"\"\"\n",
    "    Meta-detector that runs multiple specialized detectors and selects the best result.\n",
    "    \n",
    "    Score Normalization Strategy:\n",
    "    - TM scores: norm = clip((max_val - 0.2) / 0.5, 0, 1)\n",
    "    - SIFT scores: norm = min(1.0, num_inliers / 25)\n",
    "    - Multi scores: norm = 0.6 * mean(TM_scores) + 0.4 * min(1.0, num_detections / 10)\n",
    "    \n",
    "    Modes:\n",
    "        - \"single\": Assignment 1 - returns best single detection\n",
    "        - \"multi\": Assignment 2 - returns all detections from multi_tm\n",
    "        - \"auto\": Automatically choose based on multi_tm count\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, template: np.ndarray):\n",
    "        self.template = template\n",
    "        self.th, self.tw = template.shape\n",
    "        \n",
    "        # Create template variants\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        self.template_clahe = clahe.apply(template)\n",
    "        self.template_inv = 255 - template\n",
    "        self.template_inv_clahe = clahe.apply(self.template_inv)\n",
    "        \n",
    "        # SIFT configuration\n",
    "        self.sift = cv.SIFT_create(nfeatures=2000)\n",
    "        self.sift_min_matches = 8\n",
    "        \n",
    "    def _normalize_tm_score(self, max_val: float) -> float:\n",
    "        \"\"\"Normalize TM score to [0, 1] range.\"\"\"\n",
    "        return np.clip((max_val - 0.2) / 0.5, 0.0, 1.0)\n",
    "    \n",
    "    def _normalize_sift_score(self, num_inliers: int) -> float:\n",
    "        \"\"\"Normalize SIFT score to [0, 1] range.\"\"\"\n",
    "        return min(1.0, num_inliers / 25.0)\n",
    "    \n",
    "    def _normalize_multi_score(self, mean_tm_score: float, num_detections: int) -> float:\n",
    "        \"\"\"Normalize multi-detection score to [0, 1] range.\"\"\"\n",
    "        tm_component = self._normalize_tm_score(mean_tm_score)\n",
    "        count_component = min(1.0, num_detections / 10.0)\n",
    "        return 0.6 * tm_component + 0.4 * count_component\n",
    "    \n",
    "    def run_single_tm(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        \"\"\"Single-logo template matching with multiple variants.\"\"\"\n",
    "        h, w = img_gray.shape\n",
    "        \n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_proc = clahe.apply(cv.GaussianBlur(img_gray, (3, 3), 0))\n",
    "        \n",
    "        scale_min = (w * 0.08) / self.tw\n",
    "        scale_max = (w * 0.60) / self.tw\n",
    "        scales = np.linspace(max(0.1, scale_min), min(2.0, scale_max), 25)\n",
    "        \n",
    "        best_result = None\n",
    "        best_score = -1.0\n",
    "        \n",
    "        templates = [('normal', self.template_clahe), ('inverted', self.template_inv_clahe)]\n",
    "        \n",
    "        for tmpl_name, tmpl in templates:\n",
    "            for scale in scales:\n",
    "                new_w, new_h = int(self.tw * scale), int(self.th * scale)\n",
    "                if new_w >= w or new_h >= h or new_w < 30 or new_h < 15:\n",
    "                    continue\n",
    "                \n",
    "                scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n",
    "                res = cv.matchTemplate(img_proc, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "                _, max_val, _, max_loc = cv.minMaxLoc(res)\n",
    "                \n",
    "                aspect = new_w / new_h\n",
    "                if not (1.5 < aspect < 4.5):\n",
    "                    continue\n",
    "                \n",
    "                if max_val > best_score and max_val > 0.25:\n",
    "                    best_score = max_val\n",
    "                    best_result = {'bbox': (max_loc[0], max_loc[1], new_w, new_h),\n",
    "                                   'raw_score': max_val,\n",
    "                                   'scale': scale, 'variant': tmpl_name}\n",
    "        \n",
    "        if best_result is None:\n",
    "            return DetectionResult(\"single_tm\", [], 0.0, 0.0, 0, \"No detection\")\n",
    "        \n",
    "        norm_score = self._normalize_tm_score(best_result['raw_score'])\n",
    "        \n",
    "        return DetectionResult(\"single_tm\", [best_result['bbox']], best_result['raw_score'],\n",
    "                              norm_score, 1, \n",
    "                              f\"{best_result['variant']}@{best_result['scale']:.2f}\")\n",
    "    \n",
    "    def run_edge_tm(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        \"\"\"Edge-based template matching - robust to contrast inversion.\"\"\"\n",
    "        h, w = img_gray.shape\n",
    "        \n",
    "        template_edges = cv.Canny(self.template, 50, 150)\n",
    "        img_edges = cv.Canny(img_gray, 50, 150)\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        template_edges = cv.dilate(template_edges, kernel, iterations=1)\n",
    "        img_edges = cv.dilate(img_edges, kernel, iterations=1)\n",
    "        \n",
    "        scale_min = (w * 0.08) / self.tw\n",
    "        scale_max = (w * 0.60) / self.tw\n",
    "        scales = np.linspace(max(0.1, scale_min), min(2.0, scale_max), 25)\n",
    "        \n",
    "        best_result = None\n",
    "        best_score = -1.0\n",
    "        \n",
    "        for scale in scales:\n",
    "            new_w, new_h = int(self.tw * scale), int(self.th * scale)\n",
    "            if new_w >= w or new_h >= h or new_w < 30:\n",
    "                continue\n",
    "            \n",
    "            scaled_edges = cv.resize(template_edges, (new_w, new_h))\n",
    "            res = cv.matchTemplate(img_edges, scaled_edges, cv.TM_CCOEFF_NORMED)\n",
    "            _, max_val, _, max_loc = cv.minMaxLoc(res)\n",
    "            \n",
    "            if max_val > best_score and max_val > 0.20:\n",
    "                best_score = max_val\n",
    "                best_result = {'bbox': (max_loc[0], max_loc[1], new_w, new_h),\n",
    "                               'raw_score': max_val, 'scale': scale}\n",
    "        \n",
    "        if best_result is None:\n",
    "            return DetectionResult(\"edge_tm\", [], 0.0, 0.0, 0, \"No detection\")\n",
    "        \n",
    "        norm_score = self._normalize_tm_score(best_result['raw_score'])\n",
    "        \n",
    "        return DetectionResult(\"edge_tm\", [best_result['bbox']], best_result['raw_score'],\n",
    "                              norm_score, 1, f\"edges@{best_result['scale']:.2f}\")\n",
    "    \n",
    "    def run_sift_single(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        \"\"\"SIFT-based detection with homography.\"\"\"\n",
    "        img_h, img_w = img_gray.shape\n",
    "        img_area = img_h * img_w\n",
    "        \n",
    "        kp2, des2 = self.sift.detectAndCompute(img_gray, None)\n",
    "        if des2 is None or len(des2) < self.sift_min_matches:\n",
    "            return DetectionResult(\"sift_single\", [], 0.0, 0.0, 0, \"Insufficient features\")\n",
    "        \n",
    "        best_result = None\n",
    "        \n",
    "        for tmpl_name, tmpl in [('normal', self.template), ('inverted', self.template_inv)]:\n",
    "            kp1, des1 = self.sift.detectAndCompute(tmpl, None)\n",
    "            if des1 is None or len(des1) < 4:\n",
    "                continue\n",
    "            \n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "            flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "            matches = flann.knnMatch(des1, des2, k=2)\n",
    "            \n",
    "            good = [m for match in matches if len(match) == 2 \n",
    "                    for m, n in [match] if m.distance < 0.75 * n.distance]\n",
    "            \n",
    "            if len(good) < self.sift_min_matches:\n",
    "                continue\n",
    "            \n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            \n",
    "            M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
    "            if M is None:\n",
    "                continue\n",
    "            \n",
    "            num_inliers = mask.ravel().sum() if mask is not None else len(good)\n",
    "            \n",
    "            th, tw = tmpl.shape\n",
    "            pts = np.float32([[0,0], [0,th-1], [tw-1,th-1], [tw-1,0]]).reshape(-1,1,2)\n",
    "            dst = cv.perspectiveTransform(pts, M)\n",
    "            x, y, bw, bh = cv.boundingRect(dst)\n",
    "            \n",
    "            x, y = max(0, x), max(0, y)\n",
    "            bw = min(bw, img_w - x)\n",
    "            bh = min(bh, img_h - y)\n",
    "            \n",
    "            bbox_area = bw * bh\n",
    "            if bbox_area < img_area * 0.01 or bbox_area > img_area * 0.95:\n",
    "                continue\n",
    "            if bw < 20 or bh < 10 or bw / bh > 10 or bh / bw > 5:\n",
    "                continue\n",
    "            \n",
    "            if best_result is None or num_inliers > best_result['num_inliers']:\n",
    "                best_result = {'bbox': (x, y, bw, bh), 'num_inliers': num_inliers,\n",
    "                               'num_matches': len(good), 'variant': tmpl_name}\n",
    "        \n",
    "        if best_result is None:\n",
    "            return DetectionResult(\"sift_single\", [], 0.0, 0.0, 0, \"No valid homography\")\n",
    "        \n",
    "        norm_score = self._normalize_sift_score(best_result['num_inliers'])\n",
    "        raw_score = best_result['num_inliers']\n",
    "        \n",
    "        return DetectionResult(\"sift_single\", [best_result['bbox']], \n",
    "                              raw_score, norm_score, 1,\n",
    "                              f\"{best_result['variant']}({best_result['num_inliers']} inliers)\")\n",
    "    \n",
    "    def run_multi_tm(self, img_gray: np.ndarray, img_rgb: np.ndarray) -> DetectionResult:\n",
    "        \"\"\"Multi-logo detection using template matching with color validation.\"\"\"\n",
    "        h, w = img_gray.shape\n",
    "        template = self.template_inv_clahe\n",
    "        img_proc = cv.equalizeHist(cv.GaussianBlur(img_gray, (3, 3), 0))\n",
    "        \n",
    "        # Use relative size filters based on image dimensions\n",
    "        # Logo width typically 8% - 30% of image width\n",
    "        min_logo_w = int(w * 0.08)\n",
    "        max_logo_w = int(w * 0.35)\n",
    "        min_logo_h = int(h * 0.04)\n",
    "        max_logo_h = int(h * 0.20)\n",
    "        \n",
    "        # Scale range based on image size\n",
    "        scale_min = max(0.10, min_logo_w / self.tw)\n",
    "        scale_max = min(0.60, max_logo_w / self.tw)\n",
    "        scales = np.linspace(scale_min, scale_max, 20)\n",
    "        \n",
    "        all_detections = []\n",
    "        \n",
    "        for scale in scales:\n",
    "            new_w, new_h = int(self.tw * scale), int(self.th * scale)\n",
    "            if new_w >= w or new_h >= h or new_w < 40 or new_h < 15:\n",
    "                continue\n",
    "            \n",
    "            # Relative size filter\n",
    "            if not (min_logo_w <= new_w <= max_logo_w):\n",
    "                continue\n",
    "            if not (min_logo_h <= new_h <= max_logo_h):\n",
    "                continue\n",
    "            \n",
    "            scaled_tmpl = cv.resize(template, (new_w, new_h))\n",
    "            res = cv.matchTemplate(img_proc, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            mean_val, std_val = np.mean(res), np.std(res)\n",
    "            adaptive_thresh = max(mean_val + 2.5 * std_val, 0.30)\n",
    "            \n",
    "            kernel = np.ones((11, 11), np.uint8)\n",
    "            local_max = cv.dilate(res, kernel)\n",
    "            mask = (res == local_max) & (res >= adaptive_thresh)\n",
    "            \n",
    "            ys, xs = np.where(mask)\n",
    "            \n",
    "            for x, y in zip(xs, ys):\n",
    "                score = res[y, x]\n",
    "                det_aspect = new_w / new_h\n",
    "                if not (1.8 <= det_aspect <= 4.0):\n",
    "                    continue\n",
    "                \n",
    "                # Peak isolation test\n",
    "                y1, y2 = max(0, y - 2), min(res.shape[0], y + 3)\n",
    "                x1, x2 = max(0, x - 2), min(res.shape[1], x + 3)\n",
    "                window = res[y1:y2, x1:x2]\n",
    "                if window.size > 0 and window.mean() < score * 0.5:\n",
    "                    continue\n",
    "                \n",
    "                # Color check (red dominance)\n",
    "                box_y1, box_y2 = max(0, y), min(h, y + new_h)\n",
    "                box_x1, box_x2 = max(0, x), min(w, x + new_w)\n",
    "                if box_y2 > box_y1 and box_x2 > box_x1:\n",
    "                    patch = img_rgb[box_y1:box_y2, box_x1:box_x2]\n",
    "                    r, g, b = patch.mean(axis=(0, 1))\n",
    "                    if not (r > 100 and r > g + 20 and r > b + 20):\n",
    "                        continue\n",
    "                \n",
    "                all_detections.append((x, y, new_w, new_h, score, scale))\n",
    "        \n",
    "        if not all_detections:\n",
    "            return DetectionResult(\"multi_tm\", [], 0.0, 0.0, 0, \"No detections\")\n",
    "        \n",
    "        final = nms_global(all_detections, iou_threshold=0.25)\n",
    "        \n",
    "        if final:\n",
    "            mean_score = np.mean([d[4] for d in final])\n",
    "            norm_score = self._normalize_multi_score(mean_score, len(final))\n",
    "        else:\n",
    "            mean_score = 0.0\n",
    "            norm_score = 0.0\n",
    "        \n",
    "        bboxes = [(d[0], d[1], d[2], d[3]) for d in final]\n",
    "        \n",
    "        return DetectionResult(\"multi_tm\", bboxes, mean_score, norm_score, \n",
    "                              len(final), f\"{len(final)} logos, avg={mean_score:.3f}\")\n",
    "    \n",
    "    def detect(self, img_rgb: np.ndarray, img_gray: np.ndarray,\n",
    "               mode: str = \"single\") -> Dict:\n",
    "        \"\"\"\n",
    "        Run detectors and select the best result based on mode.\n",
    "        \n",
    "        Selection Rules:\n",
    "        - SINGLE MODE: If SIFT_norm > TM_norm + 0.15 → choose SIFT, else TM\n",
    "        - AUTO MODE: If multi_tm >= 5 AND norm > 0.5 → choose multi, else single rules\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        results['single_tm'] = self.run_single_tm(img_gray)\n",
    "        results['edge_tm'] = self.run_edge_tm(img_gray)\n",
    "        results['sift_single'] = self.run_sift_single(img_gray)\n",
    "        \n",
    "        if mode in ['multi', 'auto']:\n",
    "            results['multi_tm'] = self.run_multi_tm(img_gray, img_rgb)\n",
    "        else:\n",
    "            results['multi_tm'] = DetectionResult(\"multi_tm\", [], 0.0, 0.0, 0, \"Skipped\")\n",
    "        \n",
    "        print(\"Detector Results:\")\n",
    "        for name, r in results.items():\n",
    "            print(f\"  {name:12s}: num={r.num:2d}, norm={r.norm_score:.3f}, \"\n",
    "                  f\"raw={r.raw_score:.3f}, {r.details}\")\n",
    "        \n",
    "        # META-DECISION LOGIC\n",
    "        if mode == \"multi\":\n",
    "            best = results['multi_tm']\n",
    "            reason = \"Mode=multi\"\n",
    "        elif mode == \"single\":\n",
    "            sift = results['sift_single']\n",
    "            tm_results = [results['single_tm'], results['edge_tm']]\n",
    "            best_tm = max(tm_results, key=lambda r: r.norm_score if r.num > 0 else 0)\n",
    "            \n",
    "            if sift.num > 0 and sift.norm_score > best_tm.norm_score + 0.15:\n",
    "                best = sift\n",
    "                reason = f\"SIFT ({sift.raw_score:.0f} inliers, norm={sift.norm_score:.2f})\"\n",
    "            elif best_tm.num > 0:\n",
    "                best = best_tm\n",
    "                reason = f\"Best TM (norm={best_tm.norm_score:.2f})\"\n",
    "            elif sift.num > 0:\n",
    "                best = sift\n",
    "                reason = \"SIFT fallback\"\n",
    "            else:\n",
    "                best = results['single_tm']\n",
    "                reason = \"No valid detection\"\n",
    "        else:  # auto\n",
    "            multi = results['multi_tm']\n",
    "            if multi.num >= 5 and multi.norm_score > 0.5:\n",
    "                best = multi\n",
    "                reason = f\"Auto: Multi found {multi.num} logos (norm={multi.norm_score:.2f})\"\n",
    "            else:\n",
    "                sift = results['sift_single']\n",
    "                tm_results = [results['single_tm'], results['edge_tm']]\n",
    "                best_tm = max(tm_results, key=lambda r: r.norm_score if r.num > 0 else 0)\n",
    "                \n",
    "                if sift.num > 0 and sift.norm_score > best_tm.norm_score + 0.15:\n",
    "                    best = sift\n",
    "                    reason = f\"Auto: SIFT ({sift.raw_score:.0f} inliers)\"\n",
    "                elif best_tm.num > 0:\n",
    "                    best = best_tm\n",
    "                    reason = f\"Auto: Best TM (norm={best_tm.norm_score:.2f})\"\n",
    "                else:\n",
    "                    best = sift if sift.num > 0 else results['single_tm']\n",
    "                    reason = \"Auto: Fallback\"\n",
    "        \n",
    "        print(f\"\\nSelected: {best.method} - {reason}\")\n",
    "        \n",
    "        return {'best': best, 'all_results': results, 'reason': reason}\n",
    "\n",
    "\n",
    "def draw_result(img_rgb: np.ndarray, result: DetectionResult, \n",
    "                color=(0, 255, 0), thickness=2) -> np.ndarray:\n",
    "    \"\"\"Draw detection result on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for i, bbox in enumerate(result.bboxes):\n",
    "        x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, thickness)\n",
    "        if result.num > 1:\n",
    "            cv.putText(img_out, str(i+1), (x+2, y+h-5), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "uoxhi3w6lr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE DETECTION MODE\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_logo_1.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.511, raw=0.456, inverted@0.10\n",
      "  edge_tm     : num= 1, norm=0.165, raw=0.282, edges@0.12\n",
      "  sift_single : num= 1, norm=1.000, raw=42.000, inverted(42 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (42 inliers, norm=1.00)\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_logo_2.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.515, raw=0.457, inverted@0.10\n",
      "  edge_tm     : num= 1, norm=0.251, raw=0.326, edges@0.10\n",
      "  sift_single : num= 1, norm=1.000, raw=29.000, inverted(29 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (29 inliers, norm=1.00)\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_multi.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.563, raw=0.482, inverted@0.33\n",
      "  edge_tm     : num= 1, norm=0.116, raw=0.258, edges@0.25\n",
      "  sift_single : num= 1, norm=0.240, raw=6.000, inverted(6 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: single_tm - Best TM (norm=0.56)\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_retro_1.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.560, raw=0.480, normal@0.14\n",
      "  edge_tm     : num= 1, norm=0.169, raw=0.284, edges@0.14\n",
      "  sift_single : num= 1, norm=0.720, raw=18.000, normal(18 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (18 inliers, norm=0.72)\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_retro_2.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.922, raw=0.661, inverted@0.38\n",
      "  edge_tm     : num= 1, norm=0.296, raw=0.348, edges@0.38\n",
      "  sift_single : num= 1, norm=1.000, raw=30.000, inverted(30 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: single_tm - Best TM (norm=0.92)\n",
      "\n",
      "======================================================================\n",
      "Processing: COCA-COLA-LOGO.jpg\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.456, raw=0.428, inverted@0.30\n",
      "  edge_tm     : num= 0, norm=0.000, raw=0.000, No detection\n",
      "  sift_single : num= 1, norm=1.000, raw=26.000, inverted(26 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (26 inliers, norm=1.00)\n",
      "\n",
      "======================================================================\n",
      "Processing: logo_1.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.596, raw=0.498, inverted@0.73\n",
      "  edge_tm     : num= 1, norm=0.109, raw=0.254, edges@0.14\n",
      "  sift_single : num= 1, norm=1.000, raw=32.000, inverted(32 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (32 inliers, norm=1.00)\n",
      "\n",
      "================================================================================\n",
      "SINGLE DETECTION - SUMMARY\n",
      "================================================================================\n",
      "Image                     Method              norm Details                       \n",
      "--------------------------------------------------------------------------------\n",
      "coca_logo_1.png           sift_single        1.000 inverted(42 inliers)          \n",
      "coca_logo_2.png           sift_single        1.000 inverted(29 inliers)          \n",
      "coca_multi.png            single_tm          0.563 inverted@0.33                 \n",
      "coca_retro_1.png          sift_single        0.720 normal(18 inliers)            \n",
      "coca_retro_2.png          single_tm          0.922 inverted@0.38                 \n",
      "COCA-COLA-LOGO.jpg        sift_single        1.000 inverted(26 inliers)          \n",
      "logo_1.png                sift_single        1.000 inverted(32 inliers)          \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Single Detection Mode (all images)\n",
    "\n",
    "# Initialize the unified detector\n",
    "detector = UnifiedLogoDetector(template)\n",
    "\n",
    "# Test images\n",
    "test_images = [\n",
    "    \"coca_logo_1.png\",\n",
    "    \"coca_logo_2.png\",\n",
    "    \"coca_multi.png\",\n",
    "    \"coca_retro_1.png\",\n",
    "    \"coca_retro_2.png\",\n",
    "    \"COCA-COLA-LOGO.jpg\",\n",
    "    \"logo_1.png\"\n",
    "]\n",
    "\n",
    "# Run single detection on all images\n",
    "print(\"SINGLE DETECTION MODE\")\n",
    "\n",
    "unified_results = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing: {img_name}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "    \n",
    "    # Run unified detector in single mode\n",
    "    result = detector.detect(img_rgb, img_gray, mode=\"single\")\n",
    "    \n",
    "    unified_results.append({\n",
    "        'image': img_name,\n",
    "        'result': result['best'],\n",
    "        'reason': result['reason'],\n",
    "        'all_results': result['all_results']\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SINGLE DETECTION - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Image':<25} {'Method':<15} {'norm':>8} {'Details':<30}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for r in unified_results:\n",
    "    img = r['image']\n",
    "    best = r['result']\n",
    "    print(f\"{img:<25} {best.method:<15} {best.norm_score:>8.3f} {best.details:<30}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7vk51qkvs3m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/TP3-v2_assignment3_single.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize Single Detection Results\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(unified_results):\n",
    "    img_rgb, _, _ = load_image(f\"images/{r['image']}\")\n",
    "    img_out = draw_result(img_rgb, r['result'])\n",
    "    \n",
    "    axes[idx].imshow(img_out)\n",
    "    \n",
    "    best = r['result']\n",
    "    title = f\"{r['image']}\\n{best.method} | norm={best.norm_score:.2f}\"\n",
    "    axes[idx].set_title(title, fontsize=9)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(len(unified_results), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Unified Meta-Detector - Single Detection Mode', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-v2_assignment3_single.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: results/TP3-v2_assignment3_single.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sa44gx4y7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI DETECTION MODE\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_multi.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.563, raw=0.482, inverted@0.33\n",
      "  edge_tm     : num= 1, norm=0.116, raw=0.258, edges@0.25\n",
      "  sift_single : num= 1, norm=0.240, raw=6.000, inverted(6 inliers)\n",
      "  multi_tm    : num=18, norm=0.640, raw=0.400, 18 logos, avg=0.400\n",
      "\n",
      "Selected: multi_tm - Mode=multi\n",
      "\n",
      "Multi-detection found 18 logos\n",
      "Average TM score: 0.400\n",
      "Normalized score: 0.640\n",
      "\n",
      "======================================================================\n",
      "Processing: coca_retro_2.png\n",
      "======================================================================\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.922, raw=0.661, inverted@0.38\n",
      "  edge_tm     : num= 1, norm=0.296, raw=0.348, edges@0.38\n",
      "  sift_single : num= 1, norm=1.000, raw=28.000, inverted(28 inliers)\n",
      "  multi_tm    : num= 7, norm=0.508, raw=0.390, 7 logos, avg=0.390\n",
      "\n",
      "Selected: multi_tm - Mode=multi\n",
      "\n",
      "Multi-detection found 7 logos\n",
      "Average TM score: 0.390\n",
      "Normalized score: 0.508\n",
      "\n",
      "Saved: results/TP3-v2_assignment3_multi.png\n"
     ]
    }
   ],
   "source": [
    "# Multi Detection Mode (coca_multi.png + coca_retro_2.png)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI DETECTION MODE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test images with multiple logos\n",
    "multi_test_images = [\n",
    "    \"coca_multi.png\",      # Shelf with many bottles\n",
    "    \"coca_retro_2.png\"     # Poster with logo on circular badge + logo on glass\n",
    "]\n",
    "\n",
    "multi_results = []\n",
    "\n",
    "for img_name in multi_test_images:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing: {img_name}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "    \n",
    "    # Run unified detector in multi mode\n",
    "    result = detector.detect(img_rgb, img_gray, mode=\"multi\")\n",
    "    multi_result = result['best']\n",
    "    \n",
    "    multi_results.append({\n",
    "        'image': img_name,\n",
    "        'result': multi_result,\n",
    "        'img_rgb': img_rgb\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nMulti-detection found {multi_result.num} logos\")\n",
    "    print(f\"Average TM score: {multi_result.raw_score:.3f}\")\n",
    "    print(f\"Normalized score: {multi_result.norm_score:.3f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "for idx, r in enumerate(multi_results):\n",
    "    img_out = draw_result(r['img_rgb'], r['result'])\n",
    "    axes[idx].imshow(img_out)\n",
    "    axes[idx].set_title(f\"{r['image']}\\n{r['result'].num} logos detected | norm={r['result'].norm_score:.2f}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Test 3.2: Unified Meta-Detector - Multi Detection Mode', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-v2_assignment3_multi.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: results/TP3-v2_assignment3_multi.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
