{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TP3: Detección del logo de Coca-Cola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea463079",
   "metadata": {},
   "source": [
    "## 1: Detección única por imagen\n",
    "\n",
    "Encontrar el logotipo de la gaseosa dentro de las imágenes provistas.\n",
    "\n",
    "### Estrategia\n",
    "\n",
    "Para cada imagen se selecciona el método más adecuado según sus características:\n",
    "\n",
    "| Imagen | Método | Justificación |\n",
    "|--------|--------|---------------|\n",
    "| coca_logo_1.png | Edge TM | Fondo limpio, bordes preservados tras Canny |\n",
    "| coca_logo_2.png | SIFT | Superficie curva, distorsión de perspectiva |\n",
    "| coca_multi.png | TM invertido | Múltiples logos, contraste invertido |\n",
    "| coca_retro_1.png | SIFT | Logo retro estructuralmente diferente |\n",
    "| coca_retro_2.png | SIFT | Logo curvado en emblema circular |\n",
    "| COCA-COLA-LOGO.jpg | SIFT | Logo grande, fondo complejo |\n",
    "| logo_1.png | TM invertido | Reflejos en vidrio, variaciones de iluminación |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utilities-header",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str, max_size: int = 1200) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path: str, max_size: int = 400) -> np.ndarray:\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    if template is None:\n",
    "        raise FileNotFoundError(f\"Template not found: {path}\")\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "def preprocess_image(img_gray: np.ndarray, method: str = 'clahe') -> np.ndarray:\n",
    "    \"\"\"Apply preprocessing to grayscale image.\"\"\"\n",
    "    if method == 'clahe':\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(img_gray)\n",
    "    elif method == 'smooth':\n",
    "        return cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    elif method == 'equalize':\n",
    "        return cv.equalizeHist(img_gray)\n",
    "    elif method == 'clahe_smooth':\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return cv.GaussianBlur(clahe.apply(img_gray), (3, 3), 0)\n",
    "    return img_gray\n",
    "\n",
    "\n",
    "def create_template_variants(template: np.ndarray, include_inverted: bool = False) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Create template variants for matching.\"\"\"\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    variants = {'normal': template, 'clahe': clahe.apply(template)}\n",
    "    if include_inverted:\n",
    "        template_inv = 255 - template\n",
    "        variants['inverted'] = template_inv\n",
    "        variants['inverted_clahe'] = clahe.apply(template_inv)\n",
    "    return variants\n",
    "\n",
    "\n",
    "def rotate_template(template: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"Rotate template by given angle (degrees).\"\"\"\n",
    "    h, w = template.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "    cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])\n",
    "    new_w, new_h = int(h * sin + w * cos), int(h * cos + w * sin)\n",
    "    M[0, 2] += (new_w - w) / 2\n",
    "    M[1, 2] += (new_h - h) / 2\n",
    "    return cv.warpAffine(template, M, (new_w, new_h), borderValue=255)\n",
    "\n",
    "\n",
    "def compute_scale_range(\n",
    "    img_width: int, template_width: int,\n",
    "    width_ratio_min: float = 0.10, width_ratio_max: float = 0.80,\n",
    "    num_scales: int = 25, scale_bounds: Tuple[float, float] = (0.10, 2.0)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute scale range for template matching based on expected logo size ratios.\"\"\"\n",
    "    scale_min = max(scale_bounds[0], (img_width * width_ratio_min) / template_width)\n",
    "    scale_max = min(scale_bounds[1], (img_width * width_ratio_max) / template_width)\n",
    "    return np.linspace(scale_min, scale_max, num_scales)\n",
    "\n",
    "\n",
    "def compute_iou(box1: Tuple, box2: Tuple) -> float:\n",
    "    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n",
    "    x1, y1, w1, h1 = box1[:4]\n",
    "    x2, y2, w2, h2 = box2[:4]\n",
    "    xi1, yi1 = max(x1, x2), max(y1, y2)\n",
    "    xi2, yi2 = min(x1 + w1, x2 + w2), min(y1 + h1, y2 + h2)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    union_area = w1 * h1 + w2 * h2 - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def nms_global(detections: List[Tuple], iou_threshold: float = 0.3) -> List[Tuple]:\n",
    "    \"\"\"Apply Non-Maximum Suppression globally.\"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n",
    "    keep = []\n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n",
    "    return keep\n",
    "\n",
    "\n",
    "def draw_bboxes(img_rgb: np.ndarray, bboxes, color=(0, 255, 0), thickness=2, show_numbers: bool = None) -> np.ndarray:\n",
    "    \"\"\"Draw bounding boxes on image. Unified function for single or multiple boxes.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    if bboxes is None:\n",
    "        return img_out\n",
    "    if bboxes and not isinstance(bboxes[0], (list, tuple)):\n",
    "        bboxes = [bboxes]\n",
    "    bboxes = [b for b in bboxes if b is not None]\n",
    "    if not bboxes:\n",
    "        return img_out\n",
    "    if show_numbers is None:\n",
    "        show_numbers = len(bboxes) > 1\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, thickness)\n",
    "        if show_numbers:\n",
    "            cv.putText(img_out, str(i+1), (x+2, y+h-5), cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detection-header",
   "metadata": {},
   "source": [
    "### Core Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detection-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_match_multiscale(\n",
    "    img_gray: np.ndarray, template_variants: Dict[str, np.ndarray], scales: np.ndarray,\n",
    "    threshold: float = 0.30, preprocess: str = None,\n",
    "    aspect_filter: Tuple[float, float] = None, min_width_ratio: float = 0.05\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"Multi-scale template matching. Returns: (bbox, score, method_info)\"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    img_processed = preprocess_image(img_gray, preprocess) if preprocess else cv.equalizeHist(cv.GaussianBlur(img_gray, (3, 3), 0))\n",
    "    min_det_width, min_det_height = w * min_width_ratio, h * 0.02\n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        for name, tmpl in template_variants.items():\n",
    "            th, tw = tmpl.shape\n",
    "            new_w, new_h = int(tw * scale), int(th * scale)\n",
    "            if new_w > w or new_h > h or new_w < min_det_width or new_h < min_det_height:\n",
    "                continue\n",
    "            \n",
    "            res = cv.matchTemplate(img_processed, cv.resize(tmpl, (new_w, new_h)), cv.TM_CCOEFF_NORMED)\n",
    "            adaptive_thresh = max(np.mean(res) + 2.5 * np.std(res), threshold)\n",
    "            \n",
    "            for pt in zip(*np.where(res >= adaptive_thresh)[::-1]):\n",
    "                aspect = new_w / new_h if new_h > 0 else 0\n",
    "                if aspect_filter:\n",
    "                    if not (aspect_filter[0] < aspect < aspect_filter[1]):\n",
    "                        continue\n",
    "                elif not (0.5 < aspect < 4.0):\n",
    "                    continue\n",
    "                all_detections.append((pt[0], pt[1], new_w, new_h, res[pt[1], pt[0]], name, scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return None, 0, \"No detection\"\n",
    "    best = nms_global(all_detections, iou_threshold=0.3)[0]\n",
    "    return (best[0], best[1], best[2], best[3]), best[4], f\"TM-{best[5]}@{best[6]:.2f}\"\n",
    "\n",
    "\n",
    "def template_match_edges(\n",
    "    img_gray: np.ndarray, template: np.ndarray, scales: np.ndarray,\n",
    "    threshold: float = 0.25, canny_low: int = 50, canny_high: int = 150,\n",
    "    y_range: Tuple[int, int] = None\n",
    ") -> Tuple[Optional[Tuple], float, str]:\n",
    "    \"\"\"Edge-based template matching - robust to contrast inversion.\"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    min_det_width, min_det_height = w * 0.05, h * 0.02\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    template_edges = cv.dilate(cv.Canny(template, canny_low, canny_high), kernel, iterations=1)\n",
    "    img_edges = cv.dilate(cv.Canny(img_gray, canny_low, canny_high), kernel, iterations=1)\n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        th, tw = template.shape\n",
    "        new_w, new_h = int(tw * scale), int(th * scale)\n",
    "        if new_w >= w or new_h >= h or new_w < min_det_width or new_h < min_det_height:\n",
    "            continue\n",
    "        \n",
    "        res = cv.matchTemplate(img_edges, cv.resize(template_edges, (new_w, new_h)), cv.TM_CCOEFF_NORMED)\n",
    "        adaptive_thresh = max(np.mean(res) + 2.5 * np.std(res), threshold)\n",
    "        \n",
    "        for pt in zip(*np.where(res >= adaptive_thresh)[::-1]):\n",
    "            if y_range and not (y_range[0] <= pt[1] <= y_range[1]):\n",
    "                continue\n",
    "            all_detections.append((pt[0], pt[1], new_w, new_h, res[pt[1], pt[0]], 'edges', scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return None, 0, \"No detection (edges)\"\n",
    "    best = nms_global(all_detections, iou_threshold=0.3)[0]\n",
    "    return (best[0], best[1], best[2], best[3]), best[4], f\"TM-edges@{best[6]:.2f}\"\n",
    "\n",
    "\n",
    "def detect_by_sift(\n",
    "    img_gray: np.ndarray, template: np.ndarray, min_matches: int = 8,\n",
    "    ratio: float = 0.75, min_bbox_ratio: float = 0.02, max_bbox_ratio: float = 0.95\n",
    ") -> Tuple[Optional[Tuple], int, str]:\n",
    "    \"\"\"SIFT-based detection with homography. Returns: (bbox, num_inliers, method_info)\"\"\"\n",
    "    img_h, img_w = img_gray.shape\n",
    "    img_area = img_h * img_w\n",
    "    min_bbox_w, min_bbox_h = img_w * 0.03, img_h * 0.02\n",
    "    \n",
    "    sift = cv.SIFT_create(nfeatures=2000)\n",
    "    kp2, des2 = sift.detectAndCompute(img_gray, None)\n",
    "    if des2 is None or len(des2) < min_matches:\n",
    "        return None, 0, \"SIFT: insufficient features in image\"\n",
    "    \n",
    "    for tmpl_name, tmpl in [('normal', template), ('inverted', 255 - template)]:\n",
    "        kp1, des1 = sift.detectAndCompute(tmpl, None)\n",
    "        if des1 is None or len(des1) < 4:\n",
    "            continue\n",
    "        \n",
    "        flann = cv.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=50))\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "        good = [m for m, n in matches if len([m, n]) == 2 and m.distance < ratio * n.distance]\n",
    "        \n",
    "        if len(good) < min_matches:\n",
    "            continue\n",
    "        \n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
    "        \n",
    "        if M is None:\n",
    "            continue\n",
    "        \n",
    "        num_inliers = mask.ravel().sum() if mask is not None else len(good)\n",
    "        th, tw = tmpl.shape\n",
    "        dst = cv.perspectiveTransform(np.float32([[0,0], [0,th-1], [tw-1,th-1], [tw-1,0]]).reshape(-1,1,2), M)\n",
    "        x, y, bw, bh = cv.boundingRect(dst)\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        bw, bh = min(bw, img_w - x), min(bh, img_h - y)\n",
    "        bbox_area = bw * bh\n",
    "        \n",
    "        if (bbox_area < img_area * min_bbox_ratio or bbox_area > img_area * max_bbox_ratio or\n",
    "            bw < min_bbox_w or bh < min_bbox_h or bw / bh > 10 or bh / bw > 5):\n",
    "            continue\n",
    "        \n",
    "        return (x, y, bw, bh), num_inliers, f\"SIFT-{tmpl_name}({num_inliers} inliers)\"\n",
    "    \n",
    "    return None, 0, \"SIFT: no valid homography found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-template-header",
   "metadata": {},
   "source": [
    "### Load Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template shape: (175, 400)\n",
      "Variants: ['normal', 'clahe', 'inverted', 'inverted_clahe']\n"
     ]
    }
   ],
   "source": [
    "# Load template and create variants\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "template_variants = create_template_variants(template, include_inverted=True)\n",
    "\n",
    "print(f\"Template shape: {template.shape}\")\n",
    "print(f\"Variants: {list(template_variants.keys())}\")\n",
    "\n",
    "# Display template variants (2x2 grid for 4 variants)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "for ax, (name, img) in zip(axes, template_variants.items()):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Template Variants')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results storage\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image1-header",
   "metadata": {},
   "source": [
    "---\n",
    "### Image Detection\n",
    "\n",
    "#### 1 coca_logo_1.png\n",
    "\n",
    "Se utilizó template matching basado en bordes porque el fondo es limpio y el contorno del logotipo se preserva bien tras Canny, logrando una coincidencia muy estable. Además, el uso de un rango de escalas reducido y un filtro por posición vertical permite evitar falsas detecciones en áreas sin contenido relevante.\n",
    "\n",
    "**Características:** Botella con etiqueta frontal, texto BLANCO sobre fondo ROJO.  \n",
    "**Problema:** En escala de grises, el contraste está invertido respecto al template.  \n",
    "**Estrategia:** Template matching basado en bordes (Canny es invariante a la inversión de contraste).  \n",
    "**Escalas:** 0.30 - 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "detect-coca-logo-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (500, 207)\n",
      "Image: coca_logo_1.png\n",
      "Method: TM-edges@0.42\n",
      "Score: 0.411\n",
      "BBox: (np.int64(31), np.int64(198), 167, 73)\n"
     ]
    }
   ],
   "source": [
    "# coca_logo_1.png - Bottle with white text on red background\n",
    "# Problem: Inverted contrast in grayscale\n",
    "# Solution: Edge-based matching (edges are invariant to contrast inversion)\n",
    "img_name = \"coca_logo_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Edge-based matching with scales optimized for this image\n",
    "scales = np.linspace(0.30, 0.55, 20)\n",
    "\n",
    "# Use relative y_range based on image height (robust to resizing)\n",
    "h, w = img_gray.shape\n",
    "y_min, y_max = int(0.3 * h), int(0.7 * h)\n",
    "\n",
    "bbox, score, method = template_match_edges(\n",
    "    img_gray, \n",
    "    template,\n",
    "    scales=scales,\n",
    "    threshold=0.25,\n",
    "    y_range=(y_min, y_max)  # Restrict to label area (avoid false positives)\n",
    ")\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image2-header",
   "metadata": {},
   "source": [
    "#### 2 coca_logo_2.png\n",
    "\n",
    "Para esta imagen se aplicó SIFT debido a la curvatura del envase y las variaciones de iluminación, que afectan la correlación directa de plantillas pero no la coincidencia de puntos clave. La homografía obtenida a partir de los matches permite recuperar con precisión la región del logotipo pese a la deformación de perspectiva.\n",
    "\n",
    "**Características:** Lata con texto BLANCO sobre fondo ROJO, superficie curva, gotas de agua.  \n",
    "**Problema:** Template matching falla debido a la distorsión por curvatura e inversión de contraste.  \n",
    "**Estrategia:** SIFT con template invertido (el texto blanco genera features que coinciden con el template invertido).  \n",
    "**Nota:** SIFT maneja la distorsión de perspectiva de la superficie curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detect-coca-logo-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (363, 233)\n",
      "Image: coca_logo_2.png\n",
      "Method: SIFT-inverted(29 inliers)\n",
      "Score: 29.000\n",
      "BBox: (0, 96, 233, 132)\n"
     ]
    }
   ],
   "source": [
    "# coca_logo_2.png - Can with curved surface\n",
    "# Problem: Template matching fails due to curved surface and contrast inversion\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"coca_logo_2.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT works well for curved surfaces (handles perspective distortion)\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image3-header",
   "metadata": {},
   "source": [
    "#### 3 coca_multi.png\n",
    "\n",
    "Se utilizó template matching invertido y un rango de escalas estrecho porque todos los logos aparecen a tamaño similar y contrastan de manera consistente con el fondo. La supresión global de no-máximos permite conservar solo la mejor detección individual, cumpliendo con la restricción de una única coincidencia por imagen.\n",
    "\n",
    "**Características:** Estante con múltiples botellas, texto BLANCO sobre etiquetas ROJAS.  \n",
    "**Problema:** Múltiples logos similares, inversión de contraste en escala de grises.  \n",
    "**Estrategia:** Template matching invertido con CLAHE (corrige la inversión de contraste).  \n",
    "**Escalas:** Derivadas del tamaño esperado del logo (~10% del ancho de imagen).  \n",
    "**Nota:** Para Assignment 1, se detecta solo UN logo (mejor coincidencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "detect-coca-multi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (598, 799)\n",
      "Expected logo width: ~80px\n",
      "Scale range: 0.12 - 0.30\n",
      "Image: coca_multi.png\n",
      "Method: TM-inverted_clahe@0.23\n",
      "Score: 0.501\n",
      "BBox: (np.int64(274), np.int64(146), 93, 40)\n"
     ]
    }
   ],
   "source": [
    "# coca_multi.png - Shelf with many bottles\n",
    "# Problem: White text on red background = contrast inversion\n",
    "# Solution: Use inverted template with CLAHE\n",
    "img_name = \"coca_multi.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Create inverted template variants (for white-on-red labels)\n",
    "template_inv = 255 - template\n",
    "inverted_variants = {\n",
    "    'inverted': template_inv,\n",
    "    'inverted_clahe': preprocess_image(template_inv, 'clahe'),\n",
    "}\n",
    "\n",
    "# Derive scale range from template and expected logo size\n",
    "# Reference: typical bottle label logo is ~80px wide in a 800px wide shelf image\n",
    "# This gives us a reference ratio that scales with any image size\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape  # template: 175x400\n",
    "\n",
    "reference_logo_width = 80  # expected logo width in pixels (for ~800px wide image)\n",
    "reference_image_width = 800\n",
    "expected_logo_ratio = reference_logo_width / reference_image_width  # ~0.10\n",
    "\n",
    "# Scale to actual image width\n",
    "expected_logo_width = w * expected_logo_ratio\n",
    "center_scale = expected_logo_width / tw  # scale where template matches expected logo\n",
    "\n",
    "# Scale range: ±50% around center scale\n",
    "scale_min = center_scale * 0.6\n",
    "scale_max = center_scale * 1.5\n",
    "scales = np.linspace(scale_min, scale_max, 20)\n",
    "\n",
    "print(f\"Expected logo width: ~{expected_logo_width:.0f}px\")\n",
    "print(f\"Scale range: {scale_min:.2f} - {scale_max:.2f}\")\n",
    "\n",
    "# Min width as ratio of image (derived from expected size)\n",
    "min_width_ratio = expected_logo_ratio * 0.5  # allow logos down to 50% of expected\n",
    "\n",
    "bbox, score, method = template_match_multiscale(\n",
    "    img_gray, \n",
    "    inverted_variants,\n",
    "    scales=scales,\n",
    "    threshold=0.35,\n",
    "    preprocess='clahe',\n",
    "    aspect_filter=(1.8, 3.5),  # Coca-Cola logo aspect ratio\n",
    "    min_width_ratio=min_width_ratio\n",
    ")\n",
    "\n",
    "# NOTE: For Assignment 2 (multiple detections), modify template_match_multiscale\n",
    "# to return `final` (all NMS results) instead of just `final[0]`\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image4-header",
   "metadata": {},
   "source": [
    "#### 4 coca_retro_1.png\n",
    "\n",
    "Se aplicó SIFT porque el logotipo retro difiere estructuralmente del template moderno, lo que hace que la correlación clásica falle al no haber similitud pixel-a-pixel. Los puntos clave permiten encontrar correspondencias parciales y estimar una homografía incluso cuando la forma global del logotipo no coincide con la plantilla.\n",
    "\n",
    "**Características:** Etiqueta vintage B/N, logotipo estilizado diferente al template.  \n",
    "**Problema:** Diferencias estructurales entre el logo retro y el template moderno.  \n",
    "**Estrategia:** SIFT con `min_matches=6` (menor umbral por diferencias estructurales).  \n",
    "**Fallback:** Template matching con aspect ratio amplio (1.2, 4.0) para formas retro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "detect-coca-retro-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (493, 715)\n",
      "Image: coca_retro_1.png\n",
      "Method: SIFT-normal(19 inliers)\n",
      "Score: 19.000\n",
      "BBox: (67, 74, 568, 220)\n"
     ]
    }
   ],
   "source": [
    "# coca_retro_1.png - Vintage label (structurally different)\n",
    "img_name = \"coca_retro_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Try SIFT first (best for this case)\n",
    "# Lower min_matches=6 because vintage logo has different shape, fewer strong correspondences\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=6)\n",
    "\n",
    "# Fallback to template matching if SIFT fails\n",
    "if bbox is None:\n",
    "    print(\"SIFT failed, trying template matching...\")\n",
    "    scales = np.linspace(0.5, 2.0, 25)\n",
    "    bbox, score, method = template_match_multiscale(\n",
    "        img_gray, \n",
    "        template_variants,\n",
    "        scales=scales,\n",
    "        threshold=0.25,  # Lower threshold for difficult case\n",
    "        preprocess='clahe',\n",
    "        aspect_filter=(1.2, 4.0)  # Wider range for retro logo shape\n",
    "    )\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image5-header",
   "metadata": {},
   "source": [
    "#### 5 coca_retro_2.png\n",
    "\n",
    "La detección se resolvió con SIFT ya que el logotipo aparece rotado, curvado y dentro de un disco circular, condiciones que degradan el desempeño del template matching. SIFT permite identificar características locales invariantes y recuperar la transformación geométrica del emblema con alta estabilidad.\n",
    "\n",
    "**Características:** Póster vintage con emblema circular rojo, texto BLANCO sobre fondo ROJO.  \n",
    "**Problema:** Texto curvado en emblema circular, inversión de contraste.  \n",
    "**Estrategia:** SIFT con template invertido (maneja curvatura y contraste).  \n",
    "**Nota:** SIFT funciona mejor que template matching para logos curvados/distorsionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "detect-coca-retro-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (429, 715)\n",
      "Image: coca_retro_2.png\n",
      "Method: SIFT-inverted(29 inliers)\n",
      "Score: 29.000\n",
      "BBox: (61, 187, 161, 63)\n"
     ]
    }
   ],
   "source": [
    "# coca_retro_2.png - Vintage poster with circular badge\n",
    "# Problem: White text on red, curved logo on circular badge\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"coca_retro_2.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT handles curved/distorted logos well\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image6-header",
   "metadata": {},
   "source": [
    "#### 6 COCA-COLA-LOGO.jpg\n",
    "\n",
    "Se empleó SIFT porque el logotipo ocupa una región grande, con gradientes complejos, sombras y un fondo texturizado que altera fuertemente la correlación normalizada. Los descriptores locales permiten detectar el texto independientemente del color y la iluminación, obteniendo una caja bien ajustada mediante homografía.\n",
    "\n",
    "**Características:** Imagen grande (1389x1389), texto BLANCO sobre emblema circular ROJO.  \n",
    "**Problema:** Logo grande, inversión de contraste, fondo complejo (botella, hielo, burbujas).  \n",
    "**Estrategia:** SIFT con template invertido (maneja escala y contraste).  \n",
    "**Nota:** SIFT encuentra ~47 matches, proporcionando detección robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "detect-coca-cola-logo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (1200, 1200)\n",
      "Image: COCA-COLA-LOGO.jpg\n",
      "Method: SIFT-inverted(24 inliers)\n",
      "Score: 24.000\n",
      "BBox: (10, 322, 1152, 486)\n"
     ]
    }
   ],
   "source": [
    "# COCA-COLA-LOGO.jpg - Large image with complex background\n",
    "# Problem: White text on red, very large logo\n",
    "# Solution: SIFT with inverted template\n",
    "img_name = \"COCA-COLA-LOGO.jpg\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# SIFT handles large scale differences well\n",
    "bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image7-header",
   "metadata": {},
   "source": [
    "#### 7 logo_1.png\n",
    "\n",
    "Se aplicó template matching con preprocesamiento CLAHE porque la imagen presenta reflejos, variaciones de iluminación y textura sobre el vidrio que dificultan la correlación directa. La ecualización adaptativa y el suavizado previo permiten estabilizar el contraste del logotipo y mejorar la respuesta del método en un entorno visual ruidoso.\n",
    "\n",
    "**Características:** Botellas de vidrio con texto BLANCO sobre etiquetas ROJAS, reflejos, sombras.  \n",
    "**Problema:** Inversión de contraste, variaciones de iluminación, reflejos en el vidrio.  \n",
    "**Estrategia:** Template matching con preprocesamiento (Gaussian blur + CLAHE), fallback a SIFT.  \n",
    "**Escalas:** Derivadas del ratio esperado del logo (~35% del ancho de imagen para tomas cercanas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "detect-logo-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (450, 687)\n",
      "Scale range: 0.42 - 0.84\n",
      "Image: logo_1.png\n",
      "Method: TM-inverted_clahe@0.73\n",
      "Score: 0.426\n",
      "BBox: (np.int64(198), np.int64(191), 292, 127)\n"
     ]
    }
   ],
   "source": [
    "# logo_1.png - Glass bottles with glare and shadows\n",
    "# Problem: White text on red, lighting variations, reflections\n",
    "# Strategy: Try template matching first (with preprocessing), fall back to SIFT\n",
    "img_name = \"logo_1.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "\n",
    "print(f\"Image size: {img_gray.shape}\")\n",
    "\n",
    "# Preprocess: light Gaussian blur + CLAHE to handle reflections\n",
    "img_blur = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img_preprocessed = clahe.apply(img_blur)\n",
    "\n",
    "# Create inverted template variants (white text on red = inverted contrast)\n",
    "template_inv = 255 - template\n",
    "inverted_variants = {\n",
    "    'inverted': template_inv,\n",
    "    'inverted_clahe': preprocess_image(template_inv, 'clahe'),\n",
    "}\n",
    "\n",
    "# First try: Template matching with moderate scale band\n",
    "# Logo is roughly 200-300px wide in 687px image, template is 400px\n",
    "# Scale ~0.5-0.75 expected\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape\n",
    "\n",
    "# Derive scale from expected logo ratio\n",
    "expected_logo_ratio = 0.35  # logo ~35% of image width for close-up bottle shots\n",
    "expected_logo_width = w * expected_logo_ratio\n",
    "center_scale = expected_logo_width / tw\n",
    "scale_min = center_scale * 0.7\n",
    "scale_max = center_scale * 1.4\n",
    "scales = np.linspace(scale_min, scale_max, 20)\n",
    "\n",
    "print(f\"Scale range: {scale_min:.2f} - {scale_max:.2f}\")\n",
    "\n",
    "bbox, score, method = template_match_multiscale(\n",
    "    img_preprocessed, \n",
    "    inverted_variants,\n",
    "    scales=scales,\n",
    "    threshold=0.35,\n",
    "    preprocess=None,  # Already preprocessed\n",
    "    aspect_filter=(1.5, 4.0),\n",
    "    min_width_ratio=0.10\n",
    ")\n",
    "\n",
    "# Fall back to SIFT if template matching fails or score is low\n",
    "if bbox is None or score < 0.40:\n",
    "    print(f\"Template matching {'failed' if bbox is None else f'score too low ({score:.3f})'}, trying SIFT...\")\n",
    "    bbox, score, method = detect_by_sift(img_gray, template, min_matches=8)\n",
    "\n",
    "print(f\"Image: {img_name}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Score: {score:.3f}\")\n",
    "print(f\"BBox: {bbox}\")\n",
    "\n",
    "results_summary.append({\n",
    "    'image': img_name,\n",
    "    'method': method,\n",
    "    'score': score,\n",
    "    'bbox': bbox\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de detecciones:\n",
      "Image                     Method                                 Score         Size\n",
      "--------------------------------------------------------------------------------\n",
      "coca_logo_1.png           TM-edges@0.42                          0.411       167x73\n",
      "coca_logo_2.png           SIFT-inverted(29 inliers)             29.000      233x132\n",
      "coca_multi.png            TM-inverted_clahe@0.23                 0.501        93x40\n",
      "coca_retro_1.png          SIFT-normal(19 inliers)               19.000      568x220\n",
      "coca_retro_2.png          SIFT-inverted(29 inliers)             29.000       161x63\n",
      "COCA-COLA-LOGO.jpg        SIFT-inverted(24 inliers)             24.000     1152x486\n",
      "logo_1.png                TM-inverted_clahe@0.73                 0.426      292x127\n",
      "--------------------------------------------------------------------------------\n",
      "Total detected: 7/7\n"
     ]
    }
   ],
   "source": [
    "print(\"Resumen de detecciones:\")\n",
    "print(f\"{'Image':<25} {'Method':<35} {'Score':>8} {'Size':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "detected_count = 0\n",
    "for r in results_summary:\n",
    "    img = r['image']\n",
    "    method = r['method'][:33] if len(r['method']) > 33 else r['method']\n",
    "    score = r['score']\n",
    "    bbox = r['bbox']\n",
    "    \n",
    "    if bbox:\n",
    "        size = f\"{bbox[2]}x{bbox[3]}\"\n",
    "        detected_count += 1\n",
    "    else:\n",
    "        size = \"N/A\"\n",
    "    \n",
    "    print(f\"{img:<25} {method:<35} {score:>8.3f} {size:>12}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total detected: {detected_count}/{len(results_summary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grid-visualization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/TP3-assignment1.png\n"
     ]
    }
   ],
   "source": [
    "# Final grid visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(results_summary):\n",
    "    img_rgb, _, _ = load_image(f\"images/{r['image']}\")\n",
    "    img_out = draw_bboxes(img_rgb, r['bbox'])\n",
    "    \n",
    "    axes[idx].imshow(img_out)\n",
    "    axes[idx].set_title(f\"{r['image']}\\nScore: {r['score']:.3f}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(len(results_summary), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Assignment 1: Single Detection per Image', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-assignment1.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: results/TP3-assignment1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67498d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2: Detección múltiple por imagen\n",
    "\n",
    "Plantear y validar un algoritmo para múltiples detecciones en la imagen `coca_multi.png` con el mismo template del ítem 1.\n",
    "\n",
    "### Enfoque\n",
    "\n",
    "En `coca_multi` hay muchas botellas alineadas con logos a diferentes escalas según el estante.\n",
    "\n",
    "**Mejoras implementadas para reducir falsos positivos:**\n",
    "\n",
    "1. **Filtro por banda horizontal (y_ranges):** Los logos aparecen solo en franjas específicas de la imagen. Restricción a zonas donde realmente hay etiquetas (ratios relativos al alto de imagen).\n",
    "\n",
    "2. **Validación de consistencia de color:** Después de cada detección, se verifica que la región sea predominantemente roja (R > 110, R > G+25, R > B+25).\n",
    "\n",
    "3. **Filtros de forma relativos:** \n",
    "   - Aspect ratio (2.0–3.8) - adimensional\n",
    "   - Ancho: 9%–21% del ancho de imagen\n",
    "   - Alto: 5%–13% del alto de imagen\n",
    "\n",
    "4. **Test de aislamiento de picos:** Rechaza picos de correlación aislados (ruido) verificando que el vecindario local también tenga respuesta alta.\n",
    "\n",
    "**Nota:** Todos los parámetros de tamaño son relativos al tamaño de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf93631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multiple_logos(\n",
    "    img_gray: np.ndarray,\n",
    "    img_rgb: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    scales: np.ndarray,\n",
    "    threshold_sigma: float = 2.5,\n",
    "    min_threshold: float = 0.35,\n",
    "    iou_threshold: float = 0.3,\n",
    "    size_filter: Tuple[int, int] = None,\n",
    "    height_filter: Tuple[int, int] = None,\n",
    "    aspect_filter: Tuple[float, float] = (2.6, 3.8),\n",
    "    y_ranges: List[Tuple[float, float]] = None,\n",
    "    local_max_kernel: int = 7,\n",
    "    peak_isolation_ratio: float = 0.5,\n",
    "    color_check: bool = True,\n",
    "    min_red_dominance: int = 30,\n",
    "    min_red_value: int = 120\n",
    ") -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Multi-detection using template matching with local maxima and validation filters.\n",
    "    \n",
    "    Args:\n",
    "        img_gray: Grayscale image\n",
    "        img_rgb: RGB image (for color validation)\n",
    "        template: Single template (use best variant, e.g., inverted + CLAHE)\n",
    "        scales: Array of scales to test\n",
    "        threshold_sigma: Number of std devs above mean for adaptive threshold\n",
    "        min_threshold: Minimum absolute threshold\n",
    "        iou_threshold: IoU threshold for NMS\n",
    "        size_filter: Optional (min_width, max_width) to filter detections\n",
    "        height_filter: Optional (min_height, max_height) to filter detections\n",
    "        aspect_filter: (min_aspect, max_aspect) for logo shape validation\n",
    "        y_ranges: List of (y_min_ratio, y_max_ratio) for valid detection zones\n",
    "        local_max_kernel: Kernel size for local maxima detection\n",
    "        peak_isolation_ratio: Minimum ratio of neighborhood mean to peak score\n",
    "        color_check: Whether to validate red color dominance\n",
    "        min_red_dominance: Minimum R - max(G, B) for color check\n",
    "        min_red_value: Minimum R channel value for color check\n",
    "    \n",
    "    Returns: List of detections [(x, y, w, h, score), ...]\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    th, tw = template.shape\n",
    "    template_aspect = tw / th\n",
    "    \n",
    "    # Relative minimum sizes (3% width, 2% height)\n",
    "    min_det_width = w * 0.03\n",
    "    min_det_height = h * 0.02\n",
    "    \n",
    "    # Preprocess image\n",
    "    img_processed = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    img_processed = cv.equalizeHist(img_processed)\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        new_w, new_h = int(tw * scale), int(th * scale)\n",
    "        \n",
    "        # Skip invalid sizes (relative check)\n",
    "        if new_w > w or new_h > h:\n",
    "            continue\n",
    "        if new_w < min_det_width or new_h < min_det_height:\n",
    "            continue\n",
    "        \n",
    "        # Width filter (if provided)\n",
    "        if size_filter:\n",
    "            if new_w < size_filter[0] or new_w > size_filter[1]:\n",
    "                continue\n",
    "        \n",
    "        # Height filter (if provided)\n",
    "        if height_filter:\n",
    "            if new_h < height_filter[0] or new_h > height_filter[1]:\n",
    "                continue\n",
    "        \n",
    "        # Resize template\n",
    "        scaled_tmpl = cv.resize(template, (new_w, new_h))\n",
    "        \n",
    "        # Template matching\n",
    "        res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Adaptive threshold\n",
    "        mean_val, std_val = np.mean(res), np.std(res)\n",
    "        adaptive_thresh = max(mean_val + threshold_sigma * std_val, min_threshold)\n",
    "        \n",
    "        # Find local maxima instead of simple thresholding\n",
    "        kernel = np.ones((local_max_kernel, local_max_kernel), np.uint8)\n",
    "        local_max = cv.dilate(res, kernel)\n",
    "        mask = (res == local_max) & (res >= adaptive_thresh)\n",
    "        \n",
    "        ys, xs = np.where(mask)\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            score = res[y, x]\n",
    "            \n",
    "            # Strict aspect ratio filter\n",
    "            det_aspect = new_w / new_h\n",
    "            if aspect_filter:\n",
    "                if not (aspect_filter[0] <= det_aspect <= aspect_filter[1]):\n",
    "                    continue\n",
    "            elif abs(det_aspect - template_aspect) > 0.5:\n",
    "                continue\n",
    "            \n",
    "            # Y-range filter (horizontal band where labels appear)\n",
    "            if y_ranges:\n",
    "                in_valid_zone = False\n",
    "                for y_min_ratio, y_max_ratio in y_ranges:\n",
    "                    y_min = int(h * y_min_ratio)\n",
    "                    y_max = int(h * y_max_ratio)\n",
    "                    if y_min <= y <= y_max:\n",
    "                        in_valid_zone = True\n",
    "                        break\n",
    "                if not in_valid_zone:\n",
    "                    continue\n",
    "            \n",
    "            # Peak isolation test\n",
    "            # Reject sparse bright noise - keep peaks supported by local neighborhood\n",
    "            y1 = max(0, y - 2)\n",
    "            y2 = min(res.shape[0], y + 3)\n",
    "            x1 = max(0, x - 2)\n",
    "            x2 = min(res.shape[1], x + 3)\n",
    "            window = res[y1:y2, x1:x2]\n",
    "            if window.size > 0 and window.mean() < score * peak_isolation_ratio:\n",
    "                continue\n",
    "            \n",
    "            # Color consistency check (red dominance)\n",
    "            if color_check and img_rgb is not None:\n",
    "                # Sample the bounding box region in RGB\n",
    "                box_y1 = max(0, y)\n",
    "                box_y2 = min(img_rgb.shape[0], y + new_h)\n",
    "                box_x1 = max(0, x)\n",
    "                box_x2 = min(img_rgb.shape[1], x + new_w)\n",
    "                \n",
    "                if box_y2 > box_y1 and box_x2 > box_x1:\n",
    "                    patch = img_rgb[box_y1:box_y2, box_x1:box_x2]\n",
    "                    mean_color = patch.mean(axis=(0, 1))  # R, G, B average\n",
    "                    \n",
    "                    # True Coca-Cola labels: R > 120, R > G + 30, R > B + 30\n",
    "                    r, g, b = mean_color[0], mean_color[1], mean_color[2]\n",
    "                    if not (r > min_red_value and \n",
    "                            r > g + min_red_dominance and \n",
    "                            r > b + min_red_dominance):\n",
    "                        continue\n",
    "            \n",
    "            all_detections.append((x, y, new_w, new_h, score, scale))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return []\n",
    "    \n",
    "    # Apply NMS\n",
    "    final_detections = nms_global(all_detections, iou_threshold=iou_threshold)\n",
    "    \n",
    "    # Return as (x, y, w, h, score)\n",
    "    return [(d[0], d[1], d[2], d[3], d[4]) for d in final_detections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "t3kx005a3u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 799x598\n",
      "Template size: 400x175\n",
      "Width: 9%-21% → 71px-167px\n",
      "Height: 5%-13% → 29px-77px\n",
      "Scale range: 0.18-0.42\n",
      "\n",
      "Detected: 18 logos\n",
      "Top shelf: 9, Bottom shelf: 9\n",
      "\n",
      "   1. [Bottom] pos=(562,428), size=92x40, score=0.444\n",
      "   2. [Bottom] pos=(147,427), size=92x40, score=0.436\n",
      "   3. [Bottom] pos=(305,430), size=92x40, score=0.430\n",
      "   4. [Top   ] pos=( 31,148), size=85x37, score=0.426\n",
      "   5. [Bottom] pos=(406,432), size=85x37, score=0.425\n",
      "   6. [Bottom] pos=( 74,423), size=85x37, score=0.423\n",
      "   7. [Top   ] pos=(275,146), size=92x40, score=0.422\n",
      "   8. [Bottom] pos=(488,425), size=85x37, score=0.421\n",
      "   9. [Bottom] pos=(235,431), size=85x37, score=0.420\n",
      "  10. [Top   ] pos=(706,154), size=78x34, score=0.416\n",
      "  11. [Top   ] pos=(107,151), size=92x40, score=0.416\n",
      "  12. [Bottom] pos=(655,428), size=78x34, score=0.410\n",
      "  13. [Top   ] pos=(542,156), size=78x34, score=0.392\n",
      "  14. [Top   ] pos=(200,152), size=85x37, score=0.390\n",
      "  15. [Bottom] pos=(  1,420), size=78x34, score=0.385\n",
      "  16. [Top   ] pos=(367,149), size=85x37, score=0.384\n",
      "  17. [Top   ] pos=(447,150), size=85x37, score=0.383\n",
      "  18. [Top   ] pos=(625,153), size=78x34, score=0.377\n",
      "Saved: results/TP3-assignment2.png\n"
     ]
    }
   ],
   "source": [
    "# Assignment 2: Multi-detection en coca_multi.png\n",
    "img_name = \"coca_multi.png\"\n",
    "img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "h, w = img_gray.shape\n",
    "th, tw = template.shape\n",
    "\n",
    "print(f\"Image size: {w}x{h}\")\n",
    "print(f\"Template size: {tw}x{th}\")\n",
    "\n",
    "# Create single best template: inverted + CLAHE\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "template_inv_clahe = clahe.apply(255 - template)\n",
    "\n",
    "# Relative size ratios for expected logos\n",
    "width_ratio_min, width_ratio_max = 0.09, 0.21\n",
    "height_ratio_min, height_ratio_max = 0.05, 0.13\n",
    "\n",
    "w_min, w_max = int(w * width_ratio_min), int(w * width_ratio_max)\n",
    "h_min, h_max = int(h * height_ratio_min), int(h * height_ratio_max)\n",
    "scales = compute_scale_range(w, tw, width_ratio_min, width_ratio_max, num_scales=15)\n",
    "\n",
    "print(f\"Width: {width_ratio_min:.0%}-{width_ratio_max:.0%} → {w_min}px-{w_max}px\")\n",
    "print(f\"Height: {height_ratio_min:.0%}-{height_ratio_max:.0%} → {h_min}px-{h_max}px\")\n",
    "print(f\"Scale range: {scales[0]:.2f}-{scales[-1]:.2f}\")\n",
    "\n",
    "y_ranges = [(0.08, 0.35), (0.68, 0.95)]  # Top/bottom shelf\n",
    "aspect_filter = (2.0, 3.8)\n",
    "\n",
    "detections = detect_multiple_logos(\n",
    "    img_gray, img_rgb, template_inv_clahe, scales=scales,\n",
    "    threshold_sigma=2.5, min_threshold=0.34, iou_threshold=0.20,\n",
    "    size_filter=(w_min, w_max), height_filter=(h_min, h_max),\n",
    "    aspect_filter=aspect_filter, y_ranges=y_ranges,\n",
    "    local_max_kernel=11, peak_isolation_ratio=0.5,\n",
    "    color_check=True, min_red_dominance=25, min_red_value=110\n",
    ")\n",
    "\n",
    "print(f\"\\nDetected: {len(detections)} logos\")\n",
    "top_count = sum(1 for d in detections if d[1] < h * 0.5)\n",
    "print(f\"Top shelf: {top_count}, Bottom shelf: {len(detections) - top_count}\\n\")\n",
    "\n",
    "for i, (x, y, bw, bh, score) in enumerate(detections):\n",
    "    print(f\"  {i+1:2d}. [{'Top' if y < h * 0.5 else 'Bottom':6s}] pos=({x:3d},{y:3d}), size={bw}x{bh}, score={score:.3f}\")\n",
    "\n",
    "img_out = draw_bboxes(img_rgb, detections, color=(0, 255, 0), thickness=2)\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(img_out)\n",
    "plt.title(f\"Assignment 2: {len(detections)} logos detected\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-assignment2.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/TP3-assignment2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c8138",
   "metadata": {},
   "source": [
    "---\n",
    "## 3: Generalización del algoritmo\n",
    "\n",
    "Generalizar el algoritmo del ítem 2 para todas las imágenes.\n",
    "\n",
    "### Enfoque: Meta-Detector con Fusión de Detectores\n",
    "\n",
    "En lugar de un único detector, implementamos un **meta-detector** que:\n",
    "\n",
    "1. **Ejecuta múltiples detectores especializados:**\n",
    "   - Template Matching (single) - bueno para fondos limpios\n",
    "   - Template Matching con bordes - robusto a inversión de contraste\n",
    "   - SIFT (single) - bueno para logos curvados/rotados/retro\n",
    "   - Multi-detection - para imágenes con múltiples logos\n",
    "\n",
    "2. **Normaliza las puntuaciones** a rango [0, 1] para comparación justa:\n",
    "   - TM: `norm = clip((max_val - 0.2) / 0.5, 0, 1)`\n",
    "   - SIFT: `norm = min(1.0, num_inliers / 25)`\n",
    "   - Multi: `norm = 0.6 * norm_TM + 0.4 * min(1.0, num / 10)`\n",
    "\n",
    "3. **Selecciona el mejor resultado** con lógica de meta-decisión:\n",
    "   - Single mode: Si SIFT_norm > TM_norm + 0.15 → elegir SIFT\n",
    "   - Auto mode: Si multi_tm ≥ 5 detecciones AND norm > 0.5 → elegir multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-Detector: Unified Logo Detection Framework\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DetectionResult:\n",
    "    \"\"\"Standardized detection result from any detector.\"\"\"\n",
    "    method: str\n",
    "    bboxes: List[Tuple]\n",
    "    raw_score: float\n",
    "    norm_score: float\n",
    "    num: int\n",
    "    details: str = \"\"\n",
    "\n",
    "\n",
    "class UnifiedLogoDetector:\n",
    "    \"\"\"Meta-detector that runs multiple specialized detectors and selects the best result.\"\"\"\n",
    "    \n",
    "    def __init__(self, template: np.ndarray):\n",
    "        self.template = template\n",
    "        self.th, self.tw = template.shape\n",
    "        all_variants = create_template_variants(template, include_inverted=True)\n",
    "        self.template_clahe = all_variants['clahe']\n",
    "        self.template_inv = all_variants['inverted']\n",
    "        self.template_inv_clahe = all_variants['inverted_clahe']\n",
    "        self.template_variants = {'normal': all_variants['clahe'], 'inverted': all_variants['inverted_clahe']}\n",
    "        self.sift_min_matches = 6\n",
    "        \n",
    "    def _normalize_tm_score(self, max_val: float) -> float:\n",
    "        return np.clip((max_val - 0.2) / 0.5, 0.0, 1.0)\n",
    "    \n",
    "    def _normalize_sift_score(self, num_inliers: int) -> float:\n",
    "        return min(1.0, num_inliers / 25.0)\n",
    "    \n",
    "    def _normalize_multi_score(self, mean_tm_score: float, num_detections: int) -> float:\n",
    "        return 0.6 * self._normalize_tm_score(mean_tm_score) + 0.4 * min(1.0, num_detections / 10.0)\n",
    "    \n",
    "    def run_single_tm(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        h, w = img_gray.shape\n",
    "        # Use wider scale range to cover both small logos (coca_multi ~10%) and large logos\n",
    "        scales = compute_scale_range(w, self.tw, 0.08, 0.85, num_scales=35)\n",
    "        bbox, score, details = template_match_multiscale(\n",
    "            img_gray, self.template_variants, scales, threshold=0.30,\n",
    "            preprocess='clahe', aspect_filter=(1.5, 4.5), min_width_ratio=0.05\n",
    "        )\n",
    "        if bbox is None:\n",
    "            return DetectionResult(\"single_tm\", [], 0.0, 0.0, 0, \"No detection\")\n",
    "        return DetectionResult(\"single_tm\", [bbox], score, self._normalize_tm_score(score), 1, details)\n",
    "    \n",
    "    def run_edge_tm(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        h, w = img_gray.shape\n",
    "        scales = compute_scale_range(w, self.tw, 0.08, 0.85, num_scales=35)\n",
    "        bbox, score, details = template_match_edges(img_gray, self.template, scales, threshold=0.20)\n",
    "        if bbox is None:\n",
    "            return DetectionResult(\"edge_tm\", [], 0.0, 0.0, 0, \"No detection\")\n",
    "        return DetectionResult(\"edge_tm\", [bbox], score, self._normalize_tm_score(score), 1, details)\n",
    "    \n",
    "    def run_sift_single(self, img_gray: np.ndarray) -> DetectionResult:\n",
    "        bbox, num_inliers, details = detect_by_sift(img_gray, self.template, min_matches=self.sift_min_matches)\n",
    "        if bbox is None:\n",
    "            return DetectionResult(\"sift_single\", [], 0.0, 0.0, 0, details)\n",
    "        return DetectionResult(\"sift_single\", [bbox], float(num_inliers), self._normalize_sift_score(num_inliers), 1, details)\n",
    "    \n",
    "    def run_multi_tm(self, img_gray: np.ndarray, img_rgb: np.ndarray) -> DetectionResult:\n",
    "        \"\"\"Multi-logo detection - tuned for coca_multi.png (same params as Assignment 2).\"\"\"\n",
    "        h, w = img_gray.shape\n",
    "        \n",
    "        # Same parameters as Assignment 2\n",
    "        width_ratio_min, width_ratio_max = 0.09, 0.21\n",
    "        height_ratio_min, height_ratio_max = 0.05, 0.13\n",
    "        w_min, w_max = int(w * width_ratio_min), int(w * width_ratio_max)\n",
    "        h_min, h_max = int(h * height_ratio_min), int(h * height_ratio_max)\n",
    "        scales = compute_scale_range(w, self.tw, width_ratio_min, width_ratio_max, num_scales=15)\n",
    "        \n",
    "        detections = detect_multiple_logos(\n",
    "            img_gray, img_rgb, self.template_inv_clahe, scales,\n",
    "            threshold_sigma=2.5, min_threshold=0.34, iou_threshold=0.20,\n",
    "            size_filter=(w_min, w_max), height_filter=(h_min, h_max),\n",
    "            aspect_filter=(2.0, 3.8),\n",
    "            y_ranges=[(0.08, 0.35), (0.68, 0.95)],  # Top/bottom shelf\n",
    "            local_max_kernel=11, peak_isolation_ratio=0.5,\n",
    "            color_check=True, min_red_dominance=25, min_red_value=110\n",
    "        )\n",
    "        \n",
    "        if not detections:\n",
    "            return DetectionResult(\"multi_tm\", [], 0.0, 0.0, 0, \"No detections\")\n",
    "        \n",
    "        mean_score = np.mean([d[4] for d in detections])\n",
    "        bboxes = [(d[0], d[1], d[2], d[3]) for d in detections]\n",
    "        return DetectionResult(\"multi_tm\", bboxes, mean_score,\n",
    "                              self._normalize_multi_score(mean_score, len(detections)),\n",
    "                              len(detections), f\"{len(detections)} logos, avg={mean_score:.3f}\")\n",
    "    \n",
    "    def detect(self, img_rgb: np.ndarray, img_gray: np.ndarray, mode: str = \"single\") -> Dict:\n",
    "        results = {\n",
    "            'single_tm': self.run_single_tm(img_gray),\n",
    "            'edge_tm': self.run_edge_tm(img_gray),\n",
    "            'sift_single': self.run_sift_single(img_gray),\n",
    "            'multi_tm': self.run_multi_tm(img_gray, img_rgb) if mode in ['multi', 'auto'] else DetectionResult(\"multi_tm\", [], 0.0, 0.0, 0, \"Skipped\")\n",
    "        }\n",
    "        \n",
    "        print(\"Detector Results:\")\n",
    "        for name, r in results.items():\n",
    "            print(f\"  {name:12s}: num={r.num:2d}, norm={r.norm_score:.3f}, raw={r.raw_score:.3f}, {r.details}\")\n",
    "        \n",
    "        if mode == \"multi\":\n",
    "            best, reason = results['multi_tm'], \"Mode=multi\"\n",
    "        elif mode == \"single\":\n",
    "            sift = results['sift_single']\n",
    "            best_tm = max([results['single_tm'], results['edge_tm']], key=lambda r: r.norm_score if r.num > 0 else 0)\n",
    "            \n",
    "            # Standard threshold for SIFT vs TM selection\n",
    "            if sift.num > 0 and sift.norm_score > best_tm.norm_score + 0.15:\n",
    "                best, reason = sift, f\"SIFT ({sift.raw_score:.0f} inliers)\"\n",
    "            elif best_tm.num > 0:\n",
    "                best, reason = best_tm, f\"Best TM (norm={best_tm.norm_score:.2f})\"\n",
    "            else:\n",
    "                best, reason = sift if sift.num > 0 else results['single_tm'], \"Fallback\"\n",
    "        else:  # auto\n",
    "            multi = results['multi_tm']\n",
    "            if multi.num >= 5 and multi.norm_score > 0.5:\n",
    "                best, reason = multi, f\"Auto: Multi ({multi.num} logos)\"\n",
    "            else:\n",
    "                sift = results['sift_single']\n",
    "                best_tm = max([results['single_tm'], results['edge_tm']], key=lambda r: r.norm_score if r.num > 0 else 0)\n",
    "                if sift.num > 0 and sift.norm_score > best_tm.norm_score + 0.15:\n",
    "                    best, reason = sift, f\"Auto: SIFT ({sift.raw_score:.0f} inliers)\"\n",
    "                elif best_tm.num > 0:\n",
    "                    best, reason = best_tm, f\"Auto: Best TM\"\n",
    "                else:\n",
    "                    best, reason = sift if sift.num > 0 else results['single_tm'], \"Auto: Fallback\"\n",
    "        \n",
    "        print(f\"\\nSelected: {best.method} - {reason}\")\n",
    "        return {'best': best, 'all_results': results, 'reason': reason}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "uoxhi3w6lr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE DETECTION MODE\n",
      "Processing: coca_logo_1.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.415, raw=0.408, TM-inverted@0.12\n",
      "  edge_tm     : num= 1, norm=0.425, raw=0.413, TM-edges@0.43\n",
      "  sift_single : num= 1, norm=1.000, raw=40.000, SIFT-inverted(40 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (40 inliers)\n",
      "Processing: coca_logo_2.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.480, raw=0.440, TM-inverted@0.17\n",
      "  edge_tm     : num= 1, norm=0.251, raw=0.326, TM-edges@0.10\n",
      "  sift_single : num= 1, norm=1.000, raw=31.000, SIFT-inverted(31 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (31 inliers)\n",
      "Processing: coca_multi.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.566, raw=0.483, TM-inverted@0.30\n",
      "  edge_tm     : num= 1, norm=0.131, raw=0.265, TM-edges@0.25\n",
      "  sift_single : num= 1, norm=0.240, raw=6.000, SIFT-inverted(6 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: single_tm - Best TM (norm=0.57)\n",
      "Processing: coca_retro_1.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.902, raw=0.651, TM-normal@1.32\n",
      "  edge_tm     : num= 1, norm=0.169, raw=0.284, TM-edges@0.14\n",
      "  sift_single : num= 1, norm=0.720, raw=18.000, SIFT-normal(18 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: single_tm - Best TM (norm=0.90)\n",
      "Processing: coca_retro_2.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.913, raw=0.657, TM-inverted@0.39\n",
      "  edge_tm     : num= 1, norm=0.255, raw=0.327, TM-edges@0.39\n",
      "  sift_single : num= 1, norm=1.000, raw=27.000, SIFT-inverted(27 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: single_tm - Best TM (norm=0.91)\n",
      "Processing: COCA-COLA-LOGO.jpg\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.442, raw=0.421, TM-inverted@0.29\n",
      "  edge_tm     : num= 0, norm=0.000, raw=0.000, No detection\n",
      "  sift_single : num= 1, norm=0.960, raw=24.000, SIFT-inverted(24 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (24 inliers)\n",
      "Processing: logo_1.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.591, raw=0.495, TM-inverted@0.18\n",
      "  edge_tm     : num= 1, norm=0.108, raw=0.254, TM-edges@0.14\n",
      "  sift_single : num= 1, norm=1.000, raw=31.000, SIFT-inverted(31 inliers)\n",
      "  multi_tm    : num= 0, norm=0.000, raw=0.000, Skipped\n",
      "\n",
      "Selected: sift_single - SIFT (31 inliers)\n",
      "SINGLE DETECTION - SUMMARY\n",
      "Image                     Method              norm Details                       \n",
      "coca_logo_1.png           sift_single        1.000 SIFT-inverted(40 inliers)     \n",
      "coca_logo_2.png           sift_single        1.000 SIFT-inverted(31 inliers)     \n",
      "coca_multi.png            single_tm          0.566 TM-inverted@0.30              \n",
      "coca_retro_1.png          single_tm          0.902 TM-normal@1.32                \n",
      "coca_retro_2.png          single_tm          0.913 TM-inverted@0.39              \n",
      "COCA-COLA-LOGO.jpg        sift_single        0.960 SIFT-inverted(24 inliers)     \n",
      "logo_1.png                sift_single        1.000 SIFT-inverted(31 inliers)     \n"
     ]
    }
   ],
   "source": [
    "# Single Detection Mode (all images)\n",
    "\n",
    "# Initialize the unified detector\n",
    "detector = UnifiedLogoDetector(template)\n",
    "\n",
    "# Test images\n",
    "test_images = [\n",
    "    \"coca_logo_1.png\",\n",
    "    \"coca_logo_2.png\",\n",
    "    \"coca_multi.png\",\n",
    "    \"coca_retro_1.png\",\n",
    "    \"coca_retro_2.png\",\n",
    "    \"COCA-COLA-LOGO.jpg\",\n",
    "    \"logo_1.png\"\n",
    "]\n",
    "\n",
    "# Run single detection on all images\n",
    "print(\"SINGLE DETECTION MODE\")\n",
    "\n",
    "unified_results = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    print(f\"Processing: {img_name}\")\n",
    "    \n",
    "    img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "    \n",
    "    # Run unified detector in single mode\n",
    "    result = detector.detect(img_rgb, img_gray, mode=\"single\")\n",
    "    \n",
    "    unified_results.append({\n",
    "        'image': img_name,\n",
    "        'result': result['best'],\n",
    "        'reason': result['reason'],\n",
    "        'all_results': result['all_results']\n",
    "    })\n",
    "\n",
    "print(\"SINGLE DETECTION - SUMMARY\")\n",
    "print(f\"{'Image':<25} {'Method':<15} {'norm':>8} {'Details':<30}\")\n",
    "\n",
    "for r in unified_results:\n",
    "    img = r['image']\n",
    "    best = r['result']\n",
    "    print(f\"{img:<25} {best.method:<15} {best.norm_score:>8.3f} {best.details:<30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7vk51qkvs3m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/TP3-assignment3_single.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize Single Detection Results\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(unified_results):\n",
    "    img_rgb, _, _ = load_image(f\"images/{r['image']}\")\n",
    "    img_out = draw_bboxes(img_rgb, r['result'].bboxes)\n",
    "    \n",
    "    axes[idx].imshow(img_out)\n",
    "    \n",
    "    best = r['result']\n",
    "    title = f\"{r['image']}\\n{best.method} | norm={best.norm_score:.2f}\"\n",
    "    axes[idx].set_title(title, fontsize=9)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(len(unified_results), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Unified Meta-Detector - Single Detection Mode', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-assignment3_single.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: results/TP3-assignment3_single.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sa44gx4y7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTI DETECTION MODE\n",
      "Processing: coca_multi.png\n",
      "Detector Results:\n",
      "  single_tm   : num= 1, norm=0.566, raw=0.483, TM-inverted@0.30\n",
      "  edge_tm     : num= 1, norm=0.131, raw=0.265, TM-edges@0.25\n",
      "  sift_single : num= 0, norm=0.000, raw=0.000, SIFT: no valid homography found\n",
      "  multi_tm    : num=18, norm=0.653, raw=0.411, 18 logos, avg=0.411\n",
      "\n",
      "Selected: multi_tm - Mode=multi\n",
      "\n",
      "Multi-detection found 18 logos\n",
      "Average TM score: 0.411\n",
      "Normalized score: 0.653\n",
      "\n",
      "Saved: results/TP3-assignment3_multi.png\n"
     ]
    }
   ],
   "source": [
    "# Multi Detection Mode (coca_multi.png only)\n",
    "\n",
    "print(\"MULTI DETECTION MODE\")\n",
    "\n",
    "# Test images with multiple logos\n",
    "multi_test_images = [\n",
    "    \"coca_multi.png\",      # Shelf with many bottles\n",
    "]\n",
    "\n",
    "multi_results = []\n",
    "\n",
    "for img_name in multi_test_images:\n",
    "    print(f\"Processing: {img_name}\")\n",
    "        \n",
    "    img_rgb, img_gray, img_bgr = load_image(f\"images/{img_name}\")\n",
    "    \n",
    "    # Run unified detector in multi mode\n",
    "    result = detector.detect(img_rgb, img_gray, mode=\"multi\")\n",
    "    multi_result = result['best']\n",
    "    \n",
    "    multi_results.append({\n",
    "        'image': img_name,\n",
    "        'result': multi_result,\n",
    "        'img_rgb': img_rgb\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nMulti-detection found {multi_result.num} logos\")\n",
    "    print(f\"Average TM score: {multi_result.raw_score:.3f}\")\n",
    "    print(f\"Normalized score: {multi_result.norm_score:.3f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "r = multi_results[0]\n",
    "img_out = draw_bboxes(r['img_rgb'], r['result'].bboxes)\n",
    "axes.imshow(img_out)\n",
    "axes.set_title(f\"{r['image']}\\n{r['result'].num} logos detected | norm={r['result'].norm_score:.2f}\")\n",
    "axes.axis('off')\n",
    "\n",
    "plt.suptitle('Assignment 3: Unified Meta-Detector - Multi Detection Mode', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/TP3-assignment3_multi.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: results/TP3-assignment3_multi.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wieu3qt53z",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusiones\n",
    "\n",
    "### Enfoque\n",
    "\n",
    "El enfoque inicial fue intentar desarrollar un algoritmo genérico que funcionara para todas las imágenes de manera uniforme. Sin embargo, rápidamente se evidenció que generalizar un único método de detección para todos los casos resultaba difícil debido a la variabilidad en las características de las imágenes:\n",
    "\n",
    "- **Inversión de contraste:** Texto blanco sobre fondo rojo produce contraste invertido en escala de grises\n",
    "- **Superficies curvas:** Latas y botellas distorsionan la geometría del logo\n",
    "- **Variaciones de escala:** Logos desde ~10% hasta ~80% del ancho de imagen\n",
    "- **Logos retro:** Diferencias estructurales respecto al template moderno\n",
    "- **Múltiples instancias:** Detección de varios logos en una misma imagen\n",
    "\n",
    "### Análisis caso por caso\n",
    "\n",
    "Ante esta dificultad, se optó por analizar cada imagen individualmente, identificando sus características particulares y seleccionando el método más adecuado:\n",
    "\n",
    "| Característica | Método óptimo | Justificación |\n",
    "|----------------|---------------|---------------|\n",
    "| Fondo limpio, bordes definidos | Edge TM | Canny preserva contornos, invariante a inversión |\n",
    "| Superficie curva/distorsionada | SIFT | Maneja transformaciones de perspectiva |\n",
    "| Contraste invertido (blanco/rojo) | TM invertido | Corrige la inversión usando template negativo |\n",
    "| Logo estructuralmente diferente | SIFT | Encuentra correspondencias parciales |\n",
    "| Múltiples logos similares | Multi-TM + NMS | Detecta todos los picos de correlación |\n",
    "\n",
    "### Algoritmo unificado (Meta-Detector)\n",
    "\n",
    "Con el conocimiento adquirido del análisis individual, se construyó un **meta-detector** que:\n",
    "\n",
    "1. Ejecuta múltiples detectores especializados en paralelo (TM, Edge-TM, SIFT)\n",
    "2. Normaliza las puntuaciones a un rango comparable [0, 1]\n",
    "3. Selecciona automáticamente el mejor resultado según reglas de decisión\n",
    "\n",
    "Este enfoque permitió generalizar la detección sin hardcodear el método por imagen, aunque requirió ajustes adicionales:\n",
    "\n",
    "- **Rangos de escala amplios** (8%-85% del ancho) para cubrir logos pequeños y grandes\n",
    "- **Umbral adaptativo** para la selección SIFT vs TM (norm_SIFT > norm_TM + 0.15)\n",
    "- **Parámetros específicos** para multi-detección (filtros de color, bandas horizontales, aspect ratio)\n",
    "\n",
    "### Resumen\n",
    "\n",
    "1. **No existe un método universal:** Cada técnica (TM, SIFT, Edge) tiene fortalezas y debilidades específicas\n",
    "2. **El análisis previo es fundamental:** Entender las características de cada imagen guía la selección del método\n",
    "3. **La fusión de detectores es efectiva:** Combinar múltiples métodos y comparar scores produce resultados más robustos\n",
    "4. **El tuning es inevitable:** Incluso con un meta-detector, se requieren ajustes finos para casos límite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
