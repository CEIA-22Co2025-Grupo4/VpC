{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d1485",
   "metadata": {},
   "source": [
    "# TP3 - Find the soda logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdaf884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467ba69",
   "metadata": {},
   "source": [
    "## Find the soda logo within the provided images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20eb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ff4b",
   "metadata": {},
   "source": [
    "1. Obtain a logo detection in each image without false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(path, max_size=1200):\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    \n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path, max_size=400):\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "# Note: The create_template_variants function is defined in Cell 5 (DETECTION FUNCTIONS)\n",
    "# This cell only contains utility functions for loading and visualization\n",
    "\n",
    "\n",
    "def draw_detections(img_rgb, detections):\n",
    "    \"\"\"Draw detection rectangles on image with confidence scores.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for det in detections:\n",
    "        x, y, w, h = det[:4]\n",
    "        score = det[4] if len(det) > 4 else 1.0\n",
    "        \n",
    "        # Color according to confidence level (green high, yellow medium, red low)\n",
    "        if score >= 0.7:\n",
    "            color = (0, 255, 0)  # Green\n",
    "        elif score >= 0.5:\n",
    "            color = (255, 255, 0)  # Yellow\n",
    "        else:\n",
    "            color = (255, 0, 0)  # Red\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, 2)\n",
    "        \n",
    "        # Display confidence level\n",
    "        label = f'{score:.2f}'\n",
    "        label_size, _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        label_y = max(y - 5, label_size[1])\n",
    "        cv.rectangle(img_out, (x, label_y - label_size[1] - 5), \n",
    "                    (x + label_size[0], label_y + 5), color, -1)\n",
    "        cv.putText(img_out, label, (x, label_y), \n",
    "                  cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_results_grid(results, title, save_path=None):\n",
    "    \"\"\"Plot results in a grid layout with confidence information.\"\"\"\n",
    "    n = len(results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img_rgb, detections, img_name) in enumerate(results):\n",
    "        img_result = draw_detections(img_rgb, detections)\n",
    "        axes[idx].imshow(img_result)\n",
    "        \n",
    "        # Display confidence information in the title\n",
    "        if detections:\n",
    "            scores = [d[4] for d in detections if len(d) > 4]\n",
    "            avg_conf = np.mean(scores) if scores else 0.0\n",
    "            conf_str = f\"avg confidence: {avg_conf:.2f}\" if len(detections) > 1 else f\"confidence: {scores[0]:.2f}\"\n",
    "            axes[idx].set_title(f\"{img_name}\\n{len(detections)} detection(s), {conf_str}\")\n",
    "        else:\n",
    "            axes[idx].set_title(f\"{img_name}\\n0 detections\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for idx in range(n, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single_result(img_rgb, detections, title, save_path=None):\n",
    "    \"\"\"Plot single image result with confidence information.\"\"\"\n",
    "    img_result = draw_detections(img_rgb, detections)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_result)\n",
    "    \n",
    "    # Display confidence information in the title\n",
    "    if detections:\n",
    "        scores = [d[4] for d in detections if len(d) > 4]\n",
    "        avg_conf = np.mean(scores) if scores else 0.0\n",
    "        min_conf = np.min(scores) if scores else 0.0\n",
    "        max_conf = np.max(scores) if scores else 0.0\n",
    "        title_with_conf = f\"{title} | {len(detections)} detections\\nConfidence: min={min_conf:.2f}, avg={avg_conf:.2f}, max={max_conf:.2f}\"\n",
    "    else:\n",
    "        title_with_conf = f\"{title} | 0 detections\"\n",
    "    \n",
    "    plt.title(title_with_conf, fontsize=12)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ad9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_template_variants(template):\n",
    "    \"\"\"\n",
    "    Create useful template variants for template matching.\n",
    "    Preprocessing matches image preprocessing for better alignment.\n",
    "    Optimized: removed redundant variants to improve performance.\n",
    "    \"\"\"\n",
    "    # Apply CLAHE first (matching image preprocessing)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_template = clahe.apply(template)\n",
    "    \n",
    "    # Smooth variant (with CLAHE applied)\n",
    "    smooth = cv.GaussianBlur(clahe_template, (3, 3), 0)\n",
    "    \n",
    "    # Inverted variant (with CLAHE applied)\n",
    "    inverted = 255 - clahe_template\n",
    "    \n",
    "    # Return only essential variants (removed redundant 'original' and 'equalized' for speed)\n",
    "    return {\n",
    "        'clahe': clahe_template,  # Base variant matching image preprocessing\n",
    "        'smooth': smooth,          # Helps with slight blur variations\n",
    "        'inverted': inverted,      # Helps with contrast inversions\n",
    "    }\n",
    "\n",
    "\n",
    "def preprocess_image(img_gray):\n",
    "    \"\"\"\n",
    "    Preprocess image before template matching.\n",
    "    Uses CLAHE to match template preprocessing for better alignment.\n",
    "    \"\"\"\n",
    "    # Apply CLAHE for contrast normalization (matching template preprocessing)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img_gray)\n",
    "    # Light Gaussian blur to reduce noise while preserving edges\n",
    "    img = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    inter_w = max(0, xi2 - xi1)\n",
    "    inter_h = max(0, yi2 - yi1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def nms_global(detections, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression globally across all detections.\n",
    "    detections: list of (x, y, w, h, score)\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n",
    "    \n",
    "    keep = []\n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "\n",
    "def find_by_template(img_gray, template_variants, single_detection=True, min_threshold=0.30):\n",
    "    \"\"\"\n",
    "    Multi-scale template matching - OPTIMIZED VERSION.\n",
    "    - Reduced to 20 scales (from 30) for better performance\n",
    "    - Optimized threshold calculation using numpy operations\n",
    "    - Reduced template variants (3 instead of 5)\n",
    "    - Early filtering to reduce unnecessary operations\n",
    "    \n",
    "    For multiple detections, uses much lower threshold to catch all instances.\n",
    "    Following 01.Templates.ipynb Cell 6 approach but adapted for multi-scale.\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    img_processed = preprocess_image(img_gray)\n",
    "    \n",
    "    # Adjust threshold according to detection mode\n",
    "    # For multiple detections, use much more permissive thresholds\n",
    "    if single_detection:\n",
    "        base_threshold = 0.25  # For single detection, keep moderate threshold\n",
    "        adaptive_multiplier = 1.5\n",
    "    else:\n",
    "        # For multiple detections: much lower threshold to catch all instances\n",
    "        base_threshold = 0.15  # Very low threshold to catch all instances\n",
    "        adaptive_multiplier = 0.3  # Very permissive multiplier\n",
    "    \n",
    "    # Reduced scales from 30 to 20 for better performance (still covers range 0.2-1.6)\n",
    "    scales = np.linspace(0.2, 1.6, 20)\n",
    "    all_detections = []\n",
    "    \n",
    "    # Pre-calculate aspect ratio bounds to avoid repeated calculations\n",
    "    aspect_min, aspect_max = 0.5, 3.0\n",
    "    \n",
    "    for scale in scales:\n",
    "        for name, tmpl in template_variants.items():\n",
    "            th, tw = tmpl.shape\n",
    "            new_w = int(tw * scale)\n",
    "            new_h = int(th * scale)\n",
    "            \n",
    "            # Early filtering: skip invalid sizes\n",
    "            if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "                continue\n",
    "            \n",
    "            # Check aspect ratio early to avoid expensive template matching\n",
    "            aspect = new_w / new_h if new_h > 0 else 0\n",
    "            if not (aspect_min < aspect < aspect_max):\n",
    "                continue\n",
    "            \n",
    "            scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n",
    "            # Use TM_CCOEFF_NORMED as in 01.Templates.ipynb Cell 6\n",
    "            res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # Optimized threshold calculation using numpy\n",
    "            if single_detection:\n",
    "                # Adaptive threshold for single detection\n",
    "                mean_val = res.mean()\n",
    "                std_val = res.std()\n",
    "                threshold = max(mean_val + adaptive_multiplier * std_val, base_threshold)\n",
    "            else:\n",
    "                # For multiple detections: use more permissive approach\n",
    "                # Optimized: use numpy operations directly\n",
    "                mean_val = res.mean()\n",
    "                std_val = res.std()\n",
    "                adaptive_threshold = mean_val + adaptive_multiplier * std_val\n",
    "                max_allowed_threshold = 0.35  # Cap for multiple detections\n",
    "                threshold = min(adaptive_threshold, max_allowed_threshold)\n",
    "                threshold = max(threshold, base_threshold)  # Ensure minimum threshold\n",
    "            \n",
    "            # np.where() as in 01.Templates.ipynb Cell 6\n",
    "            # Optimized: directly get scores where threshold is met\n",
    "            locations = np.where(res >= threshold)\n",
    "            \n",
    "            # Batch process locations for better performance\n",
    "            for pt in zip(*locations[::-1]):\n",
    "                x, y = pt\n",
    "                score = res[y, x]\n",
    "                all_detections.append((x, y, new_w, new_h, score))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return (None, None, 0) if single_detection else []\n",
    "    \n",
    "    # Apply NMS to filter overlaps\n",
    "    iou_thresh = 0.25 if single_detection else 0.35\n",
    "    final_detections = nms_global(all_detections, iou_threshold=iou_thresh)\n",
    "    \n",
    "    if single_detection:\n",
    "        best = final_detections[0]\n",
    "        return (best[0], best[1], best[2], best[3]), 'template', best[4]\n",
    "    \n",
    "    # For multiple detections, filter out very low confidence detections\n",
    "    if final_detections:\n",
    "        min_confidence = 0.30\n",
    "        final_detections = [d for d in final_detections if d[4] >= min_confidence]\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "\n",
    "def detect_logo(img_bgr, img_gray, template_variants, single_detection=True):\n",
    "    \"\"\"\n",
    "    Detection pipeline using only template matching (aligned with 01.Templates.ipynb).\n",
    "    - Single detection: Template matching with strict threshold\n",
    "    - Multi detection: Template matching with more permissive threshold (like 01.Templates.ipynb Cell 6)\n",
    "    \"\"\"\n",
    "    if single_detection:\n",
    "        bbox, method, score = find_by_template(img_gray, template_variants, single_detection=True)\n",
    "        if bbox:\n",
    "            return bbox, method, score\n",
    "        return None, None, 0\n",
    "    else:\n",
    "        # Multiple detections using template matching (like 01.Templates.ipynb Cell 6)\n",
    "        # Lower threshold for multiple detections to catch all instances\n",
    "        detections = find_by_template(img_gray, template_variants, single_detection=False, min_threshold=0.35)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "up51dq952i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEMPLATE VARIANTS VISUALIZATION (3 optimized variants)\n",
    "# =============================================================================\n",
    "\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "variants = create_template_variants(template)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(variants), figsize=(6 * len(variants), 4))\n",
    "\n",
    "for ax, (name, img) in zip(axes, variants.items()):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(f'Template Variants ({len(variants)} optimized variants)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/template_variants.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af173e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 1: Single Detection per Image\n",
    "# =============================================================================\n",
    "\n",
    "IMAGES_DIR = 'images/'\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "results = []\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "    img_rgb, img_gray, img_bgr = load_image(img_path)\n",
    "    \n",
    "    bbox, method, match_val = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        # Save with real confidence score\n",
    "        detections = [(x, y, w, h, match_val)]\n",
    "        print(f\"{img_name}: {method} (confidence={match_val:.3f})\")\n",
    "    else:\n",
    "        detections = []\n",
    "        print(f\"{img_name}: NOT DETECTED\")\n",
    "    \n",
    "    results.append((img_rgb, detections, img_name))\n",
    "\n",
    "plot_results_grid(results, \"ASSIGNMENT 1: Single Detection per Image\", 'results/Figure_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891386f8",
   "metadata": {},
   "source": [
    "2. Propose and validate an algorithm for multiple detections in the image coca_multi.png using the same template from item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gktc1c4y0n7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 565 logo instances in coca_multi.png\n",
      "  Detection 1: position=(403,261), size=(138x60), confidence=0.480\n",
      "  Detection 2: position=(400,547), size=(109x47), confidence=0.479\n",
      "  Detection 3: position=(270,536), size=(138x60), confidence=0.478\n",
      "  Detection 4: position=(504,261), size=(138x60), confidence=0.475\n",
      "  Detection 5: position=(533,537), size=(138x60), confidence=0.474\n",
      "  Detection 6: position=(269,261), size=(138x60), confidence=0.473\n",
      "  Detection 7: position=(614,536), size=(138x60), confidence=0.472\n",
      "  Detection 8: position=(457,537), size=(138x60), confidence=0.471\n",
      "  Detection 9: position=(589,262), size=(138x60), confidence=0.466\n",
      "  Detection 10: position=(203,536), size=(138x60), confidence=0.465\n",
      "  Detection 11: position=(49,533), size=(138x60), confidence=0.464\n",
      "  Detection 12: position=(173,261), size=(138x60), confidence=0.460\n",
      "  Detection 13: position=(137,535), size=(138x60), confidence=0.459\n",
      "  Detection 14: position=(93,261), size=(138x60), confidence=0.455\n",
      "  Detection 15: position=(13,260), size=(138x60), confidence=0.452\n",
      "  Detection 16: position=(0,542), size=(109x47), confidence=0.449\n",
      "  Detection 17: position=(416,14), size=(168x73), confidence=0.446\n",
      "  Detection 18: position=(661,262), size=(138x60), confidence=0.443\n",
      "  Detection 19: position=(679,546), size=(109x47), confidence=0.441\n",
      "  Detection 20: position=(335,262), size=(138x60), confidence=0.440\n",
      "  Detection 21: position=(597,226), size=(80x35), confidence=0.440\n",
      "  Detection 22: position=(211,3), size=(197x86), confidence=0.439\n",
      "  Detection 23: position=(329,13), size=(168x73), confidence=0.439\n",
      "  Detection 24: position=(579,16), size=(168x73), confidence=0.435\n",
      "  Detection 25: position=(339,547), size=(109x47), confidence=0.433\n",
      "  Detection 26: position=(706,153), size=(80x35), confidence=0.431\n",
      "  Detection 27: position=(500,14), size=(168x73), confidence=0.428\n",
      "  Detection 28: position=(32,150), size=(80x35), confidence=0.424\n",
      "  Detection 29: position=(428,450), size=(286x125), confidence=0.421\n",
      "  Detection 30: position=(137,228), size=(80x35), confidence=0.415\n",
      "  Detection 31: position=(41,6), size=(197x86), confidence=0.415\n",
      "  Detection 32: position=(654,428), size=(80x35), confidence=0.413\n",
      "  Detection 33: position=(201,154), size=(80x35), confidence=0.412\n",
      "  Detection 34: position=(236,432), size=(80x35), confidence=0.411\n",
      "  Detection 35: position=(468,271), size=(109x47), confidence=0.410\n",
      "  Detection 36: position=(465,285), size=(315x138), confidence=0.409\n",
      "  Detection 37: position=(243,443), size=(315x138), confidence=0.409\n",
      "  Detection 38: position=(478,227), size=(80x35), confidence=0.408\n",
      "  Detection 39: position=(581,36), size=(80x35), confidence=0.407\n",
      "  Detection 40: position=(281,146), size=(80x35), confidence=0.406\n",
      "  Detection 41: position=(75,425), size=(80x35), confidence=0.406\n",
      "  Detection 42: position=(489,427), size=(80x35), confidence=0.404\n",
      "  Detection 43: position=(31,281), size=(345x151), confidence=0.403\n",
      "  Detection 44: position=(84,450), size=(286x125), confidence=0.403\n",
      "  Detection 45: position=(221,228), size=(80x35), confidence=0.402\n",
      "  Detection 46: position=(542,154), size=(80x35), confidence=0.401\n",
      "  Detection 47: position=(37,162), size=(315x138), confidence=0.400\n",
      "  Detection 48: position=(260,226), size=(80x35), confidence=0.400\n",
      "  Detection 49: position=(407,433), size=(80x35), confidence=0.400\n",
      "  Detection 50: position=(0,420), size=(80x35), confidence=0.399\n",
      "  Detection 51: position=(556,226), size=(80x35), confidence=0.399\n",
      "  Detection 52: position=(283,281), size=(345x151), confidence=0.399\n",
      "  Detection 53: position=(409,35), size=(80x35), confidence=0.398\n",
      "  Detection 54: position=(676,227), size=(80x35), confidence=0.397\n",
      "  Detection 55: position=(664,302), size=(109x47), confidence=0.396\n",
      "  Detection 56: position=(602,480), size=(197x86), confidence=0.395\n",
      "  Detection 57: position=(570,431), size=(80x35), confidence=0.395\n",
      "  Detection 58: position=(625,152), size=(80x35), confidence=0.395\n",
      "  Detection 59: position=(60,228), size=(80x35), confidence=0.395\n",
      "  Detection 60: position=(14,226), size=(80x35), confidence=0.395\n",
      "  Detection 61: position=(22,477), size=(197x86), confidence=0.393\n",
      "  Detection 62: position=(114,151), size=(80x35), confidence=0.393\n",
      "  Detection 63: position=(181,228), size=(80x35), confidence=0.390\n",
      "  Detection 64: position=(330,63), size=(109x47), confidence=0.389\n",
      "  Detection 65: position=(369,146), size=(80x35), confidence=0.387\n",
      "  Detection 66: position=(271,422), size=(138x60), confidence=0.386\n",
      "  Detection 67: position=(317,556), size=(80x35), confidence=0.384\n",
      "  Detection 68: position=(715,227), size=(80x35), confidence=0.384\n",
      "  Detection 69: position=(204,161), size=(315x138), confidence=0.384\n",
      "  Detection 70: position=(262,71), size=(80x35), confidence=0.383\n",
      "  Detection 71: position=(573,93), size=(109x47), confidence=0.383\n",
      "  Detection 72: position=(471,170), size=(286x125), confidence=0.383\n",
      "  Detection 73: position=(98,229), size=(80x35), confidence=0.382\n",
      "  Detection 74: position=(156,429), size=(80x35), confidence=0.381\n",
      "  Detection 75: position=(409,234), size=(227x99), confidence=0.380\n",
      "  Detection 76: position=(296,90), size=(109x47), confidence=0.380\n",
      "  Detection 77: position=(393,226), size=(80x35), confidence=0.380\n",
      "  Detection 78: position=(633,503), size=(80x35), confidence=0.379\n",
      "  Detection 79: position=(406,54), size=(138x60), confidence=0.379\n",
      "  Detection 80: position=(701,76), size=(80x35), confidence=0.379\n",
      "  Detection 81: position=(612,74), size=(80x35), confidence=0.378\n",
      "  Detection 82: position=(637,227), size=(80x35), confidence=0.378\n",
      "  Detection 83: position=(498,94), size=(109x47), confidence=0.376\n",
      "  Detection 84: position=(379,191), size=(227x99), confidence=0.375\n",
      "  Detection 85: position=(616,182), size=(80x35), confidence=0.375\n",
      "  Detection 86: position=(470,505), size=(80x35), confidence=0.374\n",
      "  Detection 87: position=(96,300), size=(109x47), confidence=0.373\n",
      "  Detection 88: position=(327,280), size=(80x35), confidence=0.373\n",
      "  Detection 89: position=(496,35), size=(80x35), confidence=0.372\n",
      "  Detection 90: position=(556,72), size=(80x35), confidence=0.372\n",
      "  Detection 91: position=(208,501), size=(138x60), confidence=0.372\n",
      "  Detection 92: position=(449,149), size=(80x35), confidence=0.371\n",
      "  Detection 93: position=(152,234), size=(256x112), confidence=0.371\n",
      "  Detection 94: position=(274,556), size=(80x35), confidence=0.370\n",
      "  Detection 95: position=(443,45), size=(197x86), confidence=0.370\n",
      "  Detection 96: position=(174,300), size=(109x47), confidence=0.370\n",
      "  Detection 97: position=(13,66), size=(109x47), confidence=0.368\n",
      "  Detection 98: position=(431,227), size=(80x35), confidence=0.367\n",
      "  Detection 99: position=(316,431), size=(80x35), confidence=0.366\n",
      "  Detection 100: position=(49,172), size=(80x35), confidence=0.365\n",
      "  Detection 101: position=(587,302), size=(109x47), confidence=0.364\n",
      "  Detection 102: position=(286,233), size=(256x112), confidence=0.364\n",
      "  Detection 103: position=(426,301), size=(109x47), confidence=0.364\n",
      "  Detection 104: position=(505,302), size=(109x47), confidence=0.363\n",
      "  Detection 105: position=(364,89), size=(109x47), confidence=0.363\n",
      "  Detection 106: position=(503,234), size=(256x112), confidence=0.362\n",
      "  Detection 107: position=(230,555), size=(80x35), confidence=0.361\n",
      "  Detection 108: position=(142,10), size=(168x73), confidence=0.361\n",
      "  Detection 109: position=(451,557), size=(80x35), confidence=0.361\n",
      "  Detection 110: position=(252,300), size=(109x47), confidence=0.361\n",
      "  Detection 111: position=(495,557), size=(80x35), confidence=0.361\n",
      "  Detection 112: position=(183,554), size=(80x35), confidence=0.360\n",
      "  Detection 113: position=(580,46), size=(197x86), confidence=0.360\n",
      "  Detection 114: position=(389,494), size=(168x73), confidence=0.360\n",
      "  Detection 115: position=(16,300), size=(109x47), confidence=0.359\n",
      "  Detection 116: position=(29,91), size=(109x47), confidence=0.358\n",
      "  Detection 117: position=(234,91), size=(109x47), confidence=0.358\n",
      "  Detection 118: position=(476,199), size=(80x35), confidence=0.357\n",
      "  Detection 119: position=(0,201), size=(197x86), confidence=0.357\n",
      "  Detection 120: position=(388,70), size=(80x35), confidence=0.357\n",
      "  Detection 121: position=(517,226), size=(80x35), confidence=0.356\n",
      "  Detection 122: position=(133,554), size=(80x35), confidence=0.352\n",
      "  Detection 123: position=(133,173), size=(80x35), confidence=0.352\n",
      "  Detection 124: position=(202,287), size=(256x112), confidence=0.352\n",
      "  Detection 125: position=(472,71), size=(80x35), confidence=0.352\n",
      "  Detection 126: position=(656,281), size=(80x35), confidence=0.351\n",
      "  Detection 127: position=(546,53), size=(138x60), confidence=0.351\n",
      "  Detection 128: position=(637,93), size=(109x47), confidence=0.351\n",
      "  Detection 129: position=(257,507), size=(80x35), confidence=0.351\n",
      "  Detection 130: position=(53,552), size=(80x35), confidence=0.351\n",
      "  Detection 131: position=(241,32), size=(80x35), confidence=0.350\n",
      "  Detection 132: position=(343,301), size=(109x47), confidence=0.350\n",
      "  Detection 133: position=(607,556), size=(80x35), confidence=0.350\n",
      "  Detection 134: position=(617,281), size=(80x35), confidence=0.350\n",
      "  Detection 135: position=(17,234), size=(256x112), confidence=0.350\n",
      "  Detection 136: position=(299,18), size=(109x47), confidence=0.349\n",
      "  Detection 137: position=(91,294), size=(197x86), confidence=0.349\n",
      "  Detection 138: position=(695,281), size=(80x35), confidence=0.349\n",
      "  Detection 139: position=(578,281), size=(80x35), confidence=0.348\n",
      "  Detection 140: position=(155,391), size=(256x112), confidence=0.347\n",
      "  Detection 141: position=(420,295), size=(197x86), confidence=0.347\n",
      "  Detection 142: position=(563,556), size=(80x35), confidence=0.347\n",
      "  Detection 143: position=(95,553), size=(80x35), confidence=0.347\n",
      "  Detection 144: position=(483,387), size=(256x112), confidence=0.346\n",
      "  Detection 145: position=(177,506), size=(80x35), confidence=0.346\n",
      "  Detection 146: position=(404,281), size=(80x35), confidence=0.345\n",
      "  Detection 147: position=(651,555), size=(80x35), confidence=0.344\n",
      "  Detection 148: position=(545,500), size=(138x60), confidence=0.344\n",
      "  Detection 149: position=(698,184), size=(80x35), confidence=0.344\n",
      "  Detection 150: position=(164,63), size=(109x47), confidence=0.343\n",
      "  Detection 151: position=(125,500), size=(138x60), confidence=0.342\n",
      "  Detection 152: position=(29,413), size=(138x60), confidence=0.341\n",
      "  Detection 153: position=(153,33), size=(80x35), confidence=0.341\n",
      "  Detection 154: position=(534,281), size=(80x35), confidence=0.341\n",
      "  Detection 155: position=(711,507), size=(80x35), confidence=0.340\n",
      "  Detection 156: position=(468,485), size=(168x73), confidence=0.339\n",
      "  Detection 157: position=(278,43), size=(197x86), confidence=0.338\n",
      "  Detection 158: position=(410,94), size=(109x47), confidence=0.338\n",
      "  Detection 159: position=(286,219), size=(109x47), confidence=0.338\n",
      "  Detection 160: position=(505,195), size=(168x73), confidence=0.338\n",
      "  Detection 161: position=(15,499), size=(80x35), confidence=0.337\n",
      "  Detection 162: position=(446,280), size=(80x35), confidence=0.337\n",
      "  Detection 163: position=(294,502), size=(138x60), confidence=0.336\n",
      "  Detection 164: position=(433,199), size=(80x35), confidence=0.336\n",
      "  Detection 165: position=(521,418), size=(138x60), confidence=0.336\n",
      "  Detection 166: position=(71,34), size=(80x35), confidence=0.335\n",
      "  Detection 167: position=(697,239), size=(80x35), confidence=0.335\n",
      "  Detection 168: position=(287,280), size=(80x35), confidence=0.334\n",
      "  Detection 169: position=(35,121), size=(168x73), confidence=0.334\n",
      "  Detection 170: position=(599,198), size=(80x35), confidence=0.334\n",
      "  Detection 171: position=(298,171), size=(80x35), confidence=0.334\n",
      "  Detection 172: position=(216,508), size=(80x35), confidence=0.332\n",
      "  Detection 173: position=(404,137), size=(138x60), confidence=0.332\n",
      "  Detection 174: position=(247,279), size=(80x35), confidence=0.332\n",
      "  Detection 175: position=(149,94), size=(109x47), confidence=0.332\n",
      "  Detection 176: position=(671,504), size=(80x35), confidence=0.331\n",
      "  Detection 177: position=(207,51), size=(138x60), confidence=0.331\n",
      "  Detection 178: position=(716,172), size=(80x35), confidence=0.330\n",
      "  Detection 179: position=(404,304), size=(80x35), confidence=0.330\n",
      "  Detection 180: position=(505,64), size=(109x47), confidence=0.330\n",
      "  Detection 181: position=(332,6), size=(80x35), confidence=0.330\n",
      "  Detection 182: position=(29,279), size=(80x35), confidence=0.330\n",
      "  Detection 183: position=(215,173), size=(80x35), confidence=0.328\n",
      "  Detection 184: position=(353,225), size=(80x35), confidence=0.328\n",
      "  Detection 185: position=(537,238), size=(80x35), confidence=0.328\n",
      "  Detection 186: position=(69,279), size=(80x35), confidence=0.327\n",
      "  Detection 187: position=(154,279), size=(80x35), confidence=0.327\n",
      "  Detection 188: position=(202,279), size=(80x35), confidence=0.326\n",
      "  Detection 189: position=(108,279), size=(80x35), confidence=0.325\n",
      "  Detection 190: position=(384,169), size=(80x35), confidence=0.325\n",
      "  Detection 191: position=(552,171), size=(80x35), confidence=0.325\n",
      "  Detection 192: position=(634,170), size=(80x35), confidence=0.325\n",
      "  Detection 193: position=(321,303), size=(80x35), confidence=0.324\n",
      "  Detection 194: position=(553,507), size=(80x35), confidence=0.323\n",
      "  Detection 195: position=(76,398), size=(168x73), confidence=0.323\n",
      "  Detection 196: position=(60,501), size=(80x35), confidence=0.323\n",
      "  Detection 197: position=(181,201), size=(80x35), confidence=0.323\n",
      "  Detection 198: position=(598,196), size=(168x73), confidence=0.322\n",
      "  Detection 199: position=(346,508), size=(80x35), confidence=0.322\n",
      "  Detection 200: position=(614,238), size=(80x35), confidence=0.321\n",
      "  Detection 201: position=(174,333), size=(492x215), confidence=0.321\n",
      "  Detection 202: position=(95,201), size=(80x35), confidence=0.320\n",
      "  Detection 203: position=(173,204), size=(138x60), confidence=0.319\n",
      "  Detection 204: position=(27,55), size=(168x73), confidence=0.319\n",
      "  Detection 205: position=(260,198), size=(80x35), confidence=0.318\n",
      "  Detection 206: position=(429,508), size=(80x35), confidence=0.318\n",
      "  Detection 207: position=(640,304), size=(80x35), confidence=0.317\n",
      "  Detection 208: position=(452,238), size=(80x35), confidence=0.317\n",
      "  Detection 209: position=(439,170), size=(80x35), confidence=0.317\n",
      "  Detection 210: position=(135,201), size=(80x35), confidence=0.316\n",
      "  Detection 211: position=(312,512), size=(197x86), confidence=0.316\n",
      "  Detection 212: position=(68,302), size=(80x35), confidence=0.315\n",
      "  Detection 213: position=(714,200), size=(80x35), confidence=0.314\n",
      "  Detection 214: position=(389,510), size=(80x35), confidence=0.313\n",
      "  Detection 215: position=(532,185), size=(80x35), confidence=0.313\n",
      "  Detection 216: position=(550,199), size=(80x35), confidence=0.312\n",
      "  Detection 217: position=(312,195), size=(168x73), confidence=0.312\n",
      "  Detection 218: position=(33,186), size=(80x35), confidence=0.311\n",
      "  Detection 219: position=(291,121), size=(168x73), confidence=0.309\n",
      "  Detection 220: position=(330,299), size=(197x86), confidence=0.308\n",
      "  Detection 221: position=(1,298), size=(197x86), confidence=0.306\n",
      "  Detection 222: position=(149,302), size=(80x35), confidence=0.306\n",
      "  Detection 223: position=(667,37), size=(80x35), confidence=0.305\n",
      "  Detection 224: position=(89,204), size=(138x60), confidence=0.304\n",
      "  Detection 225: position=(650,66), size=(109x47), confidence=0.302\n",
      "  Detection 226: position=(477,304), size=(80x35), confidence=0.301\n",
      "  Detection 227: position=(411,403), size=(80x35), confidence=0.299\n",
      "  Detection 228: position=(138,506), size=(80x35), confidence=0.299\n",
      "  Detection 229: position=(432,72), size=(80x35), confidence=0.299\n",
      "  Detection 230: position=(11,12), size=(138x60), confidence=0.299\n",
      "  Detection 231: position=(203,121), size=(168x73), confidence=0.298\n",
      "  Detection 232: position=(123,125), size=(168x73), confidence=0.297\n",
      "  Detection 233: position=(325,402), size=(80x35), confidence=0.296\n",
      "  Detection 234: position=(16,374), size=(80x35), confidence=0.296\n",
      "  Detection 235: position=(37,343), size=(80x35), confidence=0.296\n",
      "  Detection 236: position=(647,458), size=(80x35), confidence=0.295\n",
      "  Detection 237: position=(80,365), size=(80x35), confidence=0.295\n",
      "  Detection 238: position=(624,328), size=(80x35), confidence=0.295\n",
      "  Detection 239: position=(107,104), size=(286x125), confidence=0.294\n",
      "  Detection 240: position=(651,9), size=(80x35), confidence=0.294\n",
      "  Detection 241: position=(369,182), size=(80x35), confidence=0.293\n",
      "  Detection 242: position=(559,304), size=(80x35), confidence=0.293\n",
      "  Detection 243: position=(509,503), size=(80x35), confidence=0.293\n",
      "  Detection 244: position=(473,475), size=(80x35), confidence=0.291\n",
      "  Detection 245: position=(412,397), size=(168x73), confidence=0.291\n",
      "  Detection 246: position=(649,390), size=(80x35), confidence=0.290\n",
      "  Detection 247: position=(367,117), size=(80x35), confidence=0.290\n",
      "  Detection 248: position=(714,10), size=(80x35), confidence=0.289\n",
      "  Detection 249: position=(576,237), size=(80x35), confidence=0.289\n",
      "  Detection 250: position=(539,123), size=(80x35), confidence=0.289\n",
      "  Detection 251: position=(364,112), size=(256x112), confidence=0.289\n",
      "  Detection 252: position=(543,119), size=(168x73), confidence=0.288\n",
      "  Detection 253: position=(651,198), size=(80x35), confidence=0.288\n",
      "  Detection 254: position=(115,342), size=(80x35), confidence=0.288\n",
      "  Detection 255: position=(12,199), size=(80x35), confidence=0.287\n",
      "  Detection 256: position=(193,185), size=(80x35), confidence=0.287\n",
      "  Detection 257: position=(257,130), size=(80x35), confidence=0.287\n",
      "  Detection 258: position=(591,506), size=(80x35), confidence=0.287\n",
      "  Detection 259: position=(299,509), size=(80x35), confidence=0.286\n",
      "  Detection 260: position=(230,302), size=(80x35), confidence=0.286\n",
      "  Detection 261: position=(616,210), size=(80x35), confidence=0.285\n",
      "  Detection 262: position=(410,238), size=(80x35), confidence=0.285\n",
      "  Detection 263: position=(305,68), size=(80x35), confidence=0.284\n",
      "  Detection 264: position=(613,8), size=(80x35), confidence=0.284\n",
      "  Detection 265: position=(654,239), size=(80x35), confidence=0.284\n",
      "  Detection 266: position=(311,382), size=(286x125), confidence=0.283\n",
      "  Detection 267: position=(279,185), size=(80x35), confidence=0.282\n",
      "  Detection 268: position=(571,8), size=(80x35), confidence=0.282\n",
      "  Detection 269: position=(664,474), size=(80x35), confidence=0.280\n",
      "  Detection 270: position=(279,239), size=(80x35), confidence=0.279\n",
      "  Detection 271: position=(490,390), size=(80x35), confidence=0.279\n",
      "  Detection 272: position=(94,173), size=(80x35), confidence=0.278\n",
      "  Detection 273: position=(703,115), size=(80x35), confidence=0.278\n",
      "  Detection 274: position=(184,420), size=(138x60), confidence=0.277\n",
      "  Detection 275: position=(598,296), size=(197x86), confidence=0.277\n",
      "  Detection 276: position=(478,93), size=(80x35), confidence=0.276\n",
      "  Detection 277: position=(353,198), size=(80x35), confidence=0.276\n",
      "  Detection 278: position=(172,477), size=(80x35), confidence=0.276\n",
      "  Detection 279: position=(507,7), size=(80x35), confidence=0.275\n",
      "  Detection 280: position=(43,240), size=(80x35), confidence=0.275\n",
      "  Detection 281: position=(664,446), size=(80x35), confidence=0.274\n",
      "  Detection 282: position=(455,122), size=(80x35), confidence=0.274\n",
      "  Detection 283: position=(618,115), size=(80x35), confidence=0.273\n",
      "  Detection 284: position=(623,120), size=(168x73), confidence=0.273\n",
      "  Detection 285: position=(235,491), size=(80x35), confidence=0.273\n",
      "  Detection 286: position=(97,503), size=(80x35), confidence=0.273\n",
      "  Detection 287: position=(0,33), size=(80x35), confidence=0.273\n",
      "  Detection 288: position=(574,401), size=(80x35), confidence=0.272\n",
      "  Detection 289: position=(238,402), size=(80x35), confidence=0.272\n",
      "  Detection 290: position=(647,132), size=(80x35), confidence=0.271\n",
      "  Detection 291: position=(47,30), size=(522x228), confidence=0.271\n",
      "  Detection 292: position=(661,30), size=(138x60), confidence=0.270\n",
      "  Detection 293: position=(6,377), size=(315x138), confidence=0.269\n",
      "  Detection 294: position=(328,405), size=(168x73), confidence=0.269\n",
      "  Detection 295: position=(50,198), size=(80x35), confidence=0.268\n",
      "  Detection 296: position=(219,200), size=(80x35), confidence=0.268\n",
      "  Detection 297: position=(462,6), size=(80x35), confidence=0.268\n",
      "  Detection 298: position=(550,479), size=(80x35), confidence=0.268\n",
      "  Detection 299: position=(10,469), size=(80x35), confidence=0.267\n",
      "  Detection 300: position=(99,76), size=(80x35), confidence=0.267\n",
      "  Detection 301: position=(78,15), size=(109x47), confidence=0.266\n",
      "  Detection 302: position=(589,415), size=(138x60), confidence=0.266\n",
      "  Detection 303: position=(252,479), size=(80x35), confidence=0.266\n",
      "  Detection 304: position=(239,5), size=(80x35), confidence=0.265\n",
      "  Detection 305: position=(111,44), size=(197x86), confidence=0.264\n",
      "  Detection 306: position=(220,71), size=(80x35), confidence=0.264\n",
      "  Detection 307: position=(600,132), size=(80x35), confidence=0.264\n",
      "  Detection 308: position=(513,201), size=(80x35), confidence=0.264\n",
      "  Detection 309: position=(409,6), size=(80x35), confidence=0.264\n",
      "  Detection 310: position=(198,123), size=(80x35), confidence=0.263\n",
      "  Detection 311: position=(90,471), size=(80x35), confidence=0.262\n",
      "  Detection 312: position=(405,492), size=(80x35), confidence=0.262\n",
      "  Detection 313: position=(9,443), size=(80x35), confidence=0.261\n",
      "  Detection 314: position=(92,445), size=(80x35), confidence=0.261\n",
      "  Detection 315: position=(259,383), size=(80x35), confidence=0.260\n",
      "  Detection 316: position=(180,381), size=(80x35), confidence=0.260\n",
      "  Detection 317: position=(685,133), size=(80x35), confidence=0.260\n",
      "  Detection 318: position=(194,5), size=(80x35), confidence=0.259\n",
      "  Detection 319: position=(84,86), size=(138x60), confidence=0.258\n",
      "  Detection 320: position=(365,281), size=(80x35), confidence=0.258\n",
      "  Detection 321: position=(368,238), size=(80x35), confidence=0.258\n",
      "  Detection 322: position=(570,490), size=(80x35), confidence=0.258\n",
      "  Detection 323: position=(513,169), size=(80x35), confidence=0.257\n",
      "  Detection 324: position=(302,197), size=(80x35), confidence=0.257\n",
      "  Detection 325: position=(344,129), size=(80x35), confidence=0.256\n",
      "  Detection 326: position=(686,345), size=(80x35), confidence=0.255\n",
      "  Detection 327: position=(546,327), size=(80x35), confidence=0.255\n",
      "  Detection 328: position=(606,344), size=(80x35), confidence=0.255\n",
      "  Detection 329: position=(425,85), size=(168x73), confidence=0.255\n",
      "  Detection 330: position=(529,552), size=(80x35), confidence=0.254\n",
      "  Detection 331: position=(511,474), size=(80x35), confidence=0.254\n",
      "  Detection 332: position=(306,264), size=(80x35), confidence=0.254\n",
      "  Detection 333: position=(484,365), size=(80x35), confidence=0.254\n",
      "  Detection 334: position=(155,489), size=(80x35), confidence=0.254\n",
      "  Detection 335: position=(122,6), size=(80x35), confidence=0.254\n",
      "  Detection 336: position=(647,486), size=(80x35), confidence=0.253\n",
      "  Detection 337: position=(196,344), size=(80x35), confidence=0.253\n",
      "  Detection 338: position=(451,211), size=(80x35), confidence=0.253\n",
      "  Detection 339: position=(501,104), size=(286x125), confidence=0.253\n",
      "  Detection 340: position=(469,408), size=(80x35), confidence=0.253\n",
      "  Detection 341: position=(283,118), size=(80x35), confidence=0.252\n",
      "  Detection 342: position=(713,413), size=(80x35), confidence=0.252\n",
      "  Detection 343: position=(585,451), size=(80x35), confidence=0.251\n",
      "  Detection 344: position=(56,264), size=(80x35), confidence=0.251\n",
      "  Detection 345: position=(55,405), size=(80x35), confidence=0.251\n",
      "  Detection 346: position=(282,5), size=(80x35), confidence=0.251\n",
      "  Detection 347: position=(128,226), size=(138x60), confidence=0.251\n",
      "  Detection 348: position=(526,345), size=(80x35), confidence=0.250\n",
      "  Detection 349: position=(320,239), size=(80x35), confidence=0.250\n",
      "  Detection 350: position=(631,408), size=(80x35), confidence=0.250\n",
      "  Detection 351: position=(538,264), size=(80x35), confidence=0.249\n",
      "  Detection 352: position=(207,28), size=(80x35), confidence=0.249\n",
      "  Detection 353: position=(690,93), size=(109x47), confidence=0.249\n",
      "  Detection 354: position=(113,123), size=(80x35), confidence=0.249\n",
      "  Detection 355: position=(90,106), size=(80x35), confidence=0.248\n",
      "  Detection 356: position=(392,197), size=(80x35), confidence=0.248\n",
      "  Detection 357: position=(416,182), size=(80x35), confidence=0.247\n",
      "  Detection 358: position=(634,32), size=(80x35), confidence=0.247\n",
      "  Detection 359: position=(131,92), size=(80x35), confidence=0.247\n",
      "  Detection 360: position=(498,238), size=(80x35), confidence=0.247\n",
      "  Detection 361: position=(529,310), size=(168x73), confidence=0.246\n",
      "  Detection 362: position=(79,395), size=(80x35), confidence=0.246\n",
      "  Detection 363: position=(521,135), size=(80x35), confidence=0.246\n",
      "  Detection 364: position=(137,265), size=(80x35), confidence=0.246\n",
      "  Detection 365: position=(254,453), size=(80x35), confidence=0.246\n",
      "  Detection 366: position=(158,400), size=(80x35), confidence=0.246\n",
      "  Detection 367: position=(221,265), size=(80x35), confidence=0.246\n",
      "  Detection 368: position=(390,264), size=(80x35), confidence=0.245\n",
      "  Detection 369: position=(77,6), size=(80x35), confidence=0.245\n",
      "  Detection 370: position=(291,413), size=(80x35), confidence=0.245\n",
      "  Detection 371: position=(715,33), size=(80x35), confidence=0.245\n",
      "  Detection 372: position=(204,240), size=(80x35), confidence=0.245\n",
      "  Detection 373: position=(276,342), size=(80x35), confidence=0.245\n",
      "  Detection 374: position=(0,7), size=(80x35), confidence=0.245\n",
      "  Detection 375: position=(0,387), size=(80x35), confidence=0.245\n",
      "  Detection 376: position=(77,185), size=(80x35), confidence=0.244\n",
      "  Detection 377: position=(244,0), size=(433x189), confidence=0.244\n",
      "  Detection 378: position=(120,240), size=(80x35), confidence=0.244\n",
      "  Detection 379: position=(595,169), size=(80x35), confidence=0.244\n",
      "  Detection 380: position=(30,119), size=(80x35), confidence=0.244\n",
      "  Detection 381: position=(163,240), size=(80x35), confidence=0.243\n",
      "  Detection 382: position=(10,131), size=(80x35), confidence=0.243\n",
      "  Detection 383: position=(490,85), size=(197x86), confidence=0.242\n",
      "  Detection 384: position=(547,31), size=(80x35), confidence=0.242\n",
      "  Detection 385: position=(453,264), size=(80x35), confidence=0.241\n",
      "  Detection 386: position=(135,73), size=(80x35), confidence=0.241\n",
      "  Detection 387: position=(136,381), size=(80x35), confidence=0.240\n",
      "  Detection 388: position=(169,451), size=(80x35), confidence=0.240\n",
      "  Detection 389: position=(716,267), size=(80x35), confidence=0.239\n",
      "  Detection 390: position=(216,412), size=(80x35), confidence=0.239\n",
      "  Detection 391: position=(38,6), size=(80x35), confidence=0.238\n",
      "  Detection 392: position=(537,213), size=(80x35), confidence=0.238\n",
      "  Detection 393: position=(711,383), size=(80x35), confidence=0.237\n",
      "  Detection 394: position=(462,29), size=(80x35), confidence=0.237\n",
      "  Detection 395: position=(320,364), size=(80x35), confidence=0.237\n",
      "  Detection 396: position=(299,480), size=(80x35), confidence=0.236\n",
      "  Detection 397: position=(683,425), size=(109x47), confidence=0.236\n",
      "  Detection 398: position=(216,89), size=(80x35), confidence=0.236\n",
      "  Detection 399: position=(251,14), size=(109x47), confidence=0.235\n",
      "  Detection 400: position=(116,185), size=(80x35), confidence=0.235\n",
      "  Detection 401: position=(563,134), size=(80x35), confidence=0.234\n",
      "  Detection 402: position=(448,343), size=(80x35), confidence=0.234\n",
      "  Detection 403: position=(90,134), size=(80x35), confidence=0.234\n",
      "  Detection 404: position=(215,83), size=(197x86), confidence=0.234\n",
      "  Detection 405: position=(577,182), size=(80x35), confidence=0.233\n",
      "  Detection 406: position=(178,134), size=(80x35), confidence=0.233\n",
      "  Detection 407: position=(426,134), size=(80x35), confidence=0.232\n",
      "  Detection 408: position=(675,267), size=(80x35), confidence=0.232\n",
      "  Detection 409: position=(294,76), size=(227x99), confidence=0.232\n",
      "  Detection 410: position=(592,267), size=(80x35), confidence=0.232\n",
      "  Detection 411: position=(298,383), size=(80x35), confidence=0.231\n",
      "  Detection 412: position=(218,382), size=(80x35), confidence=0.231\n",
      "  Detection 413: position=(57,325), size=(80x35), confidence=0.231\n",
      "  Detection 414: position=(585,546), size=(80x35), confidence=0.230\n",
      "  Detection 415: position=(633,267), size=(80x35), confidence=0.230\n",
      "  Detection 416: position=(480,138), size=(138x60), confidence=0.229\n",
      "  Detection 417: position=(547,411), size=(80x35), confidence=0.229\n",
      "  Detection 418: position=(337,479), size=(80x35), confidence=0.229\n",
      "  Detection 419: position=(176,172), size=(80x35), confidence=0.229\n",
      "  Detection 420: position=(35,30), size=(80x35), confidence=0.228\n",
      "  Detection 421: position=(642,6), size=(138x60), confidence=0.228\n",
      "  Detection 422: position=(669,379), size=(80x35), confidence=0.228\n",
      "  Detection 423: position=(365,333), size=(80x35), confidence=0.227\n",
      "  Detection 424: position=(261,169), size=(80x35), confidence=0.227\n",
      "  Detection 425: position=(513,378), size=(80x35), confidence=0.227\n",
      "  Detection 426: position=(201,396), size=(80x35), confidence=0.227\n",
      "  Detection 427: position=(455,184), size=(80x35), confidence=0.226\n",
      "  Detection 428: position=(240,363), size=(80x35), confidence=0.226\n",
      "  Detection 429: position=(346,170), size=(80x35), confidence=0.225\n",
      "  Detection 430: position=(180,269), size=(80x35), confidence=0.225\n",
      "  Detection 431: position=(157,3), size=(80x35), confidence=0.224\n",
      "  Detection 432: position=(554,383), size=(80x35), confidence=0.224\n",
      "  Detection 433: position=(676,170), size=(80x35), confidence=0.224\n",
      "  Detection 434: position=(713,301), size=(80x35), confidence=0.224\n",
      "  Detection 435: position=(406,359), size=(80x35), confidence=0.222\n",
      "  Detection 436: position=(519,446), size=(80x35), confidence=0.222\n",
      "  Detection 437: position=(407,470), size=(80x35), confidence=0.221\n",
      "  Detection 438: position=(351,266), size=(80x35), confidence=0.221\n",
      "  Detection 439: position=(71,0), size=(345x151), confidence=0.221\n",
      "  Detection 440: position=(468,327), size=(80x35), confidence=0.221\n",
      "  Detection 441: position=(144,356), size=(80x35), confidence=0.220\n",
      "  Detection 442: position=(644,364), size=(80x35), confidence=0.220\n",
      "  Detection 443: position=(318,492), size=(80x35), confidence=0.219\n",
      "  Detection 444: position=(266,266), size=(80x35), confidence=0.219\n",
      "  Detection 445: position=(209,212), size=(168x73), confidence=0.219\n",
      "  Detection 446: position=(534,394), size=(80x35), confidence=0.219\n",
      "  Detection 447: position=(146,326), size=(80x35), confidence=0.218\n",
      "  Detection 448: position=(254,545), size=(80x35), confidence=0.218\n",
      "  Detection 449: position=(332,373), size=(109x47), confidence=0.217\n",
      "  Detection 450: position=(475,1), size=(138x60), confidence=0.217\n",
      "  Detection 451: position=(240,359), size=(168x73), confidence=0.217\n",
      "  Detection 452: position=(425,453), size=(80x35), confidence=0.217\n",
      "  Detection 453: position=(371,5), size=(80x35), confidence=0.217\n",
      "  Detection 454: position=(13,404), size=(80x35), confidence=0.217\n",
      "  Detection 455: position=(219,327), size=(80x35), confidence=0.216\n",
      "  Detection 456: position=(68,117), size=(80x35), confidence=0.216\n",
      "  Detection 457: position=(158,545), size=(80x35), confidence=0.216\n",
      "  Detection 458: position=(412,360), size=(168x73), confidence=0.216\n",
      "  Detection 459: position=(271,435), size=(80x35), confidence=0.216\n",
      "  Detection 460: position=(694,395), size=(80x35), confidence=0.215\n",
      "  Detection 461: position=(280,397), size=(80x35), confidence=0.215\n",
      "  Detection 462: position=(393,384), size=(80x35), confidence=0.215\n",
      "  Detection 463: position=(218,134), size=(80x35), confidence=0.215\n",
      "  Detection 464: position=(49,131), size=(80x35), confidence=0.215\n",
      "  Detection 465: position=(561,88), size=(80x35), confidence=0.214\n",
      "  Detection 466: position=(280,209), size=(80x35), confidence=0.214\n",
      "  Detection 467: position=(115,212), size=(80x35), confidence=0.213\n",
      "  Detection 468: position=(31,426), size=(80x35), confidence=0.213\n",
      "  Detection 469: position=(247,455), size=(138x60), confidence=0.213\n",
      "  Detection 470: position=(370,224), size=(138x60), confidence=0.213\n",
      "  Detection 471: position=(171,351), size=(138x60), confidence=0.212\n",
      "  Detection 472: position=(318,193), size=(404x176), confidence=0.212\n",
      "  Detection 473: position=(330,113), size=(80x35), confidence=0.211\n",
      "  Detection 474: position=(4,270), size=(80x35), confidence=0.211\n",
      "  Detection 475: position=(74,484), size=(80x35), confidence=0.211\n",
      "  Detection 476: position=(18,325), size=(80x35), confidence=0.211\n",
      "  Detection 477: position=(391,1), size=(138x60), confidence=0.211\n",
      "  Detection 478: position=(133,134), size=(80x35), confidence=0.209\n",
      "  Detection 479: position=(118,84), size=(197x86), confidence=0.207\n",
      "  Detection 480: position=(296,325), size=(80x35), confidence=0.207\n",
      "  Detection 481: position=(0,297), size=(80x35), confidence=0.206\n",
      "  Detection 482: position=(719,462), size=(80x35), confidence=0.206\n",
      "  Detection 483: position=(266,33), size=(109x47), confidence=0.206\n",
      "  Detection 484: position=(537,153), size=(168x73), confidence=0.206\n",
      "  Detection 485: position=(306,130), size=(80x35), confidence=0.206\n",
      "  Detection 486: position=(95,324), size=(80x35), confidence=0.206\n",
      "  Detection 487: position=(574,359), size=(168x73), confidence=0.205\n",
      "  Detection 488: position=(119,393), size=(80x35), confidence=0.204\n",
      "  Detection 489: position=(473,547), size=(80x35), confidence=0.203\n",
      "  Detection 490: position=(0,360), size=(168x73), confidence=0.203\n",
      "  Detection 491: position=(91,267), size=(80x35), confidence=0.203\n",
      "  Detection 492: position=(208,545), size=(80x35), confidence=0.202\n",
      "  Detection 493: position=(103,538), size=(80x35), confidence=0.202\n",
      "  Detection 494: position=(480,133), size=(80x35), confidence=0.202\n",
      "  Detection 495: position=(41,536), size=(80x35), confidence=0.202\n",
      "  Detection 496: position=(497,117), size=(80x35), confidence=0.201\n",
      "  Detection 497: position=(508,408), size=(80x35), confidence=0.201\n",
      "  Detection 498: position=(322,339), size=(168x73), confidence=0.201\n",
      "  Detection 499: position=(0,354), size=(80x35), confidence=0.201\n",
      "  Detection 500: position=(122,433), size=(80x35), confidence=0.201\n",
      "  Detection 501: position=(556,1), size=(138x60), confidence=0.200\n",
      "  Detection 502: position=(81,241), size=(80x35), confidence=0.200\n",
      "  Detection 503: position=(38,447), size=(138x60), confidence=0.199\n",
      "  Detection 504: position=(694,211), size=(80x35), confidence=0.199\n",
      "  Detection 505: position=(588,478), size=(80x35), confidence=0.198\n",
      "  Detection 506: position=(676,409), size=(80x35), confidence=0.198\n",
      "  Detection 507: position=(549,104), size=(80x35), confidence=0.198\n",
      "  Detection 508: position=(566,361), size=(80x35), confidence=0.198\n",
      "  Detection 509: position=(0,95), size=(80x35), confidence=0.198\n",
      "  Detection 510: position=(167,454), size=(138x60), confidence=0.197\n",
      "  Detection 511: position=(719,361), size=(80x35), confidence=0.197\n",
      "  Detection 512: position=(242,87), size=(522x228), confidence=0.197\n",
      "  Detection 513: position=(334,456), size=(138x60), confidence=0.197\n",
      "  Detection 514: position=(700,330), size=(80x35), confidence=0.196\n",
      "  Detection 515: position=(568,467), size=(80x35), confidence=0.195\n",
      "  Detection 516: position=(212,105), size=(80x35), confidence=0.195\n",
      "  Detection 517: position=(663,53), size=(80x35), confidence=0.195\n",
      "  Detection 518: position=(501,262), size=(80x35), confidence=0.195\n",
      "  Detection 519: position=(603,253), size=(80x35), confidence=0.195\n",
      "  Detection 520: position=(476,172), size=(80x35), confidence=0.195\n",
      "  Detection 521: position=(686,253), size=(80x35), confidence=0.195\n",
      "  Detection 522: position=(100,377), size=(80x35), confidence=0.195\n",
      "  Detection 523: position=(619,379), size=(80x35), confidence=0.195\n",
      "  Detection 524: position=(281,304), size=(138x60), confidence=0.195\n",
      "  Detection 525: position=(491,518), size=(80x35), confidence=0.195\n",
      "  Detection 526: position=(91,346), size=(138x60), confidence=0.194\n",
      "  Detection 527: position=(660,183), size=(80x35), confidence=0.194\n",
      "  Detection 528: position=(329,182), size=(80x35), confidence=0.193\n",
      "  Detection 529: position=(304,452), size=(80x35), confidence=0.193\n",
      "  Detection 530: position=(435,479), size=(80x35), confidence=0.192\n",
      "  Detection 531: position=(240,152), size=(80x35), confidence=0.192\n",
      "  Detection 532: position=(490,487), size=(80x35), confidence=0.191\n",
      "  Detection 533: position=(80,91), size=(80x35), confidence=0.190\n",
      "  Detection 534: position=(719,540), size=(80x35), confidence=0.189\n",
      "  Detection 535: position=(715,479), size=(80x35), confidence=0.189\n",
      "  Detection 536: position=(325,541), size=(80x35), confidence=0.188\n",
      "  Detection 537: position=(393,325), size=(80x35), confidence=0.188\n",
      "  Detection 538: position=(493,53), size=(80x35), confidence=0.188\n",
      "  Detection 539: position=(44,389), size=(80x35), confidence=0.187\n",
      "  Detection 540: position=(74,54), size=(80x35), confidence=0.187\n",
      "  Detection 541: position=(614,539), size=(80x35), confidence=0.187\n",
      "  Detection 542: position=(490,463), size=(80x35), confidence=0.187\n",
      "  Detection 543: position=(525,430), size=(80x35), confidence=0.187\n",
      "  Detection 544: position=(341,489), size=(138x60), confidence=0.187\n",
      "  Detection 545: position=(175,412), size=(80x35), confidence=0.186\n",
      "  Detection 546: position=(578,224), size=(138x60), confidence=0.185\n",
      "  Detection 547: position=(386,414), size=(80x35), confidence=0.185\n",
      "  Detection 548: position=(474,446), size=(80x35), confidence=0.185\n",
      "  Detection 549: position=(201,487), size=(80x35), confidence=0.184\n",
      "  Detection 550: position=(626,475), size=(80x35), confidence=0.184\n",
      "  Detection 551: position=(166,484), size=(138x60), confidence=0.184\n",
      "  Detection 552: position=(549,541), size=(80x35), confidence=0.184\n",
      "  Detection 553: position=(538,461), size=(80x35), confidence=0.183\n",
      "  Detection 554: position=(409,115), size=(80x35), confidence=0.183\n",
      "  Detection 555: position=(493,363), size=(168x73), confidence=0.183\n",
      "  Detection 556: position=(661,348), size=(138x60), confidence=0.182\n",
      "  Detection 557: position=(198,213), size=(80x35), confidence=0.182\n",
      "  Detection 558: position=(14,169), size=(80x35), confidence=0.181\n",
      "  Detection 559: position=(42,479), size=(80x35), confidence=0.181\n",
      "  Detection 560: position=(661,225), size=(138x60), confidence=0.181\n",
      "  Detection 561: position=(645,517), size=(80x35), confidence=0.181\n",
      "  Detection 562: position=(708,524), size=(80x35), confidence=0.181\n",
      "  Detection 563: position=(384,562), size=(80x35), confidence=0.181\n",
      "  Detection 564: position=(219,323), size=(138x60), confidence=0.180\n",
      "  Detection 565: position=(284,539), size=(80x35), confidence=0.180\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 2: Multiple Detections on coca_multi.png\n",
    "# Using template matching with the same template from Item 1 (like 01.Templates.ipynb Cell 6)\n",
    "# =============================================================================\n",
    "\n",
    "img_rgb, img_gray, img_bgr = load_image('images/coca_multi.png')\n",
    "detections = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "\n",
    "print(f\"Detected {len(detections)} logo instances in coca_multi.png\")\n",
    "for i, det in enumerate(detections):\n",
    "    x, y, w, h, score = det\n",
    "    print(f\"  Detection {i+1}: position=({x},{y}), size=({w}x{h}), confidence={score:.3f}\")\n",
    "\n",
    "plot_single_result(img_rgb, detections, \"ASSIGNMENT 2: coca_multi.png (Template Matching)\", 'results/Figure_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf815d5",
   "metadata": {},
   "source": [
    "3. Generalize the algorithm from item 2 for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b10e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCA-COLA-LOGO.jpg: 1 single detection, 647 multiple detections\n",
      "coca_logo_1.png: 1 single detection, 35 multiple detections\n",
      "coca_logo_2.png: 1 single detection, 37 multiple detections\n",
      "coca_multi.png: 1 single detection, 565 multiple detections\n",
      "coca_retro_1.png: 1 single detection, 365 multiple detections\n",
      "coca_retro_2.png: 1 single detection, 230 multiple detections\n",
      "logo_1.png: 1 single detection, 222 multiple detections\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 3: Generalized Algorithm for All Images\n",
    "# Generalizes the template matching algorithm from Item 2 for all images\n",
    "# =============================================================================\n",
    "\n",
    "results_single = []\n",
    "results_multi = []\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray, img_bgr = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    \n",
    "    # Single detection: template matching with strict threshold\n",
    "    bbox, method, score = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    det_single = [(bbox[0], bbox[1], bbox[2], bbox[3], score)] if bbox else []\n",
    "    results_single.append((img_rgb, det_single, img_name))\n",
    "    \n",
    "    # Multiple detection: template matching with more permissive threshold (Item 2 algorithm)\n",
    "    det_multi = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "    results_multi.append((img_rgb, det_multi, img_name))\n",
    "    \n",
    "    print(f\"{img_name}: {len(det_single)} single detection, {len(det_multi)} multiple detections\")\n",
    "\n",
    "plot_results_grid(results_single, \"ASSIGNMENT 3: Single Detection (Template Matching)\", 'results/Figure_3a_single.png')\n",
    "plot_results_grid(results_multi, \"ASSIGNMENT 3: Multiple Detection (Template Matching)\", 'results/Figure_3b_multi.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
