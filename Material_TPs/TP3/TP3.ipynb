{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d1485",
   "metadata": {},
   "source": [
    "# TP3 - Find the soda logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467ba69",
   "metadata": {},
   "source": [
    "## Find the soda logo within the provided images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ff4b",
   "metadata": {},
   "source": [
    "1. Obtain a logo detection in each image without false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(path, max_size=1200):\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    \n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path, max_size=400):\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "# Note: The create_template_variants function is defined in Cell 5 (DETECTION FUNCTIONS)\n",
    "# This cell only contains utility functions for loading and visualization\n",
    "\n",
    "\n",
    "def draw_detections(img_rgb, detections):\n",
    "    \"\"\"Draw detection rectangles on image with confidence scores.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for det in detections:\n",
    "        x, y, w, h = det[:4]\n",
    "        score = det[4] if len(det) > 4 else 1.0\n",
    "        \n",
    "        # Color according to confidence level (green high, yellow medium, red low)\n",
    "        if score >= 0.7:\n",
    "            color = (0, 255, 0)  # Green\n",
    "        elif score >= 0.5:\n",
    "            color = (255, 255, 0)  # Yellow\n",
    "        else:\n",
    "            color = (255, 0, 0)  # Red\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), color, 2)\n",
    "        \n",
    "        # Display confidence level\n",
    "        label = f'{score:.2f}'\n",
    "        label_size, _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        label_y = max(y - 5, label_size[1])\n",
    "        cv.rectangle(img_out, (x, label_y - label_size[1] - 5), \n",
    "                    (x + label_size[0], label_y + 5), color, -1)\n",
    "        cv.putText(img_out, label, (x, label_y), \n",
    "                  cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_results_grid(results, title, save_path=None):\n",
    "    \"\"\"Plot results in a grid layout with confidence information.\"\"\"\n",
    "    n = len(results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img_rgb, detections, img_name) in enumerate(results):\n",
    "        img_result = draw_detections(img_rgb, detections)\n",
    "        axes[idx].imshow(img_result)\n",
    "        \n",
    "        # Display confidence information in the title\n",
    "        if detections:\n",
    "            scores = [d[4] for d in detections if len(d) > 4]\n",
    "            avg_conf = np.mean(scores) if scores else 0.0\n",
    "            conf_str = f\"avg confidence: {avg_conf:.2f}\" if len(detections) > 1 else f\"confidence: {scores[0]:.2f}\"\n",
    "            axes[idx].set_title(f\"{img_name}\\n{len(detections)} detection(s), {conf_str}\")\n",
    "        else:\n",
    "            axes[idx].set_title(f\"{img_name}\\n0 detections\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for idx in range(n, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single_result(img_rgb, detections, title, save_path=None):\n",
    "    \"\"\"Plot single image result with confidence information.\"\"\"\n",
    "    img_result = draw_detections(img_rgb, detections)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_result)\n",
    "    \n",
    "    # Display confidence information in the title\n",
    "    if detections:\n",
    "        scores = [d[4] for d in detections if len(d) > 4]\n",
    "        avg_conf = np.mean(scores) if scores else 0.0\n",
    "        min_conf = np.min(scores) if scores else 0.0\n",
    "        max_conf = np.max(scores) if scores else 0.0\n",
    "        title_with_conf = f\"{title} | {len(detections)} detections\\nConfidence: min={min_conf:.2f}, avg={avg_conf:.2f}, max={max_conf:.2f}\"\n",
    "    else:\n",
    "        title_with_conf = f\"{title} | 0 detections\"\n",
    "    \n",
    "    plt.title(title_with_conf, fontsize=12)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ad9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_template_variants(template):\n",
    "    \"\"\"\n",
    "    Create only useful template variants for template matching.\n",
    "    Only: original, clahe, smooth, inverted.\n",
    "    \"\"\"\n",
    "    smooth = cv.GaussianBlur(template, (3, 3), 0)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_img = clahe.apply(template)\n",
    "    inverted = 255 - template\n",
    "    \n",
    "    return {\n",
    "        'original': template,\n",
    "        'clahe': clahe_img,\n",
    "        'smooth': smooth,\n",
    "        'inverted': inverted,\n",
    "    }\n",
    "\n",
    "\n",
    "def preprocess_image(img_gray):\n",
    "    \"\"\"Preprocess image before template matching.\"\"\"\n",
    "    img = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    img = cv.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    inter_w = max(0, xi2 - xi1)\n",
    "    inter_h = max(0, yi2 - yi1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def nms_global(detections, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression globally across all detections.\n",
    "    detections: list of (x, y, w, h, score)\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n",
    "    \n",
    "    keep = []\n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "\n",
    "def find_by_template(img_gray, template_variants, single_detection=True, min_threshold=0.30):\n",
    "    \"\"\"\n",
    "    Multi-scale template matching following the class code pattern.\n",
    "    - 30 scales between 0.2 and 1.6\n",
    "    - Adaptive threshold: mean + 2.5*std, min threshold according to mode\n",
    "    - Global NMS to filter overlaps\n",
    "    - Aspect ratio filtering: 0.5 < w/h < 3.0\n",
    "    \n",
    "    For multiple detections, uses lower threshold (following 01.Templates.ipynb Cell 6).\n",
    "    \"\"\"\n",
    "    h, w = img_gray.shape\n",
    "    img_processed = preprocess_image(img_gray)\n",
    "    \n",
    "    # Adjust threshold according to detection mode\n",
    "    # For multiple detections, use lower threshold (as in 01.Templates.ipynb Cell 6: 0.75)\n",
    "    if single_detection:\n",
    "        base_threshold = min_threshold  # 0.30 for single detection (stricter)\n",
    "    else:\n",
    "        base_threshold = max(min_threshold, 0.60)  # 0.60 for multiple (more permissive)\n",
    "    \n",
    "    scales = np.linspace(0.2, 1.6, 30)\n",
    "    all_detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        for name, tmpl in template_variants.items():\n",
    "            th, tw = tmpl.shape\n",
    "            new_w = int(tw * scale)\n",
    "            new_h = int(th * scale)\n",
    "            \n",
    "            if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n",
    "                continue\n",
    "            \n",
    "            scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n",
    "            # Use TM_CCOEFF_NORMED as in 01.Templates.ipynb Cell 6\n",
    "            res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # Adaptive threshold but with minimum according to mode\n",
    "            mean_val = np.mean(res)\n",
    "            std_val = np.std(res)\n",
    "            threshold = max(mean_val + 2.5 * std_val, base_threshold)\n",
    "            \n",
    "            # np.where() as in 01.Templates.ipynb Cell 6\n",
    "            locations = np.where(res >= threshold)\n",
    "            \n",
    "            for pt in zip(*locations[::-1]):\n",
    "                x, y = pt\n",
    "                score = res[y, x]\n",
    "                \n",
    "                aspect = new_w / new_h if new_h > 0 else 0\n",
    "                if not (0.5 < aspect < 3.0):\n",
    "                    continue\n",
    "                \n",
    "                all_detections.append((x, y, new_w, new_h, score))\n",
    "    \n",
    "    if not all_detections:\n",
    "        return (None, None, 0) if single_detection else []\n",
    "    \n",
    "    # Apply NMS to filter overlaps (improvement over basic 01.Templates.ipynb)\n",
    "    final_detections = nms_global(all_detections, iou_threshold=0.3)\n",
    "    \n",
    "    if single_detection:\n",
    "        best = final_detections[0]\n",
    "        return (best[0], best[1], best[2], best[3]), 'template', best[4]\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "\n",
    "def detect_logo(img_bgr, img_gray, template_variants, single_detection=True):\n",
    "    \"\"\"\n",
    "    Detection pipeline using only template matching (aligned with 01.Templates.ipynb).\n",
    "    - Single detection: Template matching with strict threshold\n",
    "    - Multi detection: Template matching with more permissive threshold (like 01.Templates.ipynb Cell 6)\n",
    "    \"\"\"\n",
    "    if single_detection:\n",
    "        bbox, method, score = find_by_template(img_gray, template_variants, single_detection=True)\n",
    "        if bbox:\n",
    "            return bbox, method, score\n",
    "        return None, None, 0\n",
    "    else:\n",
    "        # Multiple detections using template matching (like 01.Templates.ipynb Cell 6)\n",
    "        detections = find_by_template(img_gray, template_variants, single_detection=False, min_threshold=0.60)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "up51dq952i",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/template_variants.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m fig.suptitle(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTemplate Variants (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(variants)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m transformations)\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m14\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m plt.tight_layout()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults/template_variants.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:1250\u001b[39m, in \u001b[36msavefig\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1247\u001b[39m fig = gcf()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[32m   1249\u001b[39m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m res = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[32m   1251\u001b[39m fig.canvas.draw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:3490\u001b[39m, in \u001b[36mFigure.savefig\u001b[39m\u001b[34m(self, fname, transparent, **kwargs)\u001b[39m\n\u001b[32m   3488\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes:\n\u001b[32m   3489\u001b[39m         _recursively_make_axes_transparent(stack, ax)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\backends\\backend_qtagg.py:75\u001b[39m, in \u001b[36mFigureCanvasQTAgg.print_figure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_figure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# In some cases, Qt will itself trigger a paint event after closing the file\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# save dialog. When that happens, we need to be sure that the internal canvas is\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# re-drawn. However, if the user is using an automatically-chosen Qt backend but\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# saving with a different backend (such as pgf), we do not want to trigger a\u001b[39;00m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# full draw in Qt, so just set the flag for next time.\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m._draw_pending = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\backend_bases.py:2186\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2182\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2183\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2184\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2193\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\backend_bases.py:2042\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2038\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2040\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2041\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2042\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2043\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2045\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:430\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m FigureCanvasAgg.draw(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\matplotlib\\image.py:1657\u001b[39m, in \u001b[36mimsave\u001b[39m\u001b[34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[39m\n\u001b[32m   1655\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1656\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, (dpi, dpi))\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicoc\\Desktop\\VpC\\.venv\\Lib\\site-packages\\PIL\\Image.py:2566\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2564\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2565\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m         fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw+b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2568\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'results/template_variants.png'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEMPLATE VARIANTS VISUALIZATION (4 useful transformations)\n",
    "# =============================================================================\n",
    "\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "variants = create_template_variants(template)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 4))\n",
    "\n",
    "for ax, (name, img) in zip(axes, variants.items()):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(f'Template Variants ({len(variants)} transformations)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/template_variants.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af173e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 1: Single Detection per Image\n",
    "# =============================================================================\n",
    "\n",
    "IMAGES_DIR = 'images/'\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "results = []\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "    img_rgb, img_gray, img_bgr = load_image(img_path)\n",
    "    \n",
    "    bbox, method, match_val = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        # Save with real confidence score\n",
    "        detections = [(x, y, w, h, match_val)]\n",
    "        print(f\"{img_name}: {method} (confidence={match_val:.3f})\")\n",
    "    else:\n",
    "        detections = []\n",
    "        print(f\"{img_name}: NOT DETECTED\")\n",
    "    \n",
    "    results.append((img_rgb, detections, img_name))\n",
    "\n",
    "plot_results_grid(results, \"ASSIGNMENT 1: Single Detection per Image\", 'results/Figure_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891386f8",
   "metadata": {},
   "source": [
    "2. Propose and validate an algorithm for multiple detections in the image coca_multi.png using the same template from item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gktc1c4y0n7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 2: Multiple Detections on coca_multi.png\n",
    "# Using template matching with the same template from Item 1 (like 01.Templates.ipynb Cell 6)\n",
    "# =============================================================================\n",
    "\n",
    "img_rgb, img_gray, img_bgr = load_image('images/coca_multi.png')\n",
    "detections = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "\n",
    "print(f\"Detected {len(detections)} logo instances in coca_multi.png\")\n",
    "for i, det in enumerate(detections):\n",
    "    x, y, w, h, score = det\n",
    "    print(f\"  Detection {i+1}: position=({x},{y}), size=({w}x{h}), confidence={score:.3f}\")\n",
    "\n",
    "plot_single_result(img_rgb, detections, \"ASSIGNMENT 2: coca_multi.png (Template Matching)\", 'results/Figure_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf815d5",
   "metadata": {},
   "source": [
    "3. Generalize the algorithm from item 2 for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 3: Generalized Algorithm for All Images\n",
    "# Generalizes the template matching algorithm from Item 2 for all images\n",
    "# =============================================================================\n",
    "\n",
    "results_single = []\n",
    "results_multi = []\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray, img_bgr = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    \n",
    "    # Single detection: template matching with strict threshold\n",
    "    bbox, method, score = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    det_single = [(bbox[0], bbox[1], bbox[2], bbox[3], score)] if bbox else []\n",
    "    results_single.append((img_rgb, det_single, img_name))\n",
    "    \n",
    "    # Multiple detection: template matching with more permissive threshold (Item 2 algorithm)\n",
    "    det_multi = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "    results_multi.append((img_rgb, det_multi, img_name))\n",
    "    \n",
    "    print(f\"{img_name}: {len(det_single)} single detection, {len(det_multi)} multiple detections\")\n",
    "\n",
    "plot_results_grid(results_single, \"ASSIGNMENT 3: Single Detection (Template Matching)\", 'results/Figure_3a_single.png')\n",
    "plot_results_grid(results_multi, \"ASSIGNMENT 3: Multiple Detection (Template Matching)\", 'results/Figure_3b_multi.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
