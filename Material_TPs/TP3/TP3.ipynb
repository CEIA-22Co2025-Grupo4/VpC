{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d1485",
   "metadata": {},
   "source": [
    "# TP3 - Encontrar el logotipo de la gaseosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaf884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467ba69",
   "metadata": {},
   "source": [
    "## Encontrar el logotipo de la gaseosa dentro de las imágenes provistas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ff4b",
   "metadata": {},
   "source": [
    "1. Obtener una detección del logo en cada imagen sin falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "\n",
    "# Image I/O\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Load image and return RGB and grayscale versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray\n",
    "\n",
    "\n",
    "def load_template(path):\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    return cv.imread(path, 0)\n",
    "\n",
    "\n",
    "# Image Processing\n",
    "\n",
    "def scale_template(template, scale):\n",
    "    \"\"\"Scale template by given factor.\"\"\"\n",
    "    return cv.resize(template, None, fx=scale, fy=scale)\n",
    "\n",
    "\n",
    "def get_relative_scales(img_shape, template_shape, target_ratios):\n",
    "    \"\"\"\n",
    "    Compute scales so template covers target_ratios of image width.\n",
    "    \n",
    "    Example: ratio=0.5 means template will cover 50% of image width.\n",
    "    \"\"\"\n",
    "    img_width = img_shape[1]\n",
    "    template_width = template_shape[1]\n",
    "    return [(img_width * ratio) / template_width for ratio in target_ratios]\n",
    "\n",
    "\n",
    "# Template Matching Core\n",
    "\n",
    "def match_template(img, template, method_id):\n",
    "    \"\"\"Run template matching and return best match info.\"\"\"\n",
    "    w, h = template.shape[::-1]\n",
    "    res = cv.matchTemplate(img, template, method_id)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    \n",
    "    if method_id in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        return {'score': min_val, 'location': min_loc, 'size': (w, h), 'res': res}\n",
    "    return {'score': max_val, 'location': max_loc, 'size': (w, h), 'res': res}\n",
    "\n",
    "\n",
    "def find_best_scale(img, template, scales, method_name, target_ratios=None):\n",
    "    \"\"\"Find the best matching scale for template in image.\"\"\"\n",
    "    method_id = eval(method_name)\n",
    "    is_sqdiff = 'SQDIFF' in method_name\n",
    "    best_score = float('inf') if is_sqdiff else -float('inf')\n",
    "    best_result = None\n",
    "    \n",
    "    for idx, scale in enumerate(scales):\n",
    "        scaled_template = scale_template(template, scale)\n",
    "        \n",
    "        # Skip if template larger than image\n",
    "        if scaled_template.shape[0] > img.shape[0] or scaled_template.shape[1] > img.shape[1]:\n",
    "            continue\n",
    "        \n",
    "        result = match_template(img, scaled_template, method_id)\n",
    "        is_better = result['score'] < best_score if is_sqdiff else result['score'] > best_score\n",
    "        \n",
    "        if is_better:\n",
    "            best_score = result['score']\n",
    "            best_result = {\n",
    "                **result,\n",
    "                'scale': scale,\n",
    "                'method': method_name,\n",
    "                'ratio': target_ratios[idx] if target_ratios else None,\n",
    "            }\n",
    "    \n",
    "    return best_result\n",
    "\n",
    "\n",
    "# Non-Maximum Suppression\n",
    "\n",
    "def remove_overlapping(detections, overlap_thresh=0.3):\n",
    "    \"\"\"Remove overlapping detections using IoU-based NMS.\"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array([[d[0], d[1], d[0]+d[2], d[1]+d[3], d[4]] for d in detections])\n",
    "    x1, y1, x2, y2, scores = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3], boxes[:, 4]\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        # Compute IoU with remaining boxes\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        \n",
    "        intersection = np.maximum(0, xx2 - xx1) * np.maximum(0, yy2 - yy1)\n",
    "        iou = intersection / (areas[i] + areas[order[1:]] - intersection)\n",
    "        \n",
    "        # Keep boxes with IoU below threshold\n",
    "        order = order[np.where(iou <= overlap_thresh)[0] + 1]\n",
    "    \n",
    "    return [detections[i] for i in keep]\n",
    "\n",
    "\n",
    "# Visualization\n",
    "\n",
    "def draw_detection(img_rgb, result):\n",
    "    \"\"\"Draw single detection rectangle on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    x, y = result['location']\n",
    "    w, h = result['size']\n",
    "    cv.rectangle(img_out, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def draw_detections(img_rgb, detections):\n",
    "    \"\"\"Draw multiple detection rectangles on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for (x, y, w, h, score) in detections:\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_results_grid(results, title, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot results in a grid layout.\n",
    "    results: list of (img_rgb, detections, img_name) tuples\n",
    "    \"\"\"\n",
    "    n = len(results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img_rgb, detections, img_name) in enumerate(results):\n",
    "        img_result = draw_detections(img_rgb, detections)\n",
    "        axes[idx].imshow(img_result)\n",
    "        axes[idx].set_title(f\"{img_name}\\n{len(detections)} detection(s)\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for idx in range(n, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4ad9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETECTION FUNCTIONS\n",
    "\n",
    "# Single Detection\n",
    "\n",
    "def find_best_detection(img_gray, template, scales, method_name, target_ratios):\n",
    "    \"\"\"\n",
    "    Find best single detection by trying both gray and inverted variants.\n",
    "    Returns the detection with highest score.\n",
    "    \"\"\"\n",
    "    img_inv = 255 - img_gray\n",
    "    \n",
    "    result_gray = find_best_scale(img_gray, template, scales, method_name, target_ratios)\n",
    "    result_inv = find_best_scale(img_inv, template, scales, method_name, target_ratios)\n",
    "    \n",
    "    # Return best result with variant info\n",
    "    if result_inv and (not result_gray or result_inv['score'] > result_gray['score']):\n",
    "        result_inv['variant'] = 'gray_inv'\n",
    "        result_inv['use_inversion'] = True\n",
    "        return result_inv\n",
    "    elif result_gray:\n",
    "        result_gray['variant'] = 'gray'\n",
    "        result_gray['use_inversion'] = False\n",
    "        return result_gray\n",
    "    return None\n",
    "\n",
    "\n",
    "# Multiple Detection\n",
    "\n",
    "def detect_at_scale(img, template, scale, threshold, method_name):\n",
    "    \"\"\"Detect all matches at a single scale above threshold.\"\"\"\n",
    "    method_id = eval(method_name)\n",
    "    scaled_template = scale_template(template, scale)\n",
    "    w, h = scaled_template.shape[::-1]\n",
    "    \n",
    "    if scaled_template.shape[0] > img.shape[0] or scaled_template.shape[1] > img.shape[1]:\n",
    "        return []\n",
    "    \n",
    "    res = cv.matchTemplate(img, scaled_template, method_id)\n",
    "    \n",
    "    if 'SQDIFF' in method_name:\n",
    "        loc = np.where(res <= threshold)\n",
    "    else:\n",
    "        loc = np.where(res >= threshold)\n",
    "    \n",
    "    return [(pt[0], pt[1], w, h, res[pt[1], pt[0]]) for pt in zip(*loc[::-1])]\n",
    "\n",
    "\n",
    "def detect_multiscale(img, template, scales, threshold, method_name):\n",
    "    \"\"\"Detect all matches across multiple scales.\"\"\"\n",
    "    all_detections = []\n",
    "    for scale in scales:\n",
    "        all_detections.extend(detect_at_scale(img, template, scale, threshold, method_name))\n",
    "    return all_detections\n",
    "\n",
    "\n",
    "def get_adaptive_threshold(img, template, scales, method_name, factor=0.70):\n",
    "    \"\"\"Compute threshold as a factor of max correlation found.\"\"\"\n",
    "    method_id = eval(method_name)\n",
    "    max_corr = 0\n",
    "    \n",
    "    for scale in scales:\n",
    "        scaled_template = scale_template(template, scale)\n",
    "        if scaled_template.shape[0] > img.shape[0] or scaled_template.shape[1] > img.shape[1]:\n",
    "            continue\n",
    "        res = cv.matchTemplate(img, scaled_template, method_id)\n",
    "        max_corr = max(max_corr, res.max())\n",
    "    \n",
    "    return max_corr * factor\n",
    "\n",
    "\n",
    "def detect_multiple_logos(img_gray, template, scales, method_name, threshold_factor, use_inversion):\n",
    "    \"\"\"Detect multiple logos using specified variant.\"\"\"\n",
    "    img_processed = 255 - img_gray if use_inversion else img_gray\n",
    "    threshold = get_adaptive_threshold(img_processed, template, scales, method_name, threshold_factor)\n",
    "    detections = detect_multiscale(img_processed, template, scales, threshold, method_name)\n",
    "    return remove_overlapping(detections, overlap_thresh=0.3)\n",
    "\n",
    "\n",
    "# Generalized Detection\n",
    "\n",
    "def detect_logos(img_gray, template, method='cv.TM_CCOEFF_NORMED', \n",
    "                 single_detection=False, threshold_factor=0.70):\n",
    "    \"\"\"\n",
    "    General logo detection for all images.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Determines best variant (gray or gray_inv) using wide scale range\n",
    "    2. For single detection: returns best match\n",
    "    3. For multiple detection: returns all matches above adaptive threshold\n",
    "    \n",
    "    Parameters:\n",
    "        single_detection: If True, returns only best match\n",
    "        threshold_factor: Sensitivity for multi-detection (0.70 = 70% of max)\n",
    "    \"\"\"\n",
    "    # Scale configurations\n",
    "    RATIOS_SINGLE = [0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90]\n",
    "    RATIOS_MULTI = [0.15, 0.18, 0.20, 0.22, 0.25, 0.28, 0.30, 0.35, 0.40]\n",
    "    \n",
    "    # Find best variant using wide scale range\n",
    "    scales_single = get_relative_scales(img_gray.shape, template.shape, RATIOS_SINGLE)\n",
    "    best_result = find_best_detection(img_gray, template, scales_single, method, RATIOS_SINGLE)\n",
    "    \n",
    "    if not best_result:\n",
    "        return []\n",
    "    \n",
    "    use_inversion = best_result.get('use_inversion', True)\n",
    "    \n",
    "    if single_detection:\n",
    "        return [(best_result['location'][0], best_result['location'][1],\n",
    "                 best_result['size'][0], best_result['size'][1], best_result['score'])]\n",
    "    \n",
    "    # Multi-detection with winning variant\n",
    "    scales_multi = get_relative_scales(img_gray.shape, template.shape, RATIOS_MULTI)\n",
    "    return detect_multiple_logos(img_gray, template, scales_multi, method, threshold_factor, use_inversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af173e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ASSIGNMENT 1: Single Detection per Image\n",
      "======================================================================\n",
      "  COCA-COLA-LOGO.jpg: 1 detection\n",
      "  coca_logo_1.png: 1 detection\n",
      "  coca_logo_2.png: 1 detection\n",
      "  coca_multi.png: 1 detection\n",
      "  coca_retro_1.png: 1 detection\n",
      "  coca_retro_2.png: 1 detection\n",
      "  logo_1.png: 1 detection\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TEMPLATE_PATH = 'template/pattern.png'\n",
    "IMAGES_DIR = 'images/'\n",
    "METHOD = 'cv.TM_CCOEFF_NORMED'\n",
    "\n",
    "# Load template\n",
    "template = load_template(TEMPLATE_PATH)\n",
    "\n",
    "# Get all images\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ASSIGNMENT 1: Single Detection per Image\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Process all images\n",
    "results = []\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    detections = detect_logos(img_gray, template, METHOD, single_detection=True)\n",
    "    results.append((img_rgb, detections, img_name))\n",
    "    print(f\"  {img_name}: {len(detections)} detection\")\n",
    "\n",
    "# Plot results\n",
    "plot_results_grid(results, \"ASSIGNMENT 1: Single Detection per Image\", 'results/Figure_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891386f8",
   "metadata": {},
   "source": [
    "2. Plantear y validar un algoritmo para múltiples detecciones en la imagen coca_multi.png con el mismo témplate del ítem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gktc1c4y0n7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coca_multi.png\n",
    "img_rgb, img_gray = load_image('images/coca_multi.png')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ASSIGNMENT 2: Multiple Detections on coca_multi.png\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different threshold factors\n",
    "print(\"\\nTesting threshold factors:\")\n",
    "for factor in [0.80, 0.75, 0.70, 0.65]:\n",
    "    detections = detect_logos(img_gray, template, METHOD, single_detection=False, threshold_factor=factor)\n",
    "    print(f\"  factor={factor}: {len(detections)} detections\")\n",
    "\n",
    "# Final result with best threshold\n",
    "THRESHOLD_FACTOR = 0.70\n",
    "detections = detect_logos(img_gray, template, METHOD, single_detection=False, threshold_factor=THRESHOLD_FACTOR)\n",
    "print(f\"\\nFinal: {len(detections)} detections (threshold_factor={THRESHOLD_FACTOR})\")\n",
    "\n",
    "# Plot result\n",
    "img_result = draw_detections(img_rgb, detections)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(img_result)\n",
    "plt.title(f\"ASSIGNMENT 2: coca_multi.png | {len(detections)} detections\")\n",
    "plt.axis('off')\n",
    "plt.savefig('results/Figure_2.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf815d5",
   "metadata": {},
   "source": [
    "3. Generalizar el algoritmo del item 2 para todas las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ASSIGNMENT 3: Generalized Algorithm for All Images\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Process all images with multi-detection\n",
    "THRESHOLD_FACTOR = 0.70\n",
    "\n",
    "results_single = []\n",
    "results_multi = []\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    \n",
    "    # Single detection\n",
    "    det_single = detect_logos(img_gray, template, METHOD, single_detection=True)\n",
    "    results_single.append((img_rgb, det_single, img_name))\n",
    "    \n",
    "    # Multiple detection\n",
    "    det_multi = detect_logos(img_gray, template, METHOD, single_detection=False, threshold_factor=THRESHOLD_FACTOR)\n",
    "    results_multi.append((img_rgb, det_multi, img_name))\n",
    "    \n",
    "    print(f\"  {img_name}: single={len(det_single)}, multi={len(det_multi)}\")\n",
    "\n",
    "# Plot single detection results\n",
    "print(\"\\n--- Single Detection Results\")\n",
    "plot_results_grid(results_single, \"ASSIGNMENT 3: Generalized Single Detection\", 'results/Figure_3a_single.png')\n",
    "\n",
    "# Plot multiple detection results\n",
    "print(\"\\n--- Multiple Detection Results\")\n",
    "plot_results_grid(results_multi, \"ASSIGNMENT 3: Generalized Multiple Detection\", 'results/Figure_3b_multi.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
