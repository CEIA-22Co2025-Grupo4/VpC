{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d1485",
   "metadata": {},
   "source": [
    "# TP3 - Encontrar el logotipo de la gaseosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaf884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467ba69",
   "metadata": {},
   "source": [
    "## Encontrar el logotipo de la gaseosa dentro de las imágenes provistas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ff4b",
   "metadata": {},
   "source": [
    "1. Obtener una detección del logo en cada imagen sin falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(path, max_size=1200):\n",
    "    \"\"\"Load image and return RGB, grayscale, and BGR versions.\"\"\"\n",
    "    img = cv.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        img = cv.resize(img, None, fx=scale, fy=scale)\n",
    "    \n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return img_rgb, img_gray, img\n",
    "\n",
    "\n",
    "def load_template(path, max_size=400):\n",
    "    \"\"\"Load template as grayscale.\"\"\"\n",
    "    template = cv.imread(path, 0)\n",
    "    h, w = template.shape[:2]\n",
    "    if max(h, w) > max_size:\n",
    "        scale = max_size / max(h, w)\n",
    "        template = cv.resize(template, None, fx=scale, fy=scale)\n",
    "    return template\n",
    "\n",
    "\n",
    "def create_template_variants(template):\n",
    "    \"\"\"\n",
    "    Create multiple template variants to improve matching.\n",
    "    Includes: grayscale, inverted, edges, binary, sobel, CLAHE, morphological, and Laplacian.\n",
    "    \"\"\"\n",
    "    blurred = cv.GaussianBlur(template, (3, 3), 0)\n",
    "    equalized = cv.equalizeHist(blurred)\n",
    "    \n",
    "    # CLAHE\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_img = clahe.apply(blurred)\n",
    "    \n",
    "    # Binary (Otsu)\n",
    "    _, binary = cv.threshold(equalized, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    \n",
    "    # Edges\n",
    "    edges = cv.Canny(equalized, 50, 150)\n",
    "    \n",
    "    # Sobel\n",
    "    sobel_x = cv.Sobel(equalized, cv.CV_8U, 1, 0, ksize=3)\n",
    "    sobel_y = cv.Sobel(equalized, cv.CV_8U, 0, 1, ksize=3)\n",
    "    sobel = cv.addWeighted(sobel_x, 0.5, sobel_y, 0.5, 0)\n",
    "    \n",
    "    # Morphological\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated = cv.dilate(equalized, kernel, iterations=1)\n",
    "    eroded = cv.erode(equalized, kernel, iterations=1)\n",
    "    \n",
    "    # Laplacian (from Clase4/04.Piramides)\n",
    "    laplacian = cv.Laplacian(equalized, cv.CV_8U)\n",
    "    \n",
    "    # LOG (Laplacian of Gaussian)\n",
    "    log = cv.Laplacian(blurred, cv.CV_8U)\n",
    "    \n",
    "    return {\n",
    "        'original': equalized,\n",
    "        'inverted': 255 - equalized,\n",
    "        'edges': edges,\n",
    "        'binary': binary,\n",
    "        'binary_inv': 255 - binary,\n",
    "        'sobel': sobel,\n",
    "        'clahe': clahe_img,\n",
    "        'clahe_inv': 255 - clahe_img,\n",
    "        'dilated': dilated,\n",
    "        'eroded': eroded,\n",
    "        'laplacian': laplacian,\n",
    "        'log': log,\n",
    "    }\n",
    "\n",
    "\n",
    "def draw_detections(img_rgb, detections):\n",
    "    \"\"\"Draw detection rectangles on image.\"\"\"\n",
    "    img_out = img_rgb.copy()\n",
    "    for det in detections:\n",
    "        x, y, w, h = det[:4]\n",
    "        cv.rectangle(img_out, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def plot_results_grid(results, title, save_path=None):\n",
    "    \"\"\"Plot results in a grid layout.\"\"\"\n",
    "    n = len(results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img_rgb, detections, img_name) in enumerate(results):\n",
    "        img_result = draw_detections(img_rgb, detections)\n",
    "        axes[idx].imshow(img_result)\n",
    "        axes[idx].set_title(f\"{img_name}\\n{len(detections)} detection(s)\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for idx in range(n, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single_result(img_rgb, detections, title, save_path=None):\n",
    "    \"\"\"Plot single image result.\"\"\"\n",
    "    img_result = draw_detections(img_rgb, detections)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_result)\n",
    "    plt.title(f\"{title} | {len(detections)} detections\")\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad9c58",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DETECTION FUNCTIONS\n# =============================================================================\n\ndef create_template_variants(template):\n    \"\"\"\n    Create only useful template variants for template matching.\n    Only: original, clahe, smooth, inverted.\n    \"\"\"\n    smooth = cv.GaussianBlur(template, (3, 3), 0)\n    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    clahe_img = clahe.apply(template)\n    inverted = 255 - template\n    \n    return {\n        'original': template,\n        'clahe': clahe_img,\n        'smooth': smooth,\n        'inverted': inverted,\n    }\n\n\ndef preprocess_image(img_gray):\n    \"\"\"Preprocess image before template matching.\"\"\"\n    img = cv.GaussianBlur(img_gray, (3, 3), 0)\n    img = cv.equalizeHist(img)\n    return img\n\n\ndef compute_iou(box1, box2):\n    \"\"\"Compute IoU between two boxes (x, y, w, h).\"\"\"\n    x1, y1, w1, h1 = box1\n    x2, y2, w2, h2 = box2\n    \n    xi1 = max(x1, x2)\n    yi1 = max(y1, y2)\n    xi2 = min(x1 + w1, x2 + w2)\n    yi2 = min(y1 + h1, y2 + h2)\n    \n    inter_w = max(0, xi2 - xi1)\n    inter_h = max(0, yi2 - yi1)\n    inter_area = inter_w * inter_h\n    \n    area1 = w1 * h1\n    area2 = w2 * h2\n    union_area = area1 + area2 - inter_area\n    \n    return inter_area / union_area if union_area > 0 else 0\n\n\ndef nms_global(detections, iou_threshold=0.3):\n    \"\"\"\n    Apply Non-Maximum Suppression globally across all detections.\n    detections: list of (x, y, w, h, score)\n    \"\"\"\n    if not detections:\n        return []\n    \n    detections = sorted(detections, key=lambda d: d[4], reverse=True)\n    \n    keep = []\n    while detections:\n        best = detections.pop(0)\n        keep.append(best)\n        detections = [d for d in detections if compute_iou(best[:4], d[:4]) < iou_threshold]\n    \n    return keep\n\n\ndef find_by_template(img_gray, template_variants, single_detection=True, min_threshold=0.30):\n    \"\"\"\n    Multi-scale template matching.\n    - 30 scales between 0.2 and 1.6\n    - Adaptive threshold: mean + 2.5*std, min 0.30\n    - Global NMS\n    - Aspect ratio filtering: 0.5 < w/h < 3.0\n    \"\"\"\n    h, w = img_gray.shape\n    img_processed = preprocess_image(img_gray)\n    \n    scales = np.linspace(0.2, 1.6, 30)\n    all_detections = []\n    \n    for scale in scales:\n        for name, tmpl in template_variants.items():\n            th, tw = tmpl.shape\n            new_w = int(tw * scale)\n            new_h = int(th * scale)\n            \n            if new_w > w or new_h > h or new_w < 20 or new_h < 10:\n                continue\n            \n            scaled_tmpl = cv.resize(tmpl, (new_w, new_h))\n            res = cv.matchTemplate(img_processed, scaled_tmpl, cv.TM_CCOEFF_NORMED)\n            \n            mean_val = np.mean(res)\n            std_val = np.std(res)\n            threshold = max(mean_val + 2.5 * std_val, min_threshold)\n            \n            locations = np.where(res >= threshold)\n            \n            for pt in zip(*locations[::-1]):\n                x, y = pt\n                score = res[y, x]\n                \n                aspect = new_w / new_h if new_h > 0 else 0\n                if not (0.5 < aspect < 3.0):\n                    continue\n                \n                all_detections.append((x, y, new_w, new_h, score))\n    \n    if not all_detections:\n        return (None, None, 0) if single_detection else []\n    \n    final_detections = nms_global(all_detections, iou_threshold=0.3)\n    \n    if single_detection:\n        best = final_detections[0]\n        return (best[0], best[1], best[2], best[3]), 'template', best[4]\n    \n    return final_detections\n\n\ndef find_by_color_multi(img_bgr, min_area=500):\n    \"\"\"Find multiple Coca-Cola logos by color detection (for Assignment 2).\"\"\"\n    h, w = img_bgr.shape[:2]\n    hsv = cv.cvtColor(img_bgr, cv.COLOR_BGR2HSV)\n\n    mask1 = cv.inRange(hsv, np.array([0, 70, 50]), np.array([10, 255, 255]))\n    mask2 = cv.inRange(hsv, np.array([160, 70, 50]), np.array([180, 255, 255]))\n    red_mask = cv.bitwise_or(mask1, mask2)\n    red_mask = cv.morphologyEx(red_mask, cv.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n\n    white_mask = cv.inRange(hsv, np.array([0, 0, 180]), np.array([180, 50, 255]))\n    white_on_red = cv.bitwise_and(white_mask, red_mask)\n    dilated = cv.dilate(white_on_red, np.ones((5, 8), np.uint8), iterations=2)\n\n    contours, _ = cv.findContours(dilated, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n\n    detections = []\n    for cnt in contours:\n        x, y, cw, ch = cv.boundingRect(cnt)\n        area = cw * ch\n        aspect = cw / ch if ch > 0 else 0\n        if aspect > 1.0 and area > min_area and cw > 30 and ch > 15:\n            detections.append((x, y, cw, ch, area / (w * h)))\n    return detections\n\n\ndef detect_logo(img_bgr, img_gray, template_variants, single_detection=True):\n    \"\"\"\n    Detection pipeline.\n    - Single detection: Template matching\n    - Multi detection: Color-based detection\n    \"\"\"\n    if not single_detection:\n        return find_by_color_multi(img_bgr)\n\n    bbox, method, score = find_by_template(img_gray, template_variants, single_detection=True)\n    if bbox:\n        return bbox, method, score\n\n    return None, None, 0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "up51dq952i",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TEMPLATE VARIANTS VISUALIZATION (4 useful transformations)\n# =============================================================================\n\nTEMPLATE_PATH = 'template/pattern.png'\ntemplate = load_template(TEMPLATE_PATH)\nvariants = create_template_variants(template)\n\nfig, axes = plt.subplots(1, 4, figsize=(14, 4))\n\nfor ax, (name, img) in zip(axes, variants.items()):\n    ax.imshow(img, cmap='gray')\n    ax.set_title(name)\n    ax.axis('off')\n\nfig.suptitle(f'Template Variants ({len(variants)} transformations)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('results/template_variants.png', dpi=120, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af173e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 1: Single Detection per Image\n",
    "# =============================================================================\n",
    "\n",
    "IMAGES_DIR = 'images/'\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "results = []\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "    img_rgb, img_gray, img_bgr = load_image(img_path)\n",
    "    \n",
    "    bbox, method, match_val = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        detections = [(x, y, w, h, 1.0)]\n",
    "        print(f\"{img_name}: {method} (match={match_val:.2f})\")\n",
    "    else:\n",
    "        detections = []\n",
    "        print(f\"{img_name}: NOT DETECTED\")\n",
    "    \n",
    "    results.append((img_rgb, detections, img_name))\n",
    "\n",
    "plot_results_grid(results, \"ASSIGNMENT 1: Single Detection per Image\", 'results/Figure_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891386f8",
   "metadata": {},
   "source": [
    "2. Plantear y validar un algoritmo para múltiples detecciones en la imagen coca_multi.png con el mismo témplate del ítem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gktc1c4y0n7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 2: Multiple Detections on coca_multi.png\n",
    "# =============================================================================\n",
    "\n",
    "img_rgb, img_gray, img_bgr = load_image('images/coca_multi.png')\n",
    "detections = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "\n",
    "plot_single_result(img_rgb, detections, \"ASSIGNMENT 2: coca_multi.png\", 'results/Figure_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf815d5",
   "metadata": {},
   "source": [
    "3. Generalizar el algoritmo del item 2 para todas las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGNMENT 3: Generalized Algorithm for All Images\n",
    "# =============================================================================\n",
    "\n",
    "results_single = []\n",
    "results_multi = []\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_rgb, img_gray, img_bgr = load_image(os.path.join(IMAGES_DIR, img_name))\n",
    "    \n",
    "    # Single detection\n",
    "    bbox, method, _ = detect_logo(img_bgr, img_gray, variants, single_detection=True)\n",
    "    det_single = [(bbox[0], bbox[1], bbox[2], bbox[3], 1.0)] if bbox else []\n",
    "    results_single.append((img_rgb, det_single, img_name))\n",
    "    \n",
    "    # Multiple detection\n",
    "    det_multi = detect_logo(img_bgr, img_gray, variants, single_detection=False)\n",
    "    results_multi.append((img_rgb, det_multi, img_name))\n",
    "\n",
    "plot_results_grid(results_single, \"ASSIGNMENT 3: Single Detection\", 'results/Figure_3a_single.png')\n",
    "plot_results_grid(results_multi, \"ASSIGNMENT 3: Multiple Detection\", 'results/Figure_3b_multi.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}